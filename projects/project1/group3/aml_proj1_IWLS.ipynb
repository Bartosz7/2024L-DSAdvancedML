{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "gQUkvDc1jawH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_data(X,y):\n",
        "  if len(X) != len(y):\n",
        "    return False, \"Length of the answer vector doesn't fit the number of data points.\\n\"\n",
        "  for i in range(1,len(X)):\n",
        "    if len(X[i]) != len(X[0]):\n",
        "      return False, \"The row at the index \"+str(i)+\" seems to be missing an observation.\\n\"\n",
        "  for i in range(len(y)):\n",
        "    if y[i] < 0 or y[i] > 1:\n",
        "      return False, \"The answer at the index \"+str(i)+\" doesn't indicate a binary class nor does it indicate a probability of belonging to one.\\n\"\n",
        "  return True, \"\""
      ],
      "metadata": {
        "id": "JxfvWdvsjfXp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "szFf-YC-qR_Q"
      },
      "outputs": [],
      "source": [
        "def fit_with_IWLS(data, answers, intercept: bool = False,\n",
        "                  relevant_variables = None, additional_interactions = None,\n",
        "                  l2_reg: float = 1.0, beta0_gen = None,\n",
        "                  max_iterations: int = 100, min_step_norm: float = 1e-12,\n",
        "                  max_time: float = 3600.0, check_data: bool = False):\n",
        "  \"\"\"\n",
        "  Calculated the coefficients of a Logistic Regression model using Iterative\n",
        "  Weighted Least Squares method.\n",
        "  :param data: The data on which the model will be fit.\n",
        "  :param answers: The vector with answers (numbers belonging to the\n",
        "    [0,1] interval).\n",
        "  :param intercept: If True, the model will fit an intercept (meaning beta' @ x\n",
        "    shall be replaced with beta' @ x + beta0 in all calculations).\n",
        "  :param relevant_variables: A collection of indices, indicating on which\n",
        "    columns of the data should the model be built.\n",
        "    If None, all columns will be used.\n",
        "  :param additional_interactions: A collection of pairs of indices, indicating\n",
        "    which column element-wise products should be using for building the model.\n",
        "    If None, no such variables will be considered.\n",
        "  :param l2_reg: The strength of ridge regularization (the coefficient of\n",
        "    the ridge penalty). 0 means no regularization. 1 is the default, same as\n",
        "    in the scikit-learn implementation.\n",
        "  :param beta0_gen: A generator used to determine the starting values of\n",
        "    coefficients. Should include .generate(n: int) method, returning a numpy\n",
        "    array of length n filled with floats.\n",
        "    If None, all coefficients will be initialized to zeros.\n",
        "  :param max_iterations: The maximum number of iterations the algorhithm will\n",
        "    perform before stopping and proposing a solution.\n",
        "    By default, 100 in accordance to scikit-learn implementation.\n",
        "  :param min_step_norm: The minimum value for the euclidian norm of the change\n",
        "    of a parameter vector in a single step. If the difference between\n",
        "    iterations falls below that number, the algorhithm will stop and propose\n",
        "    a solution.\n",
        "  :param max_time: The maximum time the procedure can run in seconds. Once\n",
        "    exceeded, the iterating will stop and the solution will be proposed.\n",
        "  :param check_data: If True, the format of data and answers will be examined\n",
        "    prior to running the algorhithm.\n",
        "\n",
        "  :return: A numpy array containing the proposed coefficients and a dictionary,\n",
        "    labeling said coefficients.\n",
        "  \"\"\"\n",
        "  # Ensuring the correct dimensionality of the data.\n",
        "  if check_data:\n",
        "    status, message = check_data(data, answers)\n",
        "    assert status, message\n",
        "  assert len(data) == len(answers), \"For every data point, there has to be a correct class specified.\\n\"\n",
        "  n = len(data)\n",
        "\n",
        "  # Filling up the default values of parameters.\n",
        "  if additional_interactions is None:\n",
        "    additional_interactions = []\n",
        "  if relevant_variables is None:\n",
        "    relevant_variables = np.arange(len(data[0]))\n",
        "\n",
        "  ### Constructing the experiment matrix and labels for it.\n",
        "  Y = np.array(answers)\n",
        "  X = []\n",
        "  labels = []\n",
        "  for index in relevant_variables:\n",
        "    X.append(np.array(data[:,index]).astype(float))\n",
        "    labels.append(\"X\"+str(index))\n",
        "\n",
        "  for index1, index2 in additional_interactions:\n",
        "    X.append(np.array(data[:,index1]).astype(float) * np.array(data[:,index2]).astype(float))\n",
        "    labels.append(\"X\"+str(index1)+\"X\"+str(index2))\n",
        "\n",
        "  if intercept:\n",
        "    X.append(np.ones(n))\n",
        "    labels.append(\"intercept\")\n",
        "\n",
        "  X = np.column_stack(X)\n",
        "  p = len(labels)\n",
        "  # If the penalty is the l2_reg times the sum of squares of coefficients, this\n",
        "  # is the matrix of the second order derivatives with respect to the coefs.\n",
        "  penalty_hessian = 2 * l2_reg * np.eye(p)\n",
        "\n",
        "  ### Initializing coefficients.\n",
        "  if beta0_gen is None:\n",
        "    beta = np.zeros(p)\n",
        "  else:\n",
        "    beta = beta0_gen.generate(p)\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  ### Iterating the main algorhithm.\n",
        "  for _ in range(max_iterations):\n",
        "    P = X @ beta\n",
        "    P = np.exp(P) / (np.exp(P) + 1)\n",
        "    W = np.diag(P * (1 - P))\n",
        "\n",
        "    # deriv is the derivative of the minus log-like + penalty with respect to beta\n",
        "    deriv =  X.transpose() @ (P-Y) + 2 * l2_reg * beta\n",
        "    # hessian is the matrix of second order derivatives of the previously mentioned function\n",
        "    hessian = X.transpose() @ W @ X + penalty_hessian\n",
        "\n",
        "    # In order to avoid numerical complexity of the matrix inversion,\n",
        "    # new beta is defined as a solution to a linear equation.\n",
        "    beta_new = np.linalg.solve(hessian, hessian @ beta - deriv)\n",
        "\n",
        "    diff = beta - beta_new\n",
        "    diff_norm = np.sqrt(diff @ diff)\n",
        "    beta = beta_new\n",
        "    if diff_norm < min_step_norm:\n",
        "      break\n",
        "    curr = time.time()\n",
        "    if curr - start > max_time:\n",
        "      break\n",
        "\n",
        "  ### Creating the coefficient dictionary.\n",
        "  beta_dict = {}\n",
        "  for i in range(p):\n",
        "    beta_dict[labels[i]] = beta[i]\n",
        "\n",
        "  return beta, beta_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example**"
      ],
      "metadata": {
        "id": "VMzRcFbPYO4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_data(n: int):\n",
        "  X = np.random.normal(loc=0,scale=1,size=(n,3))\n",
        "  Y = X[:,0] + (X[:,1] * X[:,2])\n",
        "  Y = (Y > 1).astype(int)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "JTzEQwcGl5xG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = generate_fake_data(10)\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbHDRmasmf_c",
        "outputId": "e20ba236-11c9-4477-a78d-79a31fc42273"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.2769084   0.97461493 -1.70939791]\n",
            " [ 1.32057104  0.48228883  1.33455102]\n",
            " [ 1.44572932 -0.81520141  0.3026459 ]\n",
            " [ 0.62406698 -1.05531948 -0.65286175]\n",
            " [ 1.5757052   1.43480957 -0.59260877]\n",
            " [-1.31432842  2.00401493  0.11509419]\n",
            " [ 0.11245183  0.77642164  1.08314294]\n",
            " [-0.1703819  -2.39797365  1.11380643]\n",
            " [ 0.43700367  0.16743747 -1.67064208]\n",
            " [ 2.30200017 -0.30759345 -1.63520366]]\n",
            "[0 1 1 1 0 0 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = generate_fake_data(1000)\n",
        "interactions = [(0,1), (1,2), (2,0)]"
      ],
      "metadata": {
        "id": "GSd4z5WYnfhY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta1, beta1_dict = fit_with_IWLS(X, Y, intercept=False, max_iterations=500)\n",
        "beta2, beta2_dict = fit_with_IWLS(X, Y, intercept=True, additional_interactions=interactions, max_iterations=500)"
      ],
      "metadata": {
        "id": "6H-hwef8n6mP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(beta1_dict)\n",
        "print(beta2_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9JAZtr8omzP",
        "outputId": "755118ce-7f2b-4b8c-87aa-793b0c5c8588"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'X0': 1.111542112280021, 'X1': -0.03760221407116636, 'X2': 0.01815495209641154}\n",
            "{'X0': 3.785955804511253, 'X1': 0.042327736624419, 'X2': -0.01698865779874892, 'X0X1': 0.044835245048462556, 'X1X2': 3.793928962655196, 'X2X0': 0.013792500116502111, 'intercept': -3.9445740505194786}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9X8tXigpNEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}