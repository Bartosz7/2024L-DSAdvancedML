{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "gQUkvDc1jawH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_data(X,y):\n",
        "  if len(X) != len(y):\n",
        "    return False, \"Length of the answer vector doesn't fit the number of data points.\\n\"\n",
        "  for i in range(1,len(X)):\n",
        "    if len(X[i]) != len(X[0]):\n",
        "      return False, \"The row at the index \"+str(i)+\" seems to be missing an observation.\\n\"\n",
        "  for i in range(len(y)):\n",
        "    if y[i] < 0 or y[i] > 1:\n",
        "      return False, \"The answer at the index \"+str(i)+\" doesn't indicate a binary class nor does it indicate a probability of belonging to one.\\n\"\n",
        "  return True, \"\""
      ],
      "metadata": {
        "id": "JxfvWdvsjfXp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loglike(X, Y, beta):\n",
        "  \"\"\"\n",
        "  Calculates the value of the log-likelihood for a given training data,\n",
        "  answer vector and model parameters\n",
        "  :param X: a 2d numpy array containing the experiment matrix.\n",
        "  :param Y: a 1d numpy array containing the answer vector.\n",
        "  :param beta: a 1d numpy array containing the parameters of the model.\n",
        "  :return: a single float with the value of the log-likelihood function.\n",
        "  \"\"\"\n",
        "  Xbeta = X @ beta\n",
        "  return Y @ Xbeta - np.sum(np.log(1+np.exp(Xbeta)))"
      ],
      "metadata": {
        "id": "olvBF8nvC-0Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "szFf-YC-qR_Q"
      },
      "outputs": [],
      "source": [
        "def fit_with_IWLS(data, answers, intercept: bool = True,\n",
        "                  relevant_variables = None, additional_interactions = None,\n",
        "                  l2_reg: float = 1.0, beta0_gen = None,\n",
        "                  max_iterations: int = 500, min_step_norm: float = 1e-4,\n",
        "                  max_time: float = 3600.0, check_data: bool = False):\n",
        "  \"\"\"\n",
        "  Calculates the coefficients of a Logistic Regression model using Iterative\n",
        "  Weighted Least Squares method.\n",
        "  :param data: The data on which the model will be fit.\n",
        "  :param answers: The vector with answers (numbers belonging to the\n",
        "    [0,1] interval).\n",
        "  :param intercept: If True, the model will fit an intercept (meaning beta' @ x\n",
        "    shall be replaced with beta' @ x + beta0 in all calculations).\n",
        "  :param relevant_variables: A collection of indices, indicating on which\n",
        "    columns of the data should the model be built.\n",
        "    If None, all columns will be used.\n",
        "  :param additional_interactions: A collection of pairs of indices, indicating\n",
        "    which column element-wise products should be using for building the model.\n",
        "    If None, no such variables will be considered.\n",
        "  :param l2_reg: The strength of ridge regularization (the coefficient of\n",
        "    the ridge penalty). 0 means no regularization. 1 is the default, same as\n",
        "    in the scikit-learn implementation.\n",
        "  :param beta0_gen: A generator used to determine the starting values of\n",
        "    coefficients. Should include .generate(n: int) method, returning a numpy\n",
        "    array of length n filled with floats.\n",
        "    If None, all coefficients will be initialized to zeros.\n",
        "  :param max_iterations: The maximum number of iterations the algorhithm will\n",
        "    perform before stopping and proposing a solution.\n",
        "    By default, 100 in accordance to scikit-learn implementation.\n",
        "  :param min_step_norm: The minimum value for the euclidian norm of the change\n",
        "    of a parameter vector in a single step. If the difference between\n",
        "    iterations falls below that number, the algorhithm will stop and propose\n",
        "    a solution.\n",
        "  :param max_time: The maximum time the procedure can run in seconds. Once\n",
        "    exceeded, the iterating will stop and the solution will be proposed.\n",
        "  :param check_data: If True, the format of data and answers will be examined\n",
        "    prior to running the algorhithm.\n",
        "\n",
        "  :return: A numpy array containing the proposed coefficients and a dictionary,\n",
        "    labeling said coefficients, a list containing the coefficients after each\n",
        "    iteration and a list containing the values of the log-likelihood function\n",
        "    after each iteration.\n",
        "  \"\"\"\n",
        "  # Ensuring the correct dimensionality of the data.\n",
        "  if check_data:\n",
        "    status, message = check_data(data, answers)\n",
        "    assert status, message\n",
        "  assert len(data) == len(answers), \"For every data point, there has to be a correct class specified.\\n\"\n",
        "  n = len(data)\n",
        "\n",
        "  # Filling up the default values of parameters.\n",
        "  if additional_interactions is None:\n",
        "    additional_interactions = []\n",
        "  if relevant_variables is None:\n",
        "    relevant_variables = np.arange(len(data[0]))\n",
        "\n",
        "  ### Constructing the experiment matrix and labels for it.\n",
        "  Y = np.array(answers)\n",
        "  X = []\n",
        "  labels = []\n",
        "  for index in relevant_variables:\n",
        "    X.append(np.array(data[:,index]).astype(float))\n",
        "    labels.append(\"X\"+str(index))\n",
        "\n",
        "  for index1, index2 in additional_interactions:\n",
        "    X.append(np.array(data[:,index1]).astype(float) * np.array(data[:,index2]).astype(float))\n",
        "    labels.append(\"X\"+str(index1)+\"X\"+str(index2))\n",
        "\n",
        "  if intercept:\n",
        "    X.append(np.ones(n))\n",
        "    labels.append(\"intercept\")\n",
        "\n",
        "  X = np.column_stack(X)\n",
        "  p = len(labels)\n",
        "  # If the penalty is the l2_reg times the sum of squares of coefficients, this\n",
        "  # is the matrix of the second order derivatives with respect to the coefs.\n",
        "  penalty_hessian = 2 * l2_reg * np.eye(p)\n",
        "\n",
        "  ### Initializing coefficients.\n",
        "  if beta0_gen is None:\n",
        "    beta = np.zeros(p)\n",
        "  else:\n",
        "    beta = beta0_gen.generate(p)\n",
        "\n",
        "  start = time.time()\n",
        "  beta_hist = []\n",
        "  loglike_hist = []\n",
        "  beta_hist.append(beta)\n",
        "  loglike_hist.append(calc_loglike(X, Y, beta))\n",
        "  ### Iterating the main algorhithm.\n",
        "  for _ in range(max_iterations):\n",
        "    P = X @ beta\n",
        "    P = np.exp(P) / (np.exp(P) + 1)\n",
        "    W = np.diag(P * (1 - P))\n",
        "\n",
        "    # deriv is the derivative of the minus log-like + penalty with respect to beta\n",
        "    deriv =  X.transpose() @ (P-Y) + 2 * l2_reg * beta\n",
        "    # hessian is the matrix of second order derivatives of the previously mentioned function\n",
        "    hessian = X.transpose() @ W @ X + penalty_hessian\n",
        "\n",
        "    # In order to avoid numerical complexity of the matrix inversion,\n",
        "    # new beta is defined as a solution to a linear equation.\n",
        "    beta_new = np.linalg.solve(hessian, hessian @ beta - deriv)\n",
        "\n",
        "    diff = beta - beta_new\n",
        "    diff_norm = np.sqrt(diff @ diff)\n",
        "    beta = beta_new\n",
        "\n",
        "    beta_hist.append(beta)\n",
        "    loglike_hist.append(calc_loglike(X, Y, beta))\n",
        "\n",
        "    if diff_norm < min_step_norm:\n",
        "      break\n",
        "    curr = time.time()\n",
        "    if curr - start > max_time:\n",
        "      break\n",
        "\n",
        "  ### Creating the coefficient dictionary.\n",
        "  beta_dict = {}\n",
        "  for i in range(p):\n",
        "    beta_dict[labels[i]] = beta[i]\n",
        "\n",
        "  return beta, beta_dict, beta_hist, loglike_hist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example**"
      ],
      "metadata": {
        "id": "VMzRcFbPYO4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_data(n: int):\n",
        "  X = np.random.normal(loc=0,scale=1,size=(n,3))\n",
        "  Y = X[:,0] + (X[:,1] * X[:,2])\n",
        "  Y = (Y > 1).astype(int)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "JTzEQwcGl5xG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = generate_fake_data(10)\n",
        "print(X)\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbHDRmasmf_c",
        "outputId": "d5d7a5d7-3437-4d20-f2ff-560651fb9dbe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.12777544 -0.94382539  0.34109503]\n",
            " [-1.97898473  0.3166541   2.13205413]\n",
            " [ 0.04992092  0.18904967 -0.06868558]\n",
            " [-0.3573216  -0.42572623 -1.1094144 ]\n",
            " [ 2.04911748 -0.25506455  0.50892927]\n",
            " [ 2.21879392  0.20278518  1.24085252]\n",
            " [ 1.19691487  1.00489141  0.69139772]\n",
            " [-0.20357283 -0.27923804 -0.26133622]\n",
            " [ 0.46453406 -1.22609239  0.73921278]\n",
            " [-0.81565596 -1.2438685   0.56181934]]\n",
            "[0 0 0 0 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = generate_fake_data(1000)\n",
        "interactions = [(0,1), (1,2), (2,0)]"
      ],
      "metadata": {
        "id": "GSd4z5WYnfhY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta1, beta1_dict, _, _ = fit_with_IWLS(X, Y, intercept=False, max_iterations=500)\n",
        "beta2, beta2_dict, _, _ = fit_with_IWLS(X, Y, intercept=True, additional_interactions=interactions, max_iterations=500)"
      ],
      "metadata": {
        "id": "6H-hwef8n6mP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(beta1_dict)\n",
        "print(beta2_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9JAZtr8omzP",
        "outputId": "15a1c79e-8250-4451-fd46-5710239c9dfb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'X0': 1.2858350777070253, 'X1': -0.17847408348876884, 'X2': 0.05173706992080961}\n",
            "{'X0': 4.010084935918466, 'X1': -0.0914026690534419, 'X2': 0.056193730148987486, 'X0X1': 0.016660571525063544, 'X1X2': 3.6006955731571835, 'X2X0': -0.08156258812843332, 'intercept': -3.8712434655312964}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9X8tXigpNEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}