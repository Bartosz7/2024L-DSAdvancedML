{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz6k-V1LpDjN",
        "outputId": "62d87d17-f40c-4e60-cf5d-26780027529a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HhAH-0XfqHJL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Erasing colinearities**"
      ],
      "metadata": {
        "id": "B1bVz2-jm20T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq"
      ],
      "metadata": {
        "id": "Y8W7nSqSukP1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_collinearity(columns, indices, threshold = 1e-10):\n",
        "  \"\"\"\n",
        "  Helper function, testing whether a certain subset of columns is collinear.\n",
        "  :param columns: the whole set of columns.\n",
        "  :param indices: indices belonging to the subset.\n",
        "  :param threshold: the value of determinant, going below which will be\n",
        "    considered being numerically collinear.\n",
        "  :return: True if collinear, False otherwise.\n",
        "  \"\"\"\n",
        "  used_columns = []\n",
        "  for index in indices:\n",
        "    used_columns.append(columns[index])\n",
        "\n",
        "  X = np.column_stack(used_columns)\n",
        "  XX = X.transpose() @ X\n",
        "  if np.linalg.det(XX) < threshold:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def remove_collinear(X):\n",
        "  \"\"\"\n",
        "  Removes the minimum number of columns to ensure the result matrix will be\n",
        "  full rank.\n",
        "  :param X: a numpy matrix one needs a non-collinear version of.\n",
        "  :return: a numpy matrix with collinearities removed and a set containing\n",
        "    indices of removed columns.\n",
        "  \"\"\"\n",
        "  columns = []\n",
        "  p = len(X[0])\n",
        "  for i in range(p):\n",
        "    columns.append(X[:,i])\n",
        "\n",
        "  columns_used = []\n",
        "  columns_stashed = set()\n",
        "  columns_removed = set()\n",
        "  for i in range(p):\n",
        "    columns_used.append(i)\n",
        "\n",
        "  heapq.heapify(columns_used)\n",
        "\n",
        "  last_removed = -1\n",
        "  while(True):\n",
        "    if len(columns_used) == 0:\n",
        "      break\n",
        "\n",
        "    if test_collinearity(columns, columns_used):\n",
        "      last_removed = heapq.heappop(columns_used)\n",
        "      columns_stashed.add(last_removed)\n",
        "    else:\n",
        "      if last_removed == -1:\n",
        "        # If the whole remaining subset is non-collinear, it's time to stop.\n",
        "\n",
        "        break\n",
        "      else:\n",
        "        # If removing a certain column made the subset non-collinear, it means\n",
        "        # that this column is a good candidate for removal.\n",
        "\n",
        "        columns_stashed.remove(last_removed)\n",
        "        columns_removed.add(last_removed)\n",
        "\n",
        "        # Returning stashed away columns back to the subset.\n",
        "        for index in columns_stashed:\n",
        "          columns_used.append(index)\n",
        "        heapq.heapify(columns_used)\n",
        "        columns_stashed.clear()\n",
        "        last_removed = -1\n",
        "\n",
        "  # Recreating the matrix\n",
        "  is_used = [False for i in range(p)]\n",
        "  for index in columns_used:\n",
        "    is_used[index] = True\n",
        "\n",
        "  columns_used = []\n",
        "  for i in range(p):\n",
        "    if is_used[i]:\n",
        "      columns_used.append(columns[i])\n",
        "\n",
        "  X_clean = np.column_stack(columns_used)\n",
        "  return X_clean, columns_removed\n"
      ],
      "metadata": {
        "id": "VsETljLgnCaL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heart Disease dataset** (https://archive.ics.uci.edu/dataset/45/heart+disease)"
      ],
      "metadata": {
        "id": "lWnUmg6Nt37V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's perform some EDA:\n",
        "\n",
        "# fetch dataset\n",
        "data_heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = data_heart_disease.data.features\n",
        "y = data_heart_disease.data.targets\n",
        "\n",
        "print(X.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJhgz3kTskyx",
        "outputId": "ca5416fe-5976-4045-bb1a-e7c0d99bc69e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age           int64\n",
            "sex           int64\n",
            "cp            int64\n",
            "trestbps      int64\n",
            "chol          int64\n",
            "fbs           int64\n",
            "restecg       int64\n",
            "thalach       int64\n",
            "exang         int64\n",
            "oldpeak     float64\n",
            "slope         int64\n",
            "ca          float64\n",
            "thal        float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the amount of missing values.\n",
        "print('missing values\\n')\n",
        "for name in X.columns:\n",
        "  print(name+': '+str(X[name].isnull().sum()))\n",
        "\n",
        "print('\\nAmount of data points:',len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td1grVCvqcqy",
        "outputId": "5be258b6-2410-4ee1-e7d7-69bd38c102c1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values\n",
            "\n",
            "age: 0\n",
            "sex: 0\n",
            "cp: 0\n",
            "trestbps: 0\n",
            "chol: 0\n",
            "fbs: 0\n",
            "restecg: 0\n",
            "thalach: 0\n",
            "exang: 0\n",
            "oldpeak: 0\n",
            "slope: 0\n",
            "ca: 4\n",
            "thal: 2\n",
            "\n",
            "Amount of data points: 303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one can see, the number of missing values is miniscule compared to the amount of data points we have, so not to complicate stuff too much, we can just remove the incomplete observations if need be."
      ],
      "metadata": {
        "id": "djdbBjcJvDWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of categories for each variable.\n",
        "print('different values present\\n')\n",
        "for name in X.columns:\n",
        "  print(name+': '+str(X[name].nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd-x2e44u_ST",
        "outputId": "cfe6177f-e961-4f3f-8a7c-cd0e6371544b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "different values present\n",
            "\n",
            "age: 41\n",
            "sex: 2\n",
            "cp: 4\n",
            "trestbps: 50\n",
            "chol: 152\n",
            "fbs: 2\n",
            "restecg: 3\n",
            "thalach: 91\n",
            "exang: 2\n",
            "oldpeak: 40\n",
            "slope: 3\n",
            "ca: 4\n",
            "thal: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the https://archive.ics.uci.edu/dataset/45/heart+disease page, 'cp', 'restecg', 'slope' and 'thal' are categorical variables that have more than 2 possible values, so they should be one-hot-encoded before building the model."
      ],
      "metadata": {
        "id": "u6cwF2uMwmGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, looking at the target variable:"
      ],
      "metadata": {
        "id": "B9tceEjixZHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YxIwWcZqoDo",
        "outputId": "0cb3255e-d37e-4355-b2de-ad9a49e08cb6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are 5 possible values for that. In accordance to the experiments mentioned on the dataset's page, we will transform the answers column to have two classes:\n",
        "\n",
        "0 <- no presence of heart disease (original values: 0)\n",
        "\n",
        "1 <- presence of heart disease (original values: 1, 2, 3 ,4)\n",
        "\n",
        "\n",
        "So finally, for a function that returns this dataset in a form palatable for model training:"
      ],
      "metadata": {
        "id": "hdNABKXpxflx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_heart_disease():\n",
        "  # fetch dataset\n",
        "  data_heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = data_heart_disease.data.features\n",
        "  y = data_heart_disease.data.targets\n",
        "\n",
        "  # removing missing variables\n",
        "  X = X.dropna()\n",
        "  y = y.loc[X.index]\n",
        "\n",
        "  # one-hot-encoding the detected multi-valued categorical variables\n",
        "  X = pd.get_dummies(X, columns=['cp', 'restecg', 'slope', 'thal'],\n",
        "                     drop_first=True, dtype=int)\n",
        "\n",
        "  # changing the format to numpy arrays\n",
        "  # (flattening is necessary for y as .values isn't smart enough to notice that\n",
        "  # y had only one column)\n",
        "  X = X.values\n",
        "  y = y.values.flatten()\n",
        "\n",
        "  # mapping the answers to {0,1}\n",
        "  y = (y==0)\n",
        "  y = y.astype(int)\n",
        "\n",
        "  # removing collinearities\n",
        "  X, _ = remove_collinear(X)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "NmPpUnPYyI3o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_heart_disease()"
      ],
      "metadata": {
        "id": "c0LSUsh85Cmj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDLeA08R5ksD",
        "outputId": "259ce399-c0bb-4626-fcaf-7f5bb54b9006"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parkinsons dataset** (https://archive.ics.uci.edu/dataset/174/parkinsons)"
      ],
      "metadata": {
        "id": "JgWvEfsJ-Igc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of the EDA, this time everything is noted on the page.\n",
        "There are no missing values, every feature is continous and the target variable is indeed a {0,1} binary value, so the only thing we need to do is to fetch the dataset and turn it into an appropriate numpy arrays."
      ],
      "metadata": {
        "id": "lZKBVDRO-UR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_parkinsons():\n",
        "  # fetch dataset\n",
        "  data_parkinsons = fetch_ucirepo(id=174)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = data_parkinsons.data.features\n",
        "  y = data_parkinsons.data.targets\n",
        "\n",
        "  # changing the format to numpy arrays\n",
        "  # (flattening is necessary for y as .values isn't smart enough to notice that\n",
        "  # y had only one column)\n",
        "  X = X.values\n",
        "  y = y.values.flatten()\n",
        "\n",
        "  # removing collinearities\n",
        "  X, _ = remove_collinear(X)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "hVGbZYAP-SfJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_parkinsons()"
      ],
      "metadata": {
        "id": "APVfU8Ao_you"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some columns have been removed\n",
        "print(len(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ljA_Kh5pXK",
        "outputId": "919735c2-1edd-473d-c059-45510d841310"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HCV dataset** (https://archive.ics.uci.edu/dataset/571/hcv+data)"
      ],
      "metadata": {
        "id": "3V7RjCPJAFGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's perform some EDA:\n",
        "\n",
        "# fetch dataset\n",
        "data_hcv = fetch_ucirepo(id=571)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = data_hcv.data.features\n",
        "y = data_hcv.data.targets\n",
        "\n",
        "print(X.dtypes)\n",
        "print(y.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsVeTRcYCY6k",
        "outputId": "f28da8d9-74d5-4ace-9a5e-7900971ff829"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age       int64\n",
            "Sex      object\n",
            "ALB     float64\n",
            "ALP     float64\n",
            "AST     float64\n",
            "BIL     float64\n",
            "CHE     float64\n",
            "CHOL    float64\n",
            "CREA    float64\n",
            "CGT     float64\n",
            "PROT    float64\n",
            "ALT     float64\n",
            "dtype: object\n",
            "Category    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(X['Sex']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFA1nAW3pynj",
        "outputId": "dc9c78c9-3971-4d32-a9ae-b9963af933bb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['f' 'm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the types, it's obvious that we'll need to map the 'Sex' column to {0,1}."
      ],
      "metadata": {
        "id": "jTXkEP8AkQca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the amount of missing values.\n",
        "print('missing values\\n')\n",
        "for name in X.columns:\n",
        "  print(name+': '+str(X[name].isnull().sum()))\n",
        "\n",
        "print('\\nAmount of data points:',len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao7Gb2o4j_-T",
        "outputId": "e760f903-8961-414d-ef91-18057ba53da9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values\n",
            "\n",
            "Age: 0\n",
            "Sex: 0\n",
            "ALB: 1\n",
            "ALP: 18\n",
            "AST: 0\n",
            "BIL: 0\n",
            "CHE: 0\n",
            "CHOL: 10\n",
            "CREA: 0\n",
            "CGT: 0\n",
            "PROT: 1\n",
            "ALT: 1\n",
            "\n",
            "Amount of data points: 615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that apart from the 'ALP' and 'CHOL' columns, there aren't that many missing values, so the plan seems to be removing the observations, where 'ALB', 'PROT' or 'ALT' is missing and then using some regressor to predict the values of 'ALP' and 'CHOL' when necessary."
      ],
      "metadata": {
        "id": "YE92H8I4k5wL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the https://archive.ics.uci.edu/dataset/571/hcv+data page, there are no categorical features, only the target variable is categorical, so there is no need for one-hot-encoding.\n",
        "\n",
        "Speaking of the target variable, it has 5 different values:"
      ],
      "metadata": {
        "id": "LUR9U4k-lyBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YleIV_0ml-cO",
        "outputId": "b731b744-f00c-400f-ca3e-8c68fd29bcc8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis',\n",
              "       '2=Fibrosis', '3=Cirrhosis'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus we'll group those categories into:\n",
        "\n",
        "0 <- all blood donors (original values: 0 and 0s)\n",
        "\n",
        "1 <- all the nasty stuff (orignal values: 1, 2 and 3)\n",
        "\n",
        "Now for the fetching function:"
      ],
      "metadata": {
        "id": "laqI4D69mlXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "4AvWYePZqEQe"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_hcv():\n",
        "  # fetch dataset\n",
        "  data_hcv = fetch_ucirepo(id=571)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = data_hcv.data.features\n",
        "  y = data_hcv.data.targets\n",
        "\n",
        "  # mapping the 'Sex' column to numeric values\n",
        "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
        "  # mapping the target variable to {0,1}\n",
        "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n",
        "                                           '0s=suspect Blood Donor': 0,\n",
        "                                           '1=Hepatitis': 1, '2=Fibrosis': 1,\n",
        "                                           '3=Cirrhosis': 1})\n",
        "\n",
        "  # removing rare missing values\n",
        "  X = X.dropna(subset=['ALB','PROT','ALT'])\n",
        "  y = y.loc[X.index]\n",
        "\n",
        "  # Regressing for the remaining missing values\n",
        "  X_for_lr = X.dropna()\n",
        "  y_for_lr1 = X_for_lr['ALP'].values\n",
        "  y_for_lr2 = X_for_lr['CHOL'].values\n",
        "  X_for_lr = X_for_lr.drop(columns=['ALP','CHOL']).values\n",
        "\n",
        "  lr = LinearRegression()\n",
        "\n",
        "  lr.fit(X_for_lr, y_for_lr1)\n",
        "  ALP_missing = X[X['ALP'].isna()]\n",
        "  data_for_ALP_predicting = ALP_missing.drop(columns=['ALP', 'CHOL']).values\n",
        "  ALP_predictions = lr.predict(data_for_ALP_predicting)\n",
        "  X.loc[X['ALP'].isna(), 'ALP'] = ALP_predictions\n",
        "\n",
        "  lr.fit(X_for_lr, y_for_lr2)\n",
        "  CHOL_missing = X[X['CHOL'].isna()]\n",
        "  data_for_CHOL_predicting = CHOL_missing.drop(columns=['ALP', 'CHOL']).values\n",
        "  CHOL_predictions = lr.predict(data_for_CHOL_predicting)\n",
        "  X.loc[X['CHOL'].isna(), 'CHOL'] = CHOL_predictions\n",
        "\n",
        "  # changing the format to numpy arrays\n",
        "  # (flattening is necessary for y as .values isn't smart enough to notice that\n",
        "  # y had only one column)\n",
        "  X = X.values\n",
        "  y = y.values.flatten()\n",
        "\n",
        "  # removing collinearities\n",
        "  X, _ = remove_collinear(X)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "BXYYTvpxnHWK"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_hcv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwXga6Le59__",
        "outputId": "785476c0-d604-49e3-e6b6-47947685613e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-8626b31a57f4>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
            "<ipython-input-63-8626b31a57f4>:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
            "<ipython-input-63-8626b31a57f4>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n",
            "<ipython-input-63-8626b31a57f4>:12: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pai3dyAQ656N",
        "outputId": "4165348e-5c15-41ee-e588-32ed6fb9718d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    }
  ]
}