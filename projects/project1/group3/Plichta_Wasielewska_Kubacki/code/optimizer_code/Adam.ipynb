{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Big datasets"
      ],
      "metadata": {
        "id": "ByH4NwdX0_Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading\n",
        "\n",
        "*   https://archive.ics.uci.edu/dataset/151/connectionist+bench+sonar+mines+vs+rocks\n",
        "*   https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
        "* https://archive.ics.uci.edu/dataset/52/ionosphere\n",
        "\n"
      ],
      "metadata": {
        "id": "VXW9HGv97xFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeUE4Al58SMu",
        "outputId": "e3a795a9-8f2f-436d-943e-60e73ef88816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_Niu-UDwDonj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connectionist Bench (Sonar, Mines vs. Rocks)\n",
        "\n",
        "\n",
        "*   Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number represents the energy within a particular frequency band, integrated over a certain period of time.  The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\n",
        "\n",
        "*   The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder).\n",
        "\n"
      ],
      "metadata": {
        "id": "wtZBgpug7_8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVZxRud67Old"
      },
      "outputs": [],
      "source": [
        "def fetch_sonar():\n",
        "  # fetch dataset\n",
        "  connectionist_bench_sonar_mines_vs_rocks = fetch_ucirepo(id=151)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = connectionist_bench_sonar_mines_vs_rocks.data.features\n",
        "  y = connectionist_bench_sonar_mines_vs_rocks.data.targets\n",
        "\n",
        "  missing_values_features = X.isnull().sum().sum()  # Checking is null with every feature, then sum\n",
        "  missing_values_targets = y.isnull().sum().sum()\n",
        "\n",
        "  #Mapping target classes R - rock to 0, M - mine to 1\n",
        "  y['class'] = y['class'].replace({'R': 0, 'M': 1})\n",
        "  target_counts = y['class'].value_counts()\n",
        "\n",
        "  if missing_values_features == 0 and missing_values_targets == 0:\n",
        "      print(\"No missing data in features and targets.\")\n",
        "  else:\n",
        "      print(f\"Missing data detected! Features missing values: {missing_values_features}, Targets missing values: {missing_values_targets}\")\n",
        "\n",
        "  print(\"Tail features sonar data\", X.tail)\n",
        "  print(\"Tail targets sonar data\", y.tail)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sonar_X, sonar_y = fetch_sonar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psBvJXNC9RuQ",
        "outputId": "4c897b70-b1c6-40f5-dd99-5caa82a705da"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing data in features and targets.\n",
            "Tail features sonar data <bound method NDFrame.tail of      Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
            "0        0.0200      0.0371      0.0428      0.0207      0.0954      0.0986   \n",
            "1        0.0453      0.0523      0.0843      0.0689      0.1183      0.2583   \n",
            "2        0.0262      0.0582      0.1099      0.1083      0.0974      0.2280   \n",
            "3        0.0100      0.0171      0.0623      0.0205      0.0205      0.0368   \n",
            "4        0.0762      0.0666      0.0481      0.0394      0.0590      0.0649   \n",
            "..          ...         ...         ...         ...         ...         ...   \n",
            "203      0.0187      0.0346      0.0168      0.0177      0.0393      0.1630   \n",
            "204      0.0323      0.0101      0.0298      0.0564      0.0760      0.0958   \n",
            "205      0.0522      0.0437      0.0180      0.0292      0.0351      0.1171   \n",
            "206      0.0303      0.0353      0.0490      0.0608      0.0167      0.1354   \n",
            "207      0.0260      0.0363      0.0136      0.0272      0.0214      0.0338   \n",
            "\n",
            "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute51  \\\n",
            "0        0.1539      0.1601      0.3109       0.2111  ...       0.0232   \n",
            "1        0.2156      0.3481      0.3337       0.2872  ...       0.0125   \n",
            "2        0.2431      0.3771      0.5598       0.6194  ...       0.0033   \n",
            "3        0.1098      0.1276      0.0598       0.1264  ...       0.0241   \n",
            "4        0.1209      0.2467      0.3564       0.4459  ...       0.0156   \n",
            "..          ...         ...         ...          ...  ...          ...   \n",
            "203      0.2028      0.1694      0.2328       0.2684  ...       0.0203   \n",
            "204      0.0990      0.1018      0.1030       0.2154  ...       0.0051   \n",
            "205      0.1257      0.1178      0.1258       0.2529  ...       0.0155   \n",
            "206      0.1465      0.1123      0.1945       0.2354  ...       0.0042   \n",
            "207      0.0655      0.1400      0.1843       0.2354  ...       0.0181   \n",
            "\n",
            "     Attribute52  Attribute53  Attribute54  Attribute55  Attribute56  \\\n",
            "0         0.0027       0.0065       0.0159       0.0072       0.0167   \n",
            "1         0.0084       0.0089       0.0048       0.0094       0.0191   \n",
            "2         0.0232       0.0166       0.0095       0.0180       0.0244   \n",
            "3         0.0121       0.0036       0.0150       0.0085       0.0073   \n",
            "4         0.0031       0.0054       0.0105       0.0110       0.0015   \n",
            "..           ...          ...          ...          ...          ...   \n",
            "203       0.0116       0.0098       0.0199       0.0033       0.0101   \n",
            "204       0.0061       0.0093       0.0135       0.0063       0.0063   \n",
            "205       0.0160       0.0029       0.0051       0.0062       0.0089   \n",
            "206       0.0086       0.0046       0.0126       0.0036       0.0035   \n",
            "207       0.0146       0.0129       0.0047       0.0039       0.0061   \n",
            "\n",
            "     Attribute57  Attribute58  Attribute59  Attribute60  \n",
            "0         0.0180       0.0084       0.0090       0.0032  \n",
            "1         0.0140       0.0049       0.0052       0.0044  \n",
            "2         0.0316       0.0164       0.0095       0.0078  \n",
            "3         0.0050       0.0044       0.0040       0.0117  \n",
            "4         0.0072       0.0048       0.0107       0.0094  \n",
            "..           ...          ...          ...          ...  \n",
            "203       0.0065       0.0115       0.0193       0.0157  \n",
            "204       0.0034       0.0032       0.0062       0.0067  \n",
            "205       0.0140       0.0138       0.0077       0.0031  \n",
            "206       0.0034       0.0079       0.0036       0.0048  \n",
            "207       0.0040       0.0036       0.0061       0.0115  \n",
            "\n",
            "[208 rows x 60 columns]>\n",
            "Tail targets sonar data <bound method NDFrame.tail of      class\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "..     ...\n",
            "203      1\n",
            "204      1\n",
            "205      1\n",
            "206      1\n",
            "207      1\n",
            "\n",
            "[208 rows x 1 columns]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-1d32617517ed>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y['class'] = y['class'].replace({'R': 0, 'M': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  UCI ML Breast Cancer Wisconsin (Diagnostic) dataset"
      ],
      "metadata": {
        "id": "RBcxOI9DD6dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = load_breast_cancer()\n",
        "print(data['data'])\n",
        "print(data.feature_names)\n",
        "\n",
        "df_describe = pd.DataFrame(data['data'])\n",
        "print(df_describe.describe())\n",
        "print(\"Target data is already prepared for binary classification. Example: \", data.target[[10, 50, 60]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JoNnCS_ESsg",
        "outputId": "0224fc1f-dece-4427-c626-1ed9a1086cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "               0           1           2            3           4   \\\n",
            "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
            "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
            "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
            "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
            "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
            "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
            "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
            "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
            "\n",
            "               5           6           7           8           9   ...  \\\n",
            "count  569.000000  569.000000  569.000000  569.000000  569.000000  ...   \n",
            "mean     0.104341    0.088799    0.048919    0.181162    0.062798  ...   \n",
            "std      0.052813    0.079720    0.038803    0.027414    0.007060  ...   \n",
            "min      0.019380    0.000000    0.000000    0.106000    0.049960  ...   \n",
            "25%      0.064920    0.029560    0.020310    0.161900    0.057700  ...   \n",
            "50%      0.092630    0.061540    0.033500    0.179200    0.061540  ...   \n",
            "75%      0.130400    0.130700    0.074000    0.195700    0.066120  ...   \n",
            "max      0.345400    0.426800    0.201200    0.304000    0.097440  ...   \n",
            "\n",
            "               20          21          22           23          24  \\\n",
            "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
            "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
            "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
            "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
            "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
            "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
            "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
            "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
            "\n",
            "               25          26          27          28          29  \n",
            "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
            "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
            "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
            "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
            "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
            "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
            "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
            "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
            "\n",
            "[8 rows x 30 columns]\n",
            "Target data is already prepared for binary classification. Example:  [0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = df_describe.corr()\n",
        "sns.heatmap(df_describe.corr(), cmap='viridis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "L6kfErEmRZw9",
        "outputId": "66b0ccce-ab07-4b62-a0d9-555b31e1009c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4wAAAKZCAYAAADzpqU+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACCuElEQVR4nO3deXxU1f3/8fdkm0AgAQxLANmMShQEBaGIEBcKLgXB1gWtIFqsC1aJIsYNcYv7ioJaEagKtl/RggsKCLUIgmERFUxAligk7CSQhMky5/eHP1NHhiQ3uScTxtfz8Th/5N6Zz+fMJDeTT86553iMMUYAAAAAAPxKRKg7AAAAAAConygYAQAAAABBUTACAAAAAIKiYAQAAAAABEXBCAAAAAAIioIRAAAAABAUBSMAAAAAICgKRgAAAABAUBSMAAAAAICgKBgBAAAAAEFRMAIAAABAHfvss880ePBgtW7dWh6PR++9916Vz1m8eLFOO+00eb1eJScna9q0adb7ScEIAAAAAHWssLBQ3bp104svvlitx2/evFkXXnihzj77bK1Zs0a33nqr/vKXv+jjjz+22k+PMcZYzQAAAAAAOCKPx6N3331XQ4cOPeJjxo8frw8++EDffPNNxbHLL79c+/fv17x586z1jRFGAAAAAHCBz+dTQUFBQPP5fK7EXrZsmQYMGBBwbNCgQVq2bJkr8Y8kymp0B/x5J1jPcfxb11uNv+GKKVbjS1KpKbOe4/Qnbraeo+TMA9Zz9G671Wr8Qc2+qfpBtfT4c5dbz9H8xaXWc7Rd3sh6jm1/62Q1ftJzW6zGl6S2sfus51h1fhvrOXKusvu9kCRPud34BztZTiDphOlF1nOUxnut5/j3tOpNpaqNHjPGWo3/5YinrcaXpAN18Pl90YN3WM+xp1ep9RzxiYVW4/+x0xqr8SXp3b+fZT1H/Fb7v6f+++7t1nPYUBd1xZFkTLlCEydODDg2YcIE3X///bWOnZeXp5YtWwYca9mypQoKClRcXKwGDRrUOkcw9aZgBAAAAICjWXp6utLS0gKOeb32/3lnEwUjAAAAALjA6/VaKxBbtWqlHTt2BBzbsWOH4uPjrY0uShSMAAAAAMKIX/6Q5ba5QEyfPn304YcfBhybP3+++vTpYzEri94AAAAAQJ07ePCg1qxZozVr1kj6aduMNWvWKCcnR9JP01tHjBhR8fjrr79emzZt0h133KHvvvtOL730kv75z39q7Fi793kzwggAAAAgbJSb0I0wOimuMjMzdfbZZ1d8/fO9jyNHjtS0adOUm5tbUTxKUseOHfXBBx9o7Nixeu6559S2bVv9/e9/16BBg9zqflAUjAAAAABQx8466ywZY454ftq0aUGfs3r1aou9OhwFIwAAAICw4deRizA457hg3L17t6ZOnaply5YpLy9P0k8r9pxxxhm6+uqr1bx5c9c7CQAAAACoe44Wvfnyyy91wgkn6Pnnn1dCQoL69++v/v37KyEhQc8//7w6d+6szMxMW30FAAAAANQhRyOMN998sy655BJNmTJFHo8n4JwxRtdff71uvvlmLVu2rNI4Pp9PPp8v4Fi0zy+vl0VbAQAAANRcKLfVCEeOKrSvvvpKY8eOPaxYlCSPx6OxY8dWLAtbmYyMDCUkJAS0R1/Y56QrAAAAAADLHI0wtmrVSitWrFDnzp2Dnl+xYoVatmxZZZz09PSKZWN/Fr3vNCddAQAAAIDDlFey8iicc1Qw3n777bruuuu0cuVKnXvuuRXF4Y4dO7Rw4UK9+uqrevLJJ6uM4/V65fV6A475i5iOCgAAAAD1iaOC8aabblJiYqKeeeYZvfTSSyovL5ckRUZGqkePHpo2bZouvfRSKx0FAAAAANQtx9tqXHbZZbrssstUWlqq3bt3S5ISExMVHR3teucAAAAAwAn2YXSX44LxZ9HR0UpKSnKzLwAAAACAeqTGBSMAAAAA1DfljDC6ipVmAAAAAABBUTACAAAAAIJiSioAAACAsMGiN+7yGFM/drY87umnrefYcMUUq/GTZ15vNb4kefzWU6jtwjLrOXb2tL+qbmmc3fieOrhymq2zn6TxlmLrOXIGNrSeo6R5udX4MbsjrcaXJI/dlyBJarHafpJ9yfbfqyjLP7amDv6dGr/V/veitKHHeo4dv7OeQnOGPmM1/pD3xlqNL0kev/3vReIq6ym0/wT7r8Nv+fqri8/v+O/t5zD2f9Vq1RT714YNu7a3CVnu5q23hSy3LYwwAgAAAAgb5fVjPCxscA8jAAAAACAoRhgBAAAAhI06uIPrN4URRgAAAABAUBSMAAAAAICgmJIKAAAAIGyUs62GqxhhBAAAAAAExQgjAAAAgLBRzgCjq1wfYfzhhx90zTXXVPoYn8+ngoKCgGbK7G8WDwAAAACoPtcLxr1792r69OmVPiYjI0MJCQkBbd/ChW53BQAAAABQC46npM6ZM6fS85s2baoyRnp6utLS0gKOdZ8yxWlXAAAAACAA+zC6y3HBOHToUHk8Hhlz5MnBHo+n0hher1derzfwOVHcTgkAAAAA9YnjKalJSUmaPXu2/H5/0LZq1Sob/QQAAACAKpXLE7IWjhwXjD169NDKlSuPeL6q0UcAAAAAwNHB8TzQcePGqbCw8Ijnk5OTtWjRolp1CgAAAABqws/YlascF4z9+vWr9HxcXJxSU1Nr3CEAAAAAQP3g+rYaAAAAAIDwwNKkAAAAAMJGuC4+EyqMMAIAAAAAgqo3I4wbrphiPUfyzOutxt843P5rKDVl1nOctutm6zka9dllPceZSZusxj8nfp3V+JJ014ujrOdo+u/vrec46+ly6zk233K81fjHPZ9lNb4ktfIWWM+xfGon6zl2dWtnPYffW/VjaqOwY6ndBJJaZNrP4WkWYz3HV398wXqO0/5xm9X4X131jNX4kpRv7H+///D9HdZzlHY4ZD1H82MOWI1/afsjr/bvlumvnWc9R6PtbE9/JIwwuosRRgAAAABAUBSMAAAAAICg6s2UVAAAAACoLb9hSqqbGGEEAAAAAATFCCMAAACAsMGiN+5ihBEAAAAAEBQjjAAAAADCRjljYq7i3QQAAAAABOW4YCwuLtaSJUu0bt3hm5YfOnRIM2bMcKVjAAAAAIDQclQwZmdnKyUlRf3791fXrl2Vmpqq3NzcivP5+fkaNWpUlXF8Pp8KCgoCms/nd957AAAAAPgFv/GErIUjRwXj+PHj1aVLF+3cuVNZWVlq3Lix+vbtq5ycHEdJMzIylJCQENAefWGfoxgAAAAAALscLXqzdOlSLViwQImJiUpMTNTcuXN14403ql+/flq0aJHi4uKqFSc9PV1paWkBx6L3neakKwAAAABwGLbVcJejEcbi4mJFRf2vxvR4PJo8ebIGDx6s1NRUZWdnVyuO1+tVfHx8QPN6WX8HAAAAAOoTRyOMnTt3VmZmplJSUgKOT5o0SZI0ZMgQ93oGAAAAAAgpR8N6w4YN08yZM4OemzRpkoYPHy5jjCsdAwAAAACnyk1EyFo4cvSq0tPT9eGHHx7x/EsvvSS/n9VOAQAAACAcOJqSCgAAAAD1md/5VvOoBO8mAAAAACAoRhgBAAAAhA221XAXI4wAAAAAgKDqzQhjqSmznsNjeT2eungN0R7737KIEuspVFAcaz3HgTK7OQ74G1iNL0kRpdZTyJTYT9Ispth6ju+j7f7/Kz7qkNX4kpQUvd96DjWwf+1F+qynkCwvyO3x2f9/qom0/x9wT5n9lctLZX+xu4hyu/Hr4jU09ERazxFZB5/fptD+3yEHGnqtxs8raWI1viRF2v/IUFQRC02ibtSbghEAAAAAaitct7cIFd5NAAAAAEBQjDACAAAACBt+Fr1xFSOMAAAAAICgKBgBAAAAAEExJRUAAABA2ChnTMxVvJsAAAAAgKAYYQQAAAAQNthWw12OC8b169friy++UJ8+fdS5c2d99913eu655+Tz+fTnP/9Z55xzTpUxfD6ffL5f7ezsM/J6WdEIAAAAAOoLR+X3vHnz1L17d91+++069dRTNW/ePPXv318bN27U1q1bNXDgQH366adVxsnIyFBCQkJAe/yF/TV9DQAAAAAgSfIrImQtHDl6VQ888IDGjRunPXv26PXXX9cVV1yh0aNHa/78+Vq4cKHGjRunRx99tMo46enpys/PD2h33Nykpq8BAAAAAGCBo4Lx22+/1dVXXy1JuvTSS3XgwAH96U9/qjh/5ZVXau3atVXG8Xq9io+PD2hMRwUAAACA+sXxPYwez0+FXUREhGJjY5WQkFBxrnHjxsrPz3evdwAAAADgQLlhIMpNjkYYO3TooA0bNlR8vWzZMrVr167i65ycHCUlJbnXOwAAAABAyDgaYbzhhhtUXl5e8XWXLl0Czn/00UfVWiUVAAAAAGwoD9PFZ0LFUcF4/fXXV3r+kUceqVVnAAAAAAD1B+U3AAAAACAox4veAAAAAEB95TeMibmJdxMAAAAAEJTHGGNC3QlJOiXtGes5mn5XajX+7lOircaXpIgS6yn01R2Tree4cstZ1nOs3dHaavzYGLs/T5IUIfuXpze6zHqOvJX2V08+5lu779Xek+wv0R1ZbD2FSprY/5ny+K2nUPQBu9+PQ63Kq35QLcVtjrSeozSh6sfUVvQB+zkSvrf7Q7Wvs/3/n9fF5/dt17xjPcfDq8+3nqPcZ3cCXGwjn9X4knRodwPrObyJ9j80si6+z3oOG97a2Dtkua9IXh6y3LYwwggAAAAACIp7GAEAAACEjXJjf1bQbwkjjAAAAACAoCgYAQAAAABBMSUVAAAAQNjwMybmKt5NAAAAAEBQrowwGmPk8XBzKQAAAIDQKjeMibnJlXfT6/Vq/fr1boQCAAAAgN+MF198UR06dFBsbKx69+6tFStWVPr4Z599VieeeKIaNGigY489VmPHjtWhQ4es9c/RCGNaWlrQ4+Xl5Xr00Ud1zDHHSJKefvrp2vcMAAAAAMLY22+/rbS0NE2ZMkW9e/fWs88+q0GDBikrK0stWrQ47PFvvfWW7rzzTk2dOlVnnHGGsrOzdfXVV8vj8VirwRwVjM8++6y6deumJk2aBBw3xmj9+vWKi4ur1tRUn88nn88XcMxfVqaIKNbgAQAAAFBzfh09t8o9/fTTGj16tEaNGiVJmjJlij744ANNnTpVd95552GPX7p0qfr27asrrrhCktShQwcNHz5cy5cvt9ZHR1NSH3nkEeXn5+vee+/VokWLKlpkZKSmTZumRYsW6dNPP60yTkZGhhISEgLari8X1PhFAAAAAECo+Xw+FRQUBLRfD5T9rKSkRCtXrtSAAQMqjkVERGjAgAFatmxZ0OecccYZWrlyZcW01U2bNunDDz/UBRdc4P6L+blPTh5855136u2339YNN9yg22+/XaWlpTVKmp6ervz8/IDW/PQBVT8RAAAAACpRbiJC1oINjGVkZATt5+7du1VeXq6WLVsGHG/ZsqXy8vKCPueKK67QAw88oDPPPFPR0dE67rjjdNZZZ+muu+5y/X38meNFb04//XStXLlSu3btUs+ePfXNN984XiHV6/UqPj4+oDEdFQAAAMDRLNjAWHp6umvxFy9erEceeUQvvfSSVq1apdmzZ+uDDz7Qgw8+6FqOX6tRldaoUSNNnz5ds2bN0oABA1ReXu52vwAAAADgqOL1euX1eqv12MTEREVGRmrHjh0Bx3fs2KFWrVoFfc69996rq666Sn/5y18kSV27dlVhYaGuu+463X333YqIcH9LkVpFvPzyy5WZmanZs2erffv2bvUJAAAAAGqkXBEha07ExMSoR48eWrhwYcUxv9+vhQsXqk+fPkGfU1RUdFhRGBkZKemnhUhtqPU80LZt26pt27Zu9AUAAAAAfjPS0tI0cuRI9ezZU7169dKzzz6rwsLCilVTR4wYoTZt2lTcBzl48GA9/fTTOvXUU9W7d29t3LhR9957rwYPHlxROLqNGwcBAAAAhA2/OXq21bjsssu0a9cu3XfffcrLy1P37t01b968ioVwcnJyAkYU77nnHnk8Ht1zzz3atm2bmjdvrsGDB+vhhx+21kcKRgAAAAAIkTFjxmjMmDFBzy1evDjg66ioKE2YMEETJkyog579/5x1lgkAAAAALHN6LyEqx7sJAAAAAAiq3owwlpx5wHqOnY0aW43fqM8uq/ElqaA41nqOK7ecZT3Hmx0WW8/xRVKZ1fjbyppajS9JU3JSrecoLKne0s+1EZF80H6ONQ2txm98yl6r8SVp37446zmaLLX/O+QP139mPceC3BOtxm/dqMBqfEla/+Px1nNEdLb/2RoVU2o9x15vM6vxW/XbZjW+JO0osPs3iCS9srmf9RxTer1hPUdeWYL1HLY98s351nP0PXaz9RyAVI8KRgAAAACoLb9hEqWbeDcBAAAAAEExwggAAAAgbJTr6NlW42jACCMAAAAAICgKRgAAAABAUExJBQAAABA2WPTGXbybAAAAAICgGGEEAAAAEDZY9MZdtSoYCwsL9c9//lMbN25UUlKShg8frmOOOabK5/l8Pvl8voBj/tIyRURTvwIAAABAfeFoSupJJ52kvXv3SpJ++OEHdenSRWPHjtX8+fM1YcIEnXTSSdq8eXOVcTIyMpSQkBDQ9s7+b81eAQAAAAD8f34TEbIWjhy9qu+++05lZWWSpPT0dLVu3Vpbt27VihUrtHXrVp1yyim6++67q4yTnp6u/Pz8gNbs4n41ewUAAAAAACtqPAd02bJlmjJlihISEiRJjRo10sSJE3X55ZdX+Vyv1yuv1xtwjOmoAAAAAFC/OK7SPJ6fbiI9dOiQkpKSAs61adNGu3btcqdnAAAAAOBQeZhODQ0VxwXjueeeq6ioKBUUFCgrK0tdunSpOLd169ZqLXoDAAAAAKj/HBWMEyZMCPi6UaNGAV/PnTtX/fpxLyIAAACA0PCzrYaralUw/toTTzxRq84AAAAAAOoPJvgCAAAAAIJiaVIAAAAAYYNFb9zFuwkAAAAACKrejDD2brvVeo7PN3Sp+kG1cGbSJqvxJelAWaz1HMu2dbCe44ukMus5fue1++O9ISLXanxJ+nFfE+s5SnMaVf2gWura0/61kRvTyWr8E5vttBpfkvY3amA9xy5fe+s5thTZXy27azO7119dLJgQWWQ9hYqLoq3n6N/ue+s5Pm3QzGr83zXfYjW+JOU2TrCe47PsZOs5VrQ9znqOsxutsxr/gN/+31JFe+3/Pl/q6WA9h3raT2GD37DojZsYYQQAAAAABFVvRhgBAAAAoLbKGRNzFe8mAAAAACAoCkYAAAAAQFBMSQUAAAAQNlj0xl2MMAIAAAAAgmKEEQAAAEDY8DMm5ireTQAAAABAUI4KxlWrVmnz5s0VX//jH/9Q3759deyxx+rMM8/UrFmzXO8gAAAAACA0HBWMo0aN0vfffy9J+vvf/66//vWv6tmzp+6++26dfvrpGj16tKZOnVplHJ/Pp4KCgoBWXlJes1cAAAAAAP9fufGErIUjR/cwbtiwQccff7wk6aWXXtJzzz2n0aNHV5w//fTT9fDDD+uaa66pNE5GRoYmTpwYcOyUv3RX99GnOekOAAAAAMAiRyOMDRs21O7duyVJ27ZtU69evQLO9+7dO2DK6pGkp6crPz8/oHUd2c1JVwAAAADgMH7jCVkLR44KxvPPP1+TJ0+WJKWmpur//u//As7/85//VHJycpVxvF6v4uPjA1pkTKSTrgAAAAAALHM0JfWxxx5T3759lZqaqp49e+qpp57S4sWLlZKSoqysLH3xxRd69913bfUVAAAAACrlN2wE4SZH72br1q21evVq9enTR/PmzZMxRitWrNAnn3yitm3b6vPPP9cFF1xgq68AAAAAgDrkaIRRkpo0aaJHH31Ujz76qI3+AAAAAADqCccFIwAAAADUV+UKz8VnQoUJvgAAAACAoBhhBAAAABA2wnV7i1BhhBEAAAAAEFS9GWEc1Owb6zmWmi5W458Tv85qfEk64G9gPcfqXW2s59hW1tR6jg0RuVbjHx/dyGp8SSr12b9EG221/1+4Nv33W8+xu9BvNX4L7wGr8SWpcZTPeo6C/HbWcyz/ob31HCVF0Vbjn9g+z2p8SfLmG+s5SjbFWs9x7u/sf/Yt8ne3Gr9/4++sxpekvNgm1nN85ql6L+za+u5gK+s5yi1viTAsYZXV+JLkKbE/JlO0rbH1HIBUjwpGAAAAAKgt9mF0F+8mAAAAACAoRhgBAAAAhA0/22q4ihFGAAAAAEBQjDACAAAACBvlbKvhKkYYAQAAAABBUTACAAAAAIJiSioAAACAsMG2Gu5y9G7efPPN+u9//1vrpD6fTwUFBQGt1Gd3020AAAAAgDOOCsYXX3xRZ511lk444QQ99thjysvLq1HSjIwMJSQkBLQ5L2+vUSwAAAAA+JnfeELWwpHj8dpPPvlEF1xwgZ588km1a9dOF110kd5//335/dUfIUxPT1d+fn5AG/LX1k67AgAAAACwyHHB2LVrVz377LPavn273njjDfl8Pg0dOlTHHnus7r77bm3cuLHKGF6vV/Hx8QEt2stcYwAAAACoT2pcpUVHR+vSSy/VvHnztGnTJo0ePVpvvvmmTjzxRDf7BwAAAADV5pcnZC0cuTKs165dO91///3avHmz5s2b50ZIAAAAAECIOdpWo3379oqMjDzieY/Ho9///ve17hQAAAAA1ES4Lj4TKo4Kxs2bN9vqBwAAAACgnnFUMAIAAABAfeY3LKbpJt5NAAAAAEBQFIwAAAAAgKCYkgoAAAAgbLDojbs8xhgT6k5IUvebn7Gew5tv96UWNbf/wxlRaj2FYs7fZT1HfOwh6zl+3NfEavxSn/3/t2w8e5r1HCd8NsJ6Dm2Js54i3vKaXPnH2f9V6d1n/3dIpM96Ch3oUmI9R0R+tNX4/gblVuNLkqdhmf0cu7zWc8Rts/9zG7vX7vVX2KoOrj37H3s60M3+tRcZa//nttz252sd/OV7Qdevref48Jsu1nNsGXGn9Rw2XLL0hpDl/tcZk0OW2xZGGAEAAACEDb8YYXQT9zACAAAAAIKiYAQAAAAABMWUVAAAAABhg0Vv3MUIIwAAAAAgKEYYAQAAAIQNRhjdxQgjAAAAACAoxwXjpEmTNGLECM2aNUuS9I9//EMnnXSSOnfurLvuuktlZfb35wEAAAAA2OdoSupDDz2kxx9/XAMHDtTYsWO1detWPfHEExo7dqwiIiL0zDPPKDo6WhMnTqw0js/nk88XuHu0v7xMEZHMkAUAAABQc0xJdZejCm3atGmaNm2aLr74Yn311Vfq0aOHpk+friuvvFKS1LlzZ91xxx1VFowZGRmHPabl6QPVqvd5DrsPAAAAALDF0ZTU7du3q2fPnpKkbt26KSIiQt27d684f9ppp2n79u1VxklPT1d+fn5Aa9FzgLOeAwAAAMCv+I0nZC0cOSoYW7VqpXXr1kmSNmzYoPLy8oqvJenbb79VixYtqozj9XoVHx8f0JiOCgAAAAD1i6Mq7corr9SIESN00UUXaeHChbrjjjt0++23a8+ePfJ4PHr44Yf1pz/9yVZfAQAAAKBSfoXnSF+oOCoYJ06cqAYNGmjZsmUaPXq07rzzTnXr1k133HGHioqKNHjwYD344IO2+goAAAAAqEOOCsaIiAjdddddAccuv/xyXX755a52CgAAAAAQetw4CAAAACBshOviM6HiaNEbAAAAAMBvByOMAAAAAMIGI4zuYoQRAAAAAELkxRdfVIcOHRQbG6vevXtrxYoVlT5+//79uummm5SUlCSv16sTTjhBH374obX+1ZsRxuYvLrWew5zZ3Wr8pv/+3mp8STIlpdZzFA5Jsp+jxGs9R2lOI6vxG221/9+rEyJHWM+R3X+G9RxnvTnaeo78jnZ/nbX80liNL0lxPxZZz5E9yv6117JVvvUcOyPjrcaP2BtjNb4k6ZD9/9kO6PeV9Rw5A+2/VyWnHmc1fuKCPKvxJUklJdZTbD6zlfUcJYfs/+kYsd9ujrgt9q+9eftOs57jxoHzreeQ7qyDHL9tb7/9ttLS0jRlyhT17t1bzz77rAYNGqSsrKyg+9uXlJTo97//vVq0aKH/+7//U5s2bbR161Y1adLEWh/rTcEIAAAAALV1NE1JffrppzV69GiNGjVKkjRlyhR98MEHmjp1qu688/CCferUqdq7d6+WLl2q6OhoSVKHDh2s9pEpqQAAAADgAp/Pp4KCgoDm8/mCPrakpEQrV67UgAEDKo5FRERowIABWrZsWdDnzJkzR3369NFNN92kli1bqkuXLnrkkUdUXl5u5fVIFIwAAAAAwojfeELWMjIylJCQENAyMjKC9nP37t0qLy9Xy5YtA463bNlSeXnBp8pv2rRJ//d//6fy8nJ9+OGHuvfee/XUU0/poYcecv19/BlTUgEAAADABenp6UpLSws45vW6t36A3+9XixYt9MorrygyMlI9evTQtm3b9MQTT2jChAmu5fklCkYAAAAAYcOE8B5Gr9db7QIxMTFRkZGR2rFjR8DxHTt2qFWr4ItYJSUlKTo6WpGRkRXHUlJSlJeXp5KSEsXEuL8QGVNSAQAAAKCOxcTEqEePHlq4cGHFMb/fr4ULF6pPnz5Bn9O3b19t3LhRfr+/4lh2draSkpKsFIsSBSMAAAAAhERaWppeffVVTZ8+XevXr9cNN9ygwsLCilVTR4wYofT09IrH33DDDdq7d69uueUWZWdn64MPPtAjjzyim266yVofHU9Jzc3N1eTJk7VkyRLl5uYqIiJCnTp10tChQ3X11VcHDI8CAAAAQF3y6+jZVuOyyy7Trl27dN999ykvL0/du3fXvHnzKhbCycnJUUTE/8b4jj32WH388ccaO3asTjnlFLVp00a33HKLxo8fb62PjgrGzMxMDRgwQMnJyWrQoIE2bNigK664QiUlJbr99ts1depUzZs3T40bN640js/nO2x5Wb8pV4SHYhMAAADAb8eYMWM0ZsyYoOcWL1582LE+ffroiy++sNyr/3E0JfXWW2/V2LFjlZmZqf/+97+aNm2asrOzNWvWLG3atElFRUW65557qowTbLnZzfquxi8CAAAAAKTQbqsRjhwVjKtWrdJVV11V8fUVV1yhVatWaceOHWratKkef/xx/d///V+VcdLT05Wfnx/QOqqz894DAAAAAKxxNCW1RYsWys3NVadOnST9tORrWVmZ4uPjJUnHH3+89u7dW2WcYMvNMh0VAAAAAOoXRwXj0KFDdf311+uJJ56Q1+vVgw8+qNTUVDVo0ECSlJWVpTZt2ljpKAAAAABUJZT7MIYjRwXjQw89pNzcXA0ePFjl5eXq06eP3njjjYrzHo9HGRkZrncSAAAAAFD3HBWMjRo10ttvv61Dhw6prKxMjRo1Cjg/cOBAVzsHAAAAAE6E6+IzoeJ4H0ZJio2NdbsfAAAAAIB6pkYFIwAAAADUR9zD6C5H22oAAAAAAH47KBgBAAAAAEExJRUAAABA2GDRG3fVm4Kx7fJGVT+olj7/uKHV+Gc9XW41viQ1iym2nuP/PkqyniMi+aD1HF17brIav03//VbjS9InC3pYz3HWm6Ot51j88qvWc3R97gar8ec985zV+JJUZMqs5xj0xDjrOXYVH2M9R0SZ3T8GYjsWWI0vSWZVgvUcS97rbj3HoE+XW88x/02v1fjnPZ1rNb4kxUfa//zOnXK89Rz+1tZTqKSZ3b+nPGfvsxpfkpq918R6jndXDLCe4463rKfAUaDeFIwAAAAAUFvGhLoH4YV7GAEAAAAAQVEwAgAAAACCYkoqAAAAgLDhF4veuKlGBWNJSYnee+89LVu2THl5eZKkVq1a6YwzztBFF12kmJgYVzsJAAAAAKh7jqekbty4USkpKRo5cqRWr14tv98vv9+v1atXa8SIETr55JO1ceNGG30FAAAAgEoZ4wlZC0eORxhvuOEGde3aVatXr1Z8fHzAuYKCAo0YMUI33XSTPv74Y9c6CQAAAACoe44Lxs8//1wrVqw4rFiUpPj4eD344IPq3bu3K50DAAAAACf8YTrSFyqOC8YmTZpoy5Yt6tKlS9DzW7ZsUZMmTSqN4fP55PP5Ao6Vl5QrMibSaXcAAAAAAJY4vofxL3/5i0aMGKFnnnlGa9eu1Y4dO7Rjxw6tXbtWzzzzjK6++mpdd911lcbIyMhQQkJCQFs7bW2NXwQAAAAAwH2ORxgfeOABxcXF6YknntBtt90mj+enIV9jjFq1aqXx48frjjvuqDRGenq60tLSAo6N+XqM064AAAAAQABjQt2D8FKjbTXGjx+v8ePHa/PmzQHbanTs2LFaz/d6vfJ6vQHHmI4KAAAAAPVLjQrGn3Xs2PGwIvGHH37QhAkTNHXq1Fp1DAAAAACcCtftLULF8T2MVdm7d6+mT5/udlgAAAAAQB1zPMI4Z86cSs9v2rSpxp0BAAAAANQfjgvGoUOHyuPxyFRyN+nPC+EAAAAAQF1iSqq7HE9JTUpK0uzZs+X3+4O2VatW2egnAAAAAKCOOS4Ye/TooZUrVx7xfFWjjwAAAABgi994QtbCkeMpqePGjVNhYeERzycnJ2vRokW16hQAAAAAIPQ8pp4MBw7s86D1HNlXN7Aa//gZh6zGlyR/tOsL2x7mYLtY6zkiSu3/2JXH2P0vT3Sh32p8SSpubn9/0nJv1Y+prTK7l54k6etbJluN3+WFG6zGl6QGu6yn0J7Ty6znaJBTqx2bqiXS8q9bfx1cF4WdSq3n8OZGW8/R4d8HrOfI+qvdz6UTX7X/+W2i7P8+N5H2Rzc8pfY/+/wxdv/WiTpYYjW+JKnc/t85pYn2P1w/nX+n9Rw2nPTe/SHLvW5o6HLbYr/6AAAAAAAclSgYAQAAAABB2Z83BAAAAAB1hG013MUIIwAAAAAgKEYYAQAAAIQNRhjd5foI444dO/TAAw+4HRYAAAAAUMdcLxjz8vI0ceJEt8MCAAAAAOqY4ympa9eurfR8VlZWjTsDAAAAALVRLzaZDyOOC8bu3bvL4/HImMO/FT8f93gqnzfs8/nk8/kCjvn9ZYqI4JZKAAAAAKgvHE9JbdasmV599VVt3rz5sLZp0ya9//77VcbIyMhQQkJCQNu87bMavQAAAAAA+JkxnpC1cOR4SK9Hjx7avn272rdvH/T8/v37g44+/lJ6errS0tICjl38+6ecdgUAAAAAYJHjgvH6669XYWHhEc+3a9dOr7/+eqUxvF6vvF5vwDGmowIAAACoNW5idJXjKm3YsGGVnm/atKlGjhxZ4w4BAAAAAOoH17fV+OGHH3TNNde4HRYAAAAAUMdcLxj37t2r6dOnux0WAAAAAKrEojfucjwldc6cOZWe37RpU407AwAAAACoPxwXjEOHDj3iPow/q2ofRgAAAACwoYoNG+CQ4ympSUlJmj17tvx+f9C2atUqG/0EAAAAANQxxwVjjx49tHLlyiOer2r0EQAAAABwdHA8JXXcuHGV7sOYnJysRYsW1apTAAAAAFAT4br4TKg4Lhj79etX6fm4uDilpqY67kjSc1scP8epLfO7WI1/3PNZVuNLUnzUIes53v3oDOs5Gp+y13qOE5vttBq/hfeA1fiS9P7C063naPml/RkB8555znqOLi+MtRr/m5snW40vSTll9n+mLnr8Dus58k8ttZ7DUxhpNX7icXusxpek8szm1nN4yqynUKfJG6zn2P72aVbjn/LykWdOuSXKU249x8dT+lrPkX+i/c8Mf7zdH9zmrQ5ajS9J/nftX98RpczoQ91wXDACAAAAQL3FCKOrXN+HEQAAAAAQHigYAQAAAABBMSUVAAAAQNhgwwZ31XiE8ccff9TBg4ffNFxaWqrPPvusVp0CAAAAAISe44IxNzdXvXr1Uvv27dWkSRONGDEioHDcu3evzj77bFc7CQAAAADVYkLYwpDjgvHOO+9URESEli9frnnz5mndunU6++yztW/fvorHGMaBAQAAAOCo5/gexgULFujdd99Vz549JUmff/65LrnkEp1zzjlauHChJMnjYSlbAAAAAHXPsK2GqxyPMObn56tp06YVX3u9Xs2ePVsdOnTQ2WefrZ07q94s3efzqaCgIKCVl9jf0BYAAAAAUH2OC8ZOnTpp7dq1AceioqL0r3/9S506ddIf/vCHKmNkZGQoISEhoH09/SunXQEAAAAAWOS4YDz//PP1yiuvHHb856Kxe/fuVd7DmJ6ervz8/IDWdWQ3p10BAAAAgEAseuMqx/cwPvzwwyoqKgoeLCpK77zzjrZt21ZpDK/XK6/XG3AsMibSaVcAAAAAABY5HmGMiopSfHz8Ec/n5uZq4sSJteoUAAAAANSEMZ6QtXDkuGCsyt69ezV9+nS3wwIAAAAA6pjjKalz5syp9PymTZtq3BkAAAAAQP3huGAcOnSoPB5PpQvbsA8jAAAAgJAI08VnQsXxlNSkpCTNnj1bfr8/aFu1apWNfgIAAAAA6pjjgrFHjx5auXLlEc9XNfoIAAAAAPZ4QtjCj+MpqePGjVNhYeERzycnJ2vRokW16hQAAAAAIPQcF4z9+vWr9HxcXJxSU1Mdd6Rt7D7Hz3HKU243fitvgd0EkpKi91vPEVlsPYX27YuznmN/owZW4zeO8lmNL0neffb/UxX3Y/B9Vd1UZMqs52iwy278nLIDdhNIahfV2HoOb779GSAxudHWc9j+fb4zt4ndBJKa5VpPIU8dTPg5tg4+v207Jtr+9d26Dj6/P6mD73dUof3PpRKv64v4B8Yvt7/3t9dXB79rD/qt5zhqMdnRVXavSAAAAADAUYuCEQAAAAAQlOMpqQAAAABQbzEl1VWMMAIAAAAAgmKEEQAAAED4MOG5vUWo1Khg3LNnj9auXatu3bqpWbNm2r17t1577TX5fD5dcsklSklJcbufAAAAAIA65rhgXLFihQYOHKiCggI1adJE8+fP1yWXXKKoqCj5/X49+uijWrJkiU477TQb/QUAAAAA1BHH9zDefffduuSSS5Sfn6+77rpLQ4cO1bnnnqvs7Gxt3LhRl19+uR588EEbfQUAAACAShkTuhaOHBeMK1euVFpamho3bqxbbrlF27dv1+jRoyvOjxkzRl9++WWlMXw+nwoKCgJaWYnlXZgBAAAAAI44LhhLSkrUoEEDSVJ0dLQaNmyoxMTEivOJiYnas2dPpTEyMjKUkJAQ0Ja+lu20KwAAAAAQyISwhSHHBeOxxx6rTZs2VXw9a9YsJSUlVXydm5sbUEAGk56ervz8/IB2xrUnOO0KAAAAABzVXnzxRXXo0EGxsbHq3bu3VqxYUa3nzZo1Sx6PR0OHDrXaP8cF4+WXX66dO3dWfH3hhRdWjDhK0pw5c9SrV69KY3i9XsXHxwe0qJhIp10BAAAAgEDGE7rm0Ntvv620tDRNmDBBq1atUrdu3TRo0KCAeiuYLVu26Pbbb1e/fv1q+i5Vm+OCccKECbr88suPeP7uu+/WW2+9VatOAQAAAEC4e/rppzV69GiNGjVKJ510kqZMmaKGDRtq6tSpR3xOeXm5rrzySk2cOFGdOnWy3kfHBWNV9uzZoxtuuMHtsAAAAABQrwVb3NPn8wV9bElJiVauXKkBAwZUHIuIiNCAAQO0bNmyI+Z44IEH1KJFC1177bWu9z8Y1wvGvXv3avr06W6HBQAAAIAqeUzoWrDFPTMyMoL2c/fu3SovL1fLli0Djrds2VJ5eXlBn7NkyRK99tprevXVV11/344kyukT5syZU+n5Xy6IAwAAAAC/Fenp6UpLSws45vV6XYl94MABXXXVVXr11VerXGTUTY4LxqFDh8rj8chUsjOlx+P8hk8AAAAAqLUQbm/h9XqrXSAmJiYqMjJSO3bsCDi+Y8cOtWrV6rDHf//999qyZYsGDx5ccczv90uSoqKilJWVpeOOO64WvQ/O8ZTUpKQkzZ49W36/P2hbtWqV650EAAAAgHASExOjHj16aOHChRXH/H6/Fi5cqD59+hz2+M6dO+vrr7/WmjVrKtqQIUN09tlna82aNTr22GOt9NPxCGOPHj20cuVKXXTRRUHPVzX6CAAAAACQ0tLSNHLkSPXs2VO9evXSs88+q8LCQo0aNUqSNGLECLVp00YZGRmKjY1Vly5dAp7fpEkTSTrsuJscF4zjxo1TYWHhEc8nJydr0aJFteoUAAAAANRIDfZDDJXLLrtMu3bt0n333ae8vDx1795d8+bNq1gIJycnRxERrq9T6ojH1JPhwPPb3Gw9x8Fe7a3Gb7R6m9X4kqQGsdZTZF3X3HqOhI32L+RIn90fbW++/UunoL39XxAFncus52jyjeP/TTmWf7Ld15Hwtf3XUBc/U188NsV6juRZ11vPEX3A7u+Qsjj734uyJvavPU+k/deRMn6r9RylJ7a1Gj/6++CrEbqqDj6/s/96+D1PbuvwYfDtAY4mkUWl9pP47afYe0oj6zky/55W9YPqoQ4vPxmy3Fv+envIctti/y8gAAAAAKgr9WI4LHyEdnwTAAAAAFBvMcIIAAAAIHwwwugqRhgBAAAAAEG5VjB26tRJGzZscCscAAAAACDEHE9Jff7554Mez8nJ0euvv65WrX5aoetvf/tb7XoGAAAAAE4xJdVVjgvGW2+9VW3atFFUVOBT/X6/ZsyYoejoaHk8HgpGAAAAADjKOS4Yr7vuOi1fvlxvvfWWUlJSKo5HR0frk08+0UknneRqBwEAAACg2oz9/b5/SxzfwzhlyhTdd999GjRokCZNmlSjpD6fTwUFBQHNb8prFAsAAAAAYEeNFr0ZNmyYli1bpnfffVfnn3++8vLyHD0/IyNDCQkJAe37A5k16QoAAAAAwJIar5Lapk0bLViwQP3799epp54qY6p/d2l6erry8/MD2nGNe9a0KwAAAAAgSfKY0LVw5Pgexl/yeDxKT0/XwIEDtWTJEiUlJVXreV6vV16vN+BYhCeyNl0BAAAAALjMlX0Ye/TooVtuuUVNmzbVDz/8oGuuucaNsAAAAADgjAlhC0OuFIy/tHfvXk2fPt3tsAAAAACAOuZ4SuqcOXMqPb9p06YadwYAAAAAUH84LhiHDh0qj8dT6SI3Hg97nwAAAADA0c7xlNSkpCTNnj1bfr8/aFu1apWNfgIAAAAA6pjjgrFHjx5auXLlEc9XNfoIAAAAALawrYa7HE9JHTdunAoLC494Pjk5WYsWLapVpwAAAAAAoee4YOzXr1+l5+Pi4pSamuq4IzlXdXL8HKc85Xbj7+rWzm4CSZE+6ynk8dv/98gfrv/Meo4tRcdYjb/8h/ZW40tSycEY6zlatsq3nmNXsd3vhSQ1yKnVtrJVyj+11Gp8SYrJjbaeI3nW9dZzbLx8ivUcUwtaWo3/Y0kzq/EladrSM63nuOfMudZzPDPyYus5oo/8f2pXFJ/b0W4CSdEHraeQd7/9HO0ey7aeY39JQ6vxv9levX3Da8OTHWc9R+vfbbOe46hlWE/FTa5vqwEAAAAACA8UjAAAAACAoOzO4QIAAACAuhSmi8+ECiOMAAAAAICgGGEEAAAAED4YYXRVrQtGY4wWL16sjRs3KikpSYMGDVJ0tP2V/gAAAAAAdjkuGC+44ALNnDlTCQkJ2rt3ry644AKtWLFCiYmJ2rNnj0444QR99tlnat68uY3+AgAAAMAReRhhdJXjexjnzZsnn++nzQDvueceHThwQN9//7127typrVu3Ki4uTvfdd5/rHQUAAAAA1K1aLXrz6aefKiMjQx07/rThbdu2bfXYY4/p448/dqVzAAAAAIDQqdE9jB6PR5K0b98+HXfccQHnkpOTtX379kqf7/P5KkYpf+YvK1NEFGvwAAAAAKgFpqS6qkYjjFdffbUuvvhilZaWavPmzQHn8vLy1KRJk0qfn5GRoYSEhIC2+4sFNekKAAAAAMASxwXjyJEj1aJFCyUkJOiiiy5SUVFRwPl33nlH3bt3rzRGenq68vPzA1ri7wY47QoAAAAABDIhbGHI8RzQ119/vdLzEyZMUGRkZKWP8Xq98nq9AceYjgoAAAAA9UutFr0JZu/evbrxxhvdDgsAAAAAqGNWCsbp06e7HRYAAAAAquQxoWvhyPE80Dlz5lR6ftOmTTXuDAAAAACg/nBcMA4dOlQej0fGHLmE/nnbDQAAAACoU4ZaxE2Op6QmJSVp9uzZ8vv9QduqVats9BMAAAAAUMccF4w9evTQypUrj3i+qtFHAAAAAMDRwfGU1HHjxqmwsPCI55OTk7Vo0aJadQoAAAAAaoSxK1c5Lhj79etX6fm4uDilpqY67oin3PFTHIsqthvf7636MbVWBxdA9AH7874X5J5oPUfXZrlW45cURVuNL0kR+fZz7IyMt54josz+z1TkIbvxPYWV7y/rSo46+D1YF9f31IKW1nNcE7/Davyn9zW0Gl+SovLt/0xlF7eyniOiLj6/D9n98IsssX9dePzWUyjqyP/Pd82SLcdZz9Gr3Var8UuL7e/93Sjfegpt2ZZoPwmgGhSMAAAAAFBfhev2FqHi+j6MAAAAAIDwwAgjAAAAgPDBCKOrGGEEAAAAAATluGD88ccftXv37oqv//vf/+rKK69Uv3799Oc//1nLli1ztYMAAAAAgNBwXDD+8Y9/1BdffCFJ+ve//62zzjpLBw8eVN++fVVUVKTU1FS9//77rncUAAAAAKriMaFr4cjxPYzffvutTj75ZElSRkaGHnnkEY0fP77i/KRJk3TffffpD3/4g3u9BAAAAADUOccjjFFRUTpw4IAkafPmzTr//PMDzp9//vnKyspyp3cAAAAA4IQJYQtDjgvG1NRUzZw5U5J06qmnavHixQHnFy1apDZt2lQaw+fzqaCgIKD5y8qcdgUAAAAAYJHjKamPPvqo+vXrp+3bt+vMM8/U3XffrS+//FIpKSnKysrS22+/rSlTplQaIyMjQxMnTgw41rzPQLXoe57T7gAAAAAALHE8wpiSkqLly5erpKREjz/+uAoLC/Xmm2/q/vvv18aNGzVr1ixdffXVlcZIT09Xfn5+QEvsPaCmrwEAAAAAfsKUVFc5HmGUpOOOO04zZ86UMUY7d+6U3+9XYmKioqOjq/V8r9crr9cbcCwiqkZdAQAAAABY4niE8Zc8Ho9atmyppKSkimLxhx9+0DXXXONK5wAAAADACbbVcFetCsZg9u7dq+nTp7sdFgAAAABQxxzPA50zZ06l5zdt2lTjzgAAAAAA6g/HBePQoUPl8XhkzJHHXD0eT606BQAAAAAIPcdTUpOSkjR79mz5/f6gbdWqVTb6CQAAAACoY44Lxh49emjlypVHPF/V6CMAAAAAWMO2Gq5yPCV13LhxKiwsPOL55ORkLVq0qFadAgAAAACEnuOCsV+/fpWej4uLU2pqquOOHOxU7vg5TiVkRVqNX9ix1Gp8SfL4XF/Y9nB1kKJ1owLrOfyyey/tie3zrMaXpKxDbazniNgbYz1HbMc6+H7vSbAaP/G4PVbjS9LO3CbWc0Ttt7/n7Y8lzazneHpfQ6vx05puthpfkqZYzyB9td/+75CD7f3Wc8Tusfv7vKhdmdX4khRRbPdvEElqkGd/DYmyEvuv47u9LazGP+7YnVbjS9KeFcdazxG1w/7n99EqXLe3CJU6KA0AAAAAAEcjCkYAAAAAQFD25yYBAAAAQF1hSqqrGGEEAAAAAATFCCMAAACA8MEIo6scjzA+9dRT2rp1q42+AAAAAADqEccF47hx43Tcccfp97//vd5++22VlJTY6BcAAAAAOOYxoWvhqEb3MP79739XXFycrrrqKrVu3Vq33nqrvvnmG7f7BgAAAAAIoRoVjBdccIHee+89/fjjj7rjjjv08ccfq1u3burVq5deffVVHThwwO1+AgAAAADqWK1WSW3RooXuuOMOrV+/XosXL9ZJJ52ksWPHKikpqdLn+Xw+FRQUBDRTWlabrgAAAADAT4vehKqFIccFo8fjCXq8X79+mjZtmrZv365nnnmm0hgZGRlKSEgIaPkff+q0KwAAAAAAixwXjMZUXjrHx8dr9OjRlT4mPT1d+fn5AS1h0DlOuwIAAAAAAVj0xl2O92H0+/21Tur1euX1egOOeaLZEhIAAAAA6pNa3cMYzA8//KBrrrnG7bAAAAAAgDrmesG4d+9eTZ8+3e2wAAAAAFA1Fr1xleN5oHPmzKn0/KZNm2rcGQAAAABA/eG4YBw6dKg8Hk+li98caSVVAAAAALAqTEf6QsXxlNSkpCTNnj1bfr8/aFu1apWNfgIAAAAA6pjjgrFHjx5auXLlEc9XNfoIAAAAALawrYa7HE9JHTdunAoLC494Pjk5WYsWLapVpwAAAAAAoecx9WQ4cODvHrCeozipodX4sbt8VuNLkom0f39o7u8aWM9hoq2nUGSR3fjefPuXzp6z7f9MefbGWM/h3e36gsyHKepQajV+7Db7P7QNc62n0N6edt8nSfKU2f89FZUfaT2HbdlXTbGeo9M7f7We48S/F1jPUd7Y7u+piJJyq/ElSbXfxrpKvpb2P799CfavvYhSu5+vMfllVuNL0pZh9t+nFsvsf7aumJZmPYcNJ6c/E7Lc32aMDVluWxyPMAIAAABAvVUvhsPCh/1/TQAAAAAAgnrxxRfVoUMHxcbGqnfv3lqxYsURH/vqq6+qX79+atq0qZo2baoBAwZU+ng3UDACAAAACB8mhM2ht99+W2lpaZowYYJWrVqlbt26adCgQdq5c2fQxy9evFjDhw/XokWLtGzZMh177LEaOHCgtm3b5jx5NVEwAgAAAEAIPP300xo9erRGjRqlk046SVOmTFHDhg01derUoI9/8803deONN6p79+7q3Lmz/v73v8vv92vhwoXW+lijgvH999/Xfffdp88//1yS9Omnn+qCCy7Qeeedp1deecXVDgIAAADA0cDn86mgoCCg+XzBFzEsKSnRypUrNWDAgIpjERERGjBggJYtW1atfEVFRSotLVWzZs1c6X8wjgvGl19+WcOGDdOHH36oCy64QG+88YaGDh2qNm3aqEOHDrr11lv13HPP2egrAAAAAFQqlPswZmRkKCEhIaBlZGQE7efu3btVXl6uli1bBhxv2bKl8vLyqvVax48fr9atWwcUnW5zvErq888/r5deekmjR4/WokWLdMEFF+ipp57SjTfeKEn63e9+p8cff1y33HKL650FAAAAgPoqPT1daWmB25F4vV4ruR599FHNmjVLixcvVmxsrJUcUg1GGDdv3qxBgwZJks4++2yVl5erf//+FefPOussbd261b0eAgAAAEB1hXDRG6/Xq/j4+IB2pIIxMTFRkZGR2rFjR8DxHTt2qFWrVpW+xCeffFKPPvqoPvnkE51yyikO3hznHBeMxxxzTEVBuH37dpWVlSknJ6fi/NatW6ucQxtsbq/fb38TVQAAAACoD2JiYtSjR4+ABWt+XsCmT58+R3ze448/rgcffFDz5s1Tz549rffT8ZTUiy66SNdee61GjhypOXPmaMSIEbrtttsUEREhj8ejcePGaeDAgZXGyMjI0MSJEwOOdWpzlo5re7bT7gAAAABABU8NtrcIlbS0NI0cOVI9e/ZUr1699Oyzz6qwsFCjRo2SJI0YMUJt2rSpuA/yscce03333ae33npLHTp0qLjXsVGjRmrUqJGVPjouGB977DGVlJRo1qxZOuOMM/TCCy/o+eef10UXXaTS0lKlpqYe8cbOnwWb23vxgCeddgUAAAAAjlqXXXaZdu3apfvuu095eXnq3r275s2bV7EQTk5OjiIi/jcpdPLkySopKdGf/vSngDgTJkzQ/fffb6WPjgvGuLi4w7bOuP322zVmzBiVlpaqcePGVcbwer2HzeWNiHDcFQAAAAA4qo0ZM0ZjxowJem7x4sUBX2/ZssV+h36lRvswBhMbG6vGjRvrhx9+0DXXXONWWAAAAACovhAuehOOXCsYf7Z3715Nnz7d7bAAAAAAgDrmeB7onDlzKj2/adOmGncGAAAAAGolTEf6QsVxwTh06FB5PB4Zc+TvhMfjqVWnAAAAAACh53hKalJSkmbPni2/3x+0rVq1ykY/AQAAAAB1zHHB2KNHD61cufKI56safQQAAAAAWzwhbOHI8ZTUcePGqbCw8Ijnk5OTtWjRolp1CgAAAAAQeo4Lxn79+lV6Pi4uTqmpqY47UhrvrfpBtVTa0G7d72kWYzW+JHnK7I/eliZYT6GIzges5yguirYav2RTrNX4kuTZZf+6GNDvK+s5lrzX3XoOb67d77enzGr4n3LUweQMT6T9JPecOdd6juziVlbjf7W/jdX4ktTpnb9az7Hpjy9bz3HunGut5yiPdX1R9zrnKbV/7e073v6e1gUnllvPIb/d8HE59v9eO+bIk/Fc0/CqbfaTHK2Y7Oiqo/83MAAAAADACvv/igIAAACAOlIXM3Z+SxhhBAAAAAAERcEIAAAAAAiKKakAAAAAwgdTUl1Vo4KxuLhYM2fO1JIlS5Sbm6uIiAh16tRJQ4cO1bnnnut2HwEAAAAAIeC4YNy4caMGDBig4uJieb1e/fjjj7rgggv05ZdfavLkybr44ov11ltvKSqKwUsAAAAAdYwRRlc5vofxb3/7m8477zzl5eUpJydHGRkZ8vv9+uKLL7R+/Xp9+eWXeuihh2z0FQAAAABQhxwXjP/5z3902223yePxSJLGjh2rBQsWaM+ePTr++OP17LPPavr06a53FAAAAABQtxzPG23SpIkOHDhQ8XVRUZHKysoUExMjSTrllFOUm5tbaQyfzyefzxdwzO8vU0QE01gBAAAA1Bz7MLrL8Qjj73//e6Wlpem7777T5s2bdf3116t79+5q3LixJCknJ0ctWrSoNEZGRoYSEhIC2tbNi2r2CgAAAAAAVjguGB9//HH5fD6ddNJJSk5O1hdffKHXXnut4vyuXbs0bty4SmOkp6crPz8/oLXveLbz3gMAAADAL5kQtjDkeA5oixYttGzZMm3YsEE+n0+dO3cOWBH1T3/6U5UxvF6vvF5vwDGmowIAAABA/eJ4hPFnxx9/vLp06XLY9hk//PCDrrnmmlp3DAAAAAAQWjUuGI9k7969rJIKAAAAICQ8JnQtHDmeBzpnzpxKz2/atKnGnQEAAAAA1B+OC8ahQ4fK4/HImCOX0D/v0QgAAAAAdSpMR/pCxfGU1KSkJM2ePVt+vz9oW7VqlY1+AgAAAADqmOOCsUePHlq5cuURz1c1+ggAAAAAtnAPo7scT0kdN26cCgsLj3g+OTlZixYtqlWnAAAAAACh5zH1ZDiwYHs76zm6vXOL1fhf/fE5q/ElqVR+6zn6v3Cb9RxRffdaz9G7VY7V+Oc2WWc1viQ9NOUK6znaTLX/OlI+PWA9x7fXnWQ1fqfJG6zGl6RjY/dZz7HkXPu/a3NGHm89R0S53fgH29v/XXvC1ALrOUpaNLSeY+H016znOO7//mo1/oY/TbYaX5JKjeUfWkk9Xvib9Ry+bkXWc7Roavcz48p2K6zGl6RJMwdbz9HoR/t/wme+lmY9hw2n3fBMyHKvmjw2ZLltcTzCCAAAAAD1Vr0YDgsfru/DCAAAAAAID4wwAgAAAAgfjDC6qkYF44oVK7Rs2TLl5eVJklq1aqU+ffqoV69ernYOAAAAABA6jgrGnTt36o9//KM+//xztWvXTi1btpQk7dixQ2PHjlXfvn31zjvvqEWLFlY6CwAAAACoO47uYbzxxhtVXl6u9evXa8uWLVq+fLmWL1+uLVu2aP369fL7/brpppts9RUAAAAAKsU+jO5yNML48ccf67PPPtOJJ5542LkTTzxRzz//vM466yy3+gYAAAAACCFHBaPX61VBwZH3jTpw4IC8Xm+tOwUAAAAANRKmI32h4mhK6mWXXaaRI0fq3XffDSgcCwoK9O6772rUqFEaPnx4lXF8Pp8KCgoCms/HdxYAAAAA6hNHI4xPP/20/H6/Lr/8cpWVlSkmJkaSVFJSoqioKF177bV68sknq4yTkZGhiRMnBhy7My1e6bclOOkOAAAAAATwGAai3OR4SurkyZP12GOPaeXKlQHbavTo0UPx8fHVipOenq60tLSAY749JzvpCgAAAADAshrtwxgfH6+zzz67xkm9Xu9h9zoWHPTUOB4AAAAAwH2O7mGUpOLiYi1ZskTr1q077NyhQ4c0Y8YMVzoGAAAAAI6ZELYw5KhgzM7OVkpKivr376+uXbsqNTVV27dvrzifn5+vUaNGud5JAAAAAEDdc1Qwjh8/Xl26dNHOnTuVlZWlxo0b68wzz1ROTo6t/gEAAABAtXlM6Fo4clQwLl26VBkZGUpMTFRycrLmzp2rQYMGqV+/ftq0aZOtPgIAAAAAQsBRwVhcXKyoqP+tk+PxeDR58mQNHjxYqampys7Odr2DAAAAAIDQcLRKaufOnZWZmamUlJSA45MmTZIkDRkyxL2eAQAAAIBTYTo1NFQcjTAOGzZMM2fODHpu0qRJGj58uAwbZQIAAABAWPCYelLhHf/oM9ZzzL7yKavxh711m9X4khRRbj2FEtf4refYe5LjHV0cK2tgN77H/tukJhvsX56Nt5ZYz7HzNG/VD6qlA51LrcZvnBVtNX5dabW82HqO3V0tX3ySog7ZvTY8dfC7NuF7+9+LkqYx1nP88Hv7v8+//9PLVuN3euevVuNLdfP5HbvD/veiOMn+h5+xvDV3XSxMUhffi7r4PbXukbH2k1jQ6+qnQ5Z7xbS0kOW2xf5PMwAAAADgqOToHkYAAAAAqNfqxfzJ8MEIIwAAAAAgKApGAAAAAEBQrhaM+/bt04wZM9wMCQAAAADV5jGha+HI1YIxJydHo0aNcjMkAAAAACBEHC16U1BQUOn5AwcO1KozAAAAAFArYTrSFyqOCsYmTZrI4zny5jjGmErPAwAAAACOHo4KxsaNG+vuu+9W7969g57fsGGD/vpX+5vfAgAAAADsc1QwnnbaaZKk1NTUoOebNGkiY6oeA/b5fPL5fAHHTFmZPFFsCwkAAACg5sJ18ZlQcbTozRVXXKHY2Ngjnm/VqpUmTJhQZZyMjAwlJCQEtL2LFzjpCgAAAADAMkdDeqNHj670fMuWLatVMKanpystLS3g2GnPv+ykKwAAAABwuGrMeET1hWQOqNfrldfrDTjGdFQAAAAAqF8c78NYXFysJUuWaN26dYedO3TokGbMmOFKxwAAAADAKY8JXQtHjgrG7OxspaSkqH///uratatSU1OVm5tbcT4/P1+jRo1yvZMAAAAAgLrnqGAcP368unTpop07dyorK0uNGzdW3759lZOTY6t/AAAAAIAQcXTj4NKlS7VgwQIlJiYqMTFRc+fO1Y033qh+/fpp0aJFiouLs9VPAAAAAKhamE4NDRVHI4zFxcWK+sXiNB6PR5MnT9bgwYOVmpqq7Oxs1zsIAAAAAAgNRyOMnTt3VmZmplJSUgKOT5o0SZI0ZMgQ93oGAAAAAA55/KHuQXhxNMI4bNgwzZw5M+i5SZMmafjw4TLsewIAAAAAYcFj6kmFt3/7sdZznPrOrVbjf/XH56zGl6RS2f+XyZlTbrOeo2XqNus5ftd8i9X4/Rt/ZzW+JN3+6rXWc7R/Y6v1HCfPza36QbW09q8nW41/ysvfWo0vScdEH7Ce47OBydZzbLquo/UckSV24xe1K7ObQNIJU4ut5zjUsoH1HJ++/LL1HMnv3GA1/qY/2n8NxcZnPUfPybdazxF9+j7rOdok5FuNf0XScqvxJemhWZdZz9Ewz3oKrX5xrP0kFpxx2VMhy730bft/R9c1R1NSAQAAAKBeqxfDYeHD0ZRUAAAAAMBvByOMAAAAAMKGhxFGV9VohNHvD34fnd/vV05OTq06BAAAAACoHxwVjAUFBbr00ksVFxenli1b6r777lN5eXnF+V27dqljR/uLHQAAAABAUMaEroUhR1NS7733Xn311Vf6xz/+of379+uhhx7SqlWrNHv2bMXExEgS22oAAAAAQJhwNML43nvv6eWXX9af/vQn/eUvf1FmZqZ27dqlwYMHy+f7abloj8djpaMAAAAAgLrlqGDctWuX2rdvX/F1YmKiFixYoAMHDuiCCy5QUVGR6x0EAAAAgOrymNC1cOSoYGzXrp3Wr18fcKxx48b65JNPVFxcrGHDhlUrjs/nU0FBQUDz+cL0HQYAAACAo5SjgnHgwIF6/fXXDzveqFEjffzxx4qNja1WnIyMDCUkJAS0ZyYVOOkKAAAAABzOhLCFIUeL3kycOFHbt28Peq5x48aaP3++Vq1aVWWc9PR0paWlBRwr3nOSk64AAAAAACxzVDA2bdpUTZs2PeL5xo0bKzU1tco4Xq9XXq834Jj/IIvlAAAAAEB94mhKqiQVFxdryZIlWrdu3WHnDh06pBkzZrjSMQAAAABwikVv3OWoYMzOzlZKSor69++vrl27KjU1Vbm5uRXn8/PzNWrUKNc7CQAAAADh6MUXX1SHDh0UGxur3r17a8WKFZU+/l//+pc6d+6s2NhYde3aVR9++KHV/jkqGMePH68uXbpo586dysrKUuPGjdW3b1/l5OTY6h8AAAAAVJ8xoWsOvf3220pLS9OECRO0atUqdevWTYMGDdLOnTuDPn7p0qUaPny4rr32Wq1evVpDhw7V0KFD9c0339T2XTsiRwXj0qVLlZGRocTERCUnJ2vu3LkaNGiQ+vXrp02bNtnqIwAAAACEnaefflqjR4/WqFGjdNJJJ2nKlClq2LChpk6dGvTxzz33nM477zyNGzdOKSkpevDBB3Xaaadp0qRJ1vroqGAsLi5WVNT/1snxeDyaPHmyBg8erNTUVGVnZ7veQQAAAACorlDewxh8v3lf0H6WlJRo5cqVGjBgQMWxiIgIDRgwQMuWLQv6nGXLlgU8XpIGDRp0xMe7wVHB2LlzZ2VmZh52fNKkSbrooos0ZMgQ1zoGAAAAAEeTYPvNZ2RkBH3s7t27VV5erpYtWwYcb9mypfLy8oI+Jy8vz9Hj3eCoYBw2bJhmzpwZ9NykSZM0fPhwmRrM3QUAAACAo116erry8/MDWnp6eqi7VSuOCsb09PRKV+F56aWX5Pf7a90pAAAAAKgRE7rm9XoVHx8f0H69//zPEhMTFRkZqR07dgQc37Fjh1q1ahX0Oa1atXL0eDdEVf2QunHAlFnP4fF7rMbPN6VW40tSQ0+k9RwRJdZTaEdBY+s5chsnWI2fF9vEanxJijxkPYVUYv8bHh9ZbD2HibJ7bUR5yq3Gl6TW0fut51CDWOspog9aTyGP5f9NRhTb/12rOvj/qqfU/qyfUmP/2oiwnKLYBL+/yE0NPMH/YHRTXXx+F+xraD1HRITdn9vvm7Ws+kG1FFVoPYWiC5nVd7SLiYlRjx49tHDhQg0dOlSS5Pf7tXDhQo0ZMyboc/r06aOFCxfq1ltvrTg2f/589enTx1o/603BCAAAAAC15TmKaum0tDSNHDlSPXv2VK9evfTss8+qsLCwYm/7ESNGqE2bNhX3Qd5yyy1KTU3VU089pQsvvFCzZs1SZmamXnnlFWt9pGAEAAAAgBC47LLLtGvXLt13333Ky8tT9+7dNW/evIqFbXJychQR8b+7CM844wy99dZbuueee3TXXXfp+OOP13vvvacuXbpY6yMFIwAAAACEyJgxY444BXXx4sWHHbvkkkt0ySWXWO7V/zguGI0x2rJli4499lhFRUWppKRE7777rnw+ny644AIlJiba6CcAAAAAVM1/FM1JPQo4KhizsrI0aNAg/fDDD+rUqZM++eQTXXLJJfruu+9kjFHDhg21dOlSHX/88bb6CwAAAACoI4621Rg/fry6deumNWvW6A9/+IMuvPBCtW3bVvv27dPevXvVp08fPfDAA7b6CgAAAACVC+G2GuHIUcG4dOlSTZw4UV27dtVDDz2k7777Trfffruio6Pl9Xp155136rPPPrPVVwAAAABAHXJUMB48eFDNmjWTJMXFxSkuLk5JSUkV54899tjDNpIEAAAAABydHN3D2Lp1a+Xk5Khdu3aSpMcff1wtWrSoOL9r1y41bdq0yjg+n08+n+9Xx4y8Xo+T7gAAAABAgKNpH8ajgaMRxgEDBui7776r+PqGG25Q48aNK77+5JNPdNppp1UZJyMjQwkJCQHtxUkHnXQFAAAAAGCZoxHGKVOmVHr+sssu08iRI6uMk56errS0tIBjO3ef4KQrAAAAAHA4wxCjmxzvw1iZjh07VutxXq9XXq834Fj+AaajAgAAAEB94mhKqiQVFxdryZIlWrdu3WHnDh06pBkzZrjSMQAAAABwymNC18KRo4IxOztbKSkp6t+/v7p27arU1FTl5uZWnM/Pz9eoUaNc7yQAAAAAoO45KhjHjx+vLl26aOfOncrKylLjxo3Vt29f5eTk2OofAAAAACBEHN3DuHTpUi1YsECJiYlKTEzU3LlzdeONN6pfv35atGiR4uLibPUTAAAAAKoWplNDQ8XRCGNxcbGiov5XY3o8Hk2ePFmDBw9WamqqsrOzXe8gAAAAACA0HI0wdu7cWZmZmUpJSQk4PmnSJEnSkCFD3OsZAAAAADjkYVsNVzkaYRw2bJhmzpwZ9NykSZM0fPhwGb5BAAAAABAWPKaeVHinXf+M9RxRxXZfqi/B/l6SkSXWU2hM2jvWc7yyuZ/1HDt2xdtNUAdbh5oyxzvfOBbb2Gc/x6eNredI/LrYavw9JzewGl+qm+W484+zn8S73/7FEVVoN355rN34kpT4TZn1HPuOd3W75aDK6uC9sv371kTajS9JEXXw+f31rZOt5zjjqz9az3HgkLfqB9WCN9r+tXew2O5rkKTjmu+2nuOj/s9Zz2HDOb9/NGS5P51/Z8hy22L/kwQAAAAA6oo/1B0IL/aHLwAAAAAARyVGGAEAAACEDRa9cZcrI4znnHOOtm7d6kYoAAAAAEA94WiEcc6cOUGPf/bZZ3r//fd17LHHSmJ7DQAAAAAhwgCjqxwVjEOHDpXH4wm6dcbNN98sSfJ4PCovL3endwAAAACAkHE0JXXQoEE6//zzlZeXJ7/fX9EiIyP1zTffyO/3UywCAAAAQJhwVDB+9NFHOvfcc9WzZ0+9//77tvoEAAAAADVjTOhaGHK8SurYsWN19tln68orr9TcuXP1zDPPOE7q8/nk8wVuFu4vL1NEJIu2AgAAAEB9UaNVUrt3767MzEx5PB5179496D2NlcnIyFBCQkJA27F6QU26AgAAAAAVPCZ0LRzVeFuNBg0aaMqUKXryySd18803KzExsdrPTU9PV35+fkBreeqAmnYFAAAAAGBBreeADhkyxPE2Gl6vV16vN+AY01EBAAAAoH5xPMJYXFysJUuWaN26dYedO3TokGbMmOFKxwAAAADAMRa9cZWjgjE7O1spKSnq37+/unbtqtTUVOXm5lacz8/P16hRo1zvJAAAAACg7jkqGMePH68uXbpo586dysrKUuPGjdW3b1/l5OTY6h8AAAAAVJvHH7oWjhwVjEuXLlVGRoYSExOVnJysuXPnatCgQerXr582bdpkq48AAAAAgBBwVDAWFxcrKup/i9N4PB5NnjxZgwcPVmpqqrKzs13vIAAAAABUG/cwusrR0qSdO3dWZmamUlJSAo5PmjRJkhyvlgoAAAAAqL8cjTAOGzZMM2fODHpu0qRJGj58uEyYVtYAAAAA8FvjqGBMT0/Xhx9+eMTzL730kvz+ML3bEwAAAED9Z0LYwpCjKak27elVaj2HNzfaavzSDoesxpckU2j/W/bw6vOt55jS6w3rOVa0Pc5q/O8OtrIaX5KWbuloPUfJIfs/U/7W1lPIs8ruP6vyT7T/KRBV6LGeo8OHPus52j1m/372JVvsXt9lJZFW40uS7wev9RwFJ5ZbzxHZxP7PlH9XrNX4jdvnW40vSQX7GlrPccZXf7SeY2m3d6zn+NJn92/Cr31trcaXpH/l9rCe4/KkL63nAKR6VDACAAAAQG15uEXOVY6mpAIAAAAAfjsoGAEAAAAAQdV6SurmzZu1ceNGJSUlqUuXLm70CQAAAABqhimprnI0wnjjjTfq4MGDkqTi4mL96U9/UnJysgYNGqRu3brpnHPOqTgPAAAAADi6OSoYX375ZRUVFUmSHnzwQS1fvlwLFizQwYMH9dlnnyknJ0cPP/ywlY4CAAAAQJX8IWxhyFHBaH4xvDt37lw9/vjjOvvss9WwYUP17dtXTz/9tGbPnu16JwEAAAAAdc/xPYwez0/7hOXl5emUU04JONetWzf98MMP7vQMAAAAABxiWw13OS4Y7733XjVs2FARERHavn27Tj755Ipze/bsUVxcXJUxfD6ffL7AjX5NaZk80WwLCQAAAAD1haMpqf3791dWVpZWr16tk046SVu3bg04/+GHHwYUkEeSkZGhhISEgJb/4SJnPQcAAAAAWOVoSG/x4sWVnr/iiit09dVXVxknPT1daWlpAce6zJzkpCsAAAAAcDimpLrK1TmgnTp1qtbjvF6vvF5vwDGmowIAAABA/eJoSqr00/6LS5Ys0bp16w47d+jQIc2YMcOVjgEAAACAY8aEroUhRwVjdna2UlJS1L9/f3Xt2lWpqanKzc2tOJ+fn69Ro0a53kkAAAAAQN1zVDCOHz9eXbp00c6dO5WVlaXGjRurb9++ysnJsdU/AAAAAECIOLpxcOnSpVqwYIESExOVmJiouXPn6sYbb1S/fv20aNGiam2pAQAAAADW+EPdgfDiaISxuLhYUVH/qzE9Ho8mT56swYMHKzU1VdnZ2a53EAAAAAAQGo5GGDt37qzMzEylpKQEHJ806actMYYMGeJezwAAAADAIU+YLj4TKo5GGIcNG6aZM2cGPTdp0iQNHz5chm8QAAAAAIQFRyOM6enpSk9PP+L5l156SS+99FKNOhKfWFij5zlRvKuJ1fjNjzlgNb4kHWjorfpBtVR8INZ6jryyBOs5zm50+NYvbio3jnelcey/vuOt54jYb38P1JJm5dZz+GPsfj/88WVW40tSidf+z1Rd2F/S0HqOXu22Wo3/3d4WVuNLUkRpjPUcdXEfT4um9j/7cnfb/Vxqk5BvNb4kRUTY/4f6gUP2/0b40ldqPcfp3mir8ff491mNL0m5BfHWc/w37gTrOUZaz2AJA1iuCo+/TgAAAAAArqNgBAAAAAAEZX8uGgAAAADUFaakuspRwejz+RQREaHo6J/mln///feaOnWqcnJy1L59e1177bXq2LGjlY4CAAAAAOqWoympgwYN0r///W9J0ueff66TTz5Z77//vkpLS/Xhhx+qS5cuWrZsmZWOAgAAAECVjAldC0OOCsbVq1erW7dukqS7775bN954o7766ivNmjVLq1atUlpamsaNG2elowAAAACAuuWoYCwvL1d5+U/L43/33XcaOTJwsd2rr75aX331lXu9AwAAAACEjKOCsXfv3po7d64k6bjjjjusOFyzZo2aNWvmXu8AAAAAwAl/CFsYcrTozUMPPaTzzz9fhYWFGj58uG677TZt2LBBKSkpysrK0vPPP6/09PQq4/h8Pvl8voBj/tIyRUSzaCsAAAAA1BeOKrQ+ffroo48+UlpampYvXy5JevjhhyVJrVu31v33369bbrmlyjgZGRmaOHFiwLHml/dXy+FnOekOAAAAAATwhOniM6HieEivT58+WrZsmXbt2qVNmzbJ7/crKSlJHTp0qHaM9PR0paWlBcad/5jTrgAAAAAALKrxHNDmzZurefPmNXqu1+uV1+sNOMZ0VAAAAAC1xgijqxwteiNJxcXFWrJkidatW3fYuUOHDmnGjBmudAwAAAAAEFqOCsbs7GylpKSof//+6tq1q1JTU5Wbm1txPj8/X6NGjXK9kwAAAACAuueoYBw/fry6dOminTt3KisrS40bN1bfvn2Vk5Njq38AAAAAUH1+E7oWhhwVjEuXLlVGRoYSExOVnJysuXPnatCgQerXr582bdpkq48AAAAAgBBwVDAWFxcrKup/i9N4PB5NnjxZgwcPVmpqqrKzs13vIAAAAABUmzGha2HI0dKknTt3VmZmplJSUgKOT5o0SZI0ZMgQ93oGAAAAAAgpRyOMw4YN08yZM4OemzRpkoYPHy4TppU1AAAAAPzWOCoY09PT9eGHHx7x/EsvvSS/31/rTgEAAABAjTAl1VWOpqTa9MdOa6zneHPdWVbjX9p+pdX4kpRX0sR6jve/P9l6jrpwwB9rNf6whFVW40vSVNPXeo64LY63Y3XMc/Y+6zmiDtp9Hc1bHbQaX5JKyiOt54gsirae45vtSdZzlBbb/fg67tidVuNLUnl+mfUccTkx1nNcefYK6zmeyr7QavwrkpZbjS9J3zdraT3HnJyu1nN87WtrPccev93PjPMalFiNL0ljS+3/if35Dx2t51BP+ylQ/9WbghEAAAAAai1MR/pCxf7QAgAAAADgqETBCAAAAAAIylHB+M4776ioqMhWXwAAAACgdvwmdC0MOSoYL7nkEiUlJem6667T8uX2bxAHAAAAgN+6vXv36sorr1R8fLyaNGmia6+9VgcPHnlBvr179+rmm2/WiSeeqAYNGqhdu3b629/+pvz8fMe5HU9Jvf3225WZmak+ffqoS5cuevbZZ7Vnzx7HiQEAAADAdcYfumbJlVdeqW+//Vbz58/X+++/r88++0zXXXfdER+/fft2bd++XU8++aS++eYbTZs2TfPmzdO1117rOLfjgvGvf/2rVq1apS+//FL9+/fXxIkT1aZNG1166aWaP3++4w4AAAAAAIJbv3695s2bp7///e/q3bu3zjzzTL3wwguaNWuWtm/fHvQ5Xbp00TvvvKPBgwfruOOO0znnnKOHH35Yc+fOVVmZs22darzoTY8ePfTSSy8pNzdXr776qnbt2qXzzjtPHTvWwZ4wAAAAABCMMSFrPp9PBQUFAc3n89Xq5SxbtkxNmjRRz57/2xhzwIABioiIcHSbYH5+vuLj4xUV5WxnRUcFo8fjOexYbGysrrrqKi1atEhZWVm64oorqowT7I0sKyl30hUAAAAAqFcyMjKUkJAQ0DIyMmoVMy8vTy1atAg4FhUVpWbNmikvL69aMXbv3q0HH3yw0mmsR+KoYDRVbIKZnJyshx9+uMo4wd7IJX/f4KQrAAAAAFCvpKenKz8/P6Clp6cHfeydd94pj8dTafvuu+9q3aeCggJdeOGFOumkk3T//fc7fr6j8cjNmzerefPmjpP8Wnp6utLS0gKOPb6x6pFJAAAAAKhUCLe38Hq98nq91XrsbbfdpquvvrrSx3Tq1EmtWrXSzp07A46XlZVp7969atWqVaXPP3DggM477zw1btxY7777rqKjo6vVt19yVDC2b9/ecYJggr2RUTGRrsQGAAAAgPquefPm1RqM69Onj/bv36+VK1eqR48ekqRPP/1Ufr9fvXv3PuLzCgoKNGjQIHm9Xs2ZM0exsbE16qfjRW+Ki4u1ZMkSrVu37rBzhw4d0owZM2rUEQAAAACotRAuemNDSkqKzjvvPI0ePVorVqzQ559/rjFjxujyyy9X69atJUnbtm1T586dtWLFCkk/FYsDBw5UYWGhXnvtNRUUFCgvL095eXkqL3e2doyjgjE7O1spKSnq37+/unbtqtTUVOXm5lacz8/P16hRoxx1AAAAAABwZG+++aY6d+6sc889VxdccIHOPPNMvfLKKxXnS0tLlZWVpaKiIknSqlWrtHz5cn399ddKTk5WUlJSRfvhhx8c5XY0JXX8+PHq0qWLMjMztX//ft16663q27evFi9erHbt2jlKDAAAAACoWrNmzfTWW28d8XyHDh0CFig966yzqlywtLocFYxLly7VggULlJiYqMTERM2dO1c33nij+vXrp0WLFikuLs6VTgEAAABAjViaGvpb5WhKanFxccBGjx6PR5MnT9bgwYOVmpqq7Oxs1zsIAAAAAAgNRyOMnTt3VmZmplJSUgKOT5o0SZI0ZMgQ93oGAAAAAE4xwugqRyOMw4YN08yZM4OemzRpkoYPH+7aXFkAAAAAQGh5TD2p8Lrd+oz1HFGFduOXJNiNL0mRh+zn2H9KmfUcDZoXWc9RtLeB1fieEse70jh2Qe811nPM++w06zmafW09hY5ZlW81/u7Tm1iNL0mRPvu/jpusP2g9x5aLGlvPEWP3260o+7+itL+rs2XNa+KYlfb3OC5Msp5CHr/d+P4Yu/El+3+DSFLp6fav746Je6znyC2ItxrfV+pogl2NrD/jDes5Ts28zHqOr/7woPUcNpyfdFPIcn+U+2LIctti/y9eAAAAAMBRiYIRAAAAABCU/TF5AAAAAKgr9eOOu7DBCCMAAAAAICjHI4xfffWVVq5cqbPOOkudOnXSt99+qxdffFF+v1/Dhg3ToEGDbPQTAAAAAKrGCKOrHI0wzp49Wz169NAdd9yhbt26acGCBTrzzDO1YcMGbdmyRRdeeKHeeustW30FAAAAANQhRwXjww8/rIkTJ2r37t169dVXdckllygtLU3z58/XvHnz9Nhjj+mJJ56w1VcAAAAAQB1yVDBmZWXpyiuvlCRddtllKiws1NChQyvODxs2TBs3bnS1gwAAAABQbX4TuhaGHN3D2LhxY+3Zs0cdOnTQ/v37VVZWpj17/reB6549e9SoUaMq4/h8Pvl8voBj/rIyRUSxaCsAAAAA1BeORhgHDBigm266SW+++aZGjhypgQMHKj09Xd99952ysrI0btw4nXnmmVXGycjIUEJCQkDbmbmgxi8CAAAAACTJGH/IWjhyVDA++eSTio+P1/XXX6+SkhK9/fbb6tmzp0466SSddNJJ2r59ux599NEq46Snpys/Pz+gteg5oMYvAgAAAADgPkdzQFu2bKlPPvkk4NgLL7ygsWPHqqioSJ07d1ZUNaaVer1eeb3egGNMRwUAAABQa2F6L2GouFKlderUyY0wAAAAAIB6xNGUVEkqLi7WkiVLtG7dusPOHTp0SDNmzHClYwAAAACA0HJUMGZnZyslJUX9+/dX165dlZqaqtzc3Irz+fn5GjVqlOudBAAAAIBqMSZ0LQw5KhjHjx+vLl26aOfOncrKylLjxo3Vt29f5eTk2OofAAAAACBEHN3DuHTpUi1YsECJiYlKTEzU3LlzdeONN6pfv35atGiR4uLibPUTAAAAAKrmD8/tLULF0QhjcXFxwCqoHo9HkydP1uDBg5Wamqrs7GzXOwgAAAAACA1HI4ydO3dWZmamUlJSAo5PmjRJkjRkyBD3egYAAAAACClHI4zDhg3TzJkzg56bNGmShg8fLhOmN3sCAAAAOAqw6I2rPKaeVHj9hj1pPUdhy0ir8b0F9udLRxXZz7FzRLH1HP3abbKeY+mPHazGL9rW2Gp8SVLjUuspbuz5H+s53n1ogPUcDXbZfa8OtI2xGl+qm98hh5o63k3JsUbDt1vPsWVbotX4UTvsf7+bfWs9hRpeZf97cfCt1tZzFLX0WI3vzbcaXpIUXWj/z61jrtlqPcflSV9az/Hf/BOsxv/8h45W40tSTHSZ9Ryre75tPUdEq6PzdrPz4kO3a8O8gtdDltsWR1NSAQAAAKA+Myx64yr7/2oGAAAAAByVGGEEAAAAED7qxx13YaNGBeOnn36qJUuWKDc3VxEREerUqZOGDBmi448/3u3+AQAAAABCxFHBuHPnTg0ePFiZmZmKiIiQ3+/XqaeeqtmzZ2v8+PFKS0vT448/bquvAAAAAIA65Khg/Nvf/qbWrVtr37598nq9uv3221VQUKDMzEx9+umnuvTSS9WmTRvdcssttvoLAAAAAEfmZ0qqmxwtevPRRx/poYceUnx8vLxerx599FHNnDlTBQUFOuecc/Tss89q8uTJtvoKAAAAAKhDjkYYvV6vPJ7/7YUUERGh8vJylZX9tNfMGWecoS1btrjaQQAAAACoNsO2Gm5yNMJ45pln6r777lNhYaFKS0t11113qVOnTmrWrJkkadeuXWratGmVcXw+nwoKCgKav9z+BqcAAAAAgOpzVDA++eSTWrNmjZo0aaK4uDhNmzYtYArq+vXrdfXVV1cZJyMjQwkJCQHth+xPHXceAAAAAGCPoympnTp10tq1a7VkyRKVlJTod7/7nRITEyvOV6dYlKT09HSlpaUFHDv/zy856QoAAAAAHMaw6I2rHO/D2LBhQw0cOLBWSb1er7xeb8CxiMgabQkJAAAAALDE0ZRUSSouLtaSJUu0bt26w84dOnRIM2bMcKVjAAAAAOCY8YeuhSFHBWN2drZSUlLUv39/de3aVampqcrNza04n5+fr1GjRrneSQAAAABA3XNUMI4fP15dunTRzp07lZWVpcaNG6tv377Kycmx1T8AAAAAqDbjNyFr4chRwbh06VJlZGQoMTFRycnJmjt3rgYNGqR+/fpp06ZNtvoIAAAAAAgBRwVjcXGxoqL+tziNx+PR5MmTNXjwYKWmpio7O9v1DgIAAAAAQsPR0qSdO3dWZmamUlJSAo5PmjRJkjRkyBD3egYAAAAAToXp4jOh4miEcdiwYZo5c2bQc5MmTdLw4cNlTHjO3QUAAACA3xxzFDp06JCZMGGCOXToEDlCnCMcXgM56k98ctSvHOHwGshRf+KTo37lCIfXQI76Ex/hzWPM0TckWFBQoISEBOXn5ys+Pp4cIcwRDq+BHPUnPjnqV45weA3kqD/xyVG/coTDayBH/YmP8OZoSioAAAAA4LeDghEAAAAAEBQFIwAAAAAgqKOyYPR6vZowYYK8Xi85QpwjHF4DOepPfHLUrxzh8BrIUX/ik6N+5QiH10CO+hMf4e2oXPQGAAAAAGDfUTnCCAAAAACwj4IRAAAAABAUBSMAAAAAICgKRgAAAABAUEdlwfjiiy+qQ4cOio2NVe/evbVixQrXYn/22WcaPHiwWrduLY/Ho/fee8+12JKUkZGh008/XY0bN1aLFi00dOhQZWVluZpj8uTJOuWUUxQfH6/4+Hj16dNHH330kas5fu3RRx+Vx+PRrbfe6lrM+++/Xx6PJ6B17tzZtfiStG3bNv35z3/WMcccowYNGqhr167KzMx0LX6HDh0Oew0ej0c33XSTaznKy8t17733qmPHjmrQoIGOO+44Pfjgg3J7PasDBw7o1ltvVfv27dWgQQOdccYZ+vLLL2scr6przRij++67T0lJSWrQoIEGDBigDRs2uJpj9uzZGjhwoI455hh5PB6tWbPGtfilpaUaP368unbtqri4OLVu3VojRozQ9u3bXX0N999/vzp37qy4uDg1bdpUAwYM0PLly13N8UvXX3+9PB6Pnn32WVdzXH311YddJ+edd57rr2P9+vUaMmSIEhISFBcXp9NPP105OTmuxA92rXs8Hj3xxBOuvYaDBw9qzJgxatu2rRo0aKCTTjpJU6ZMqXb86uTYsWOHrr76arVu3VoNGzbUeeed5+jaq87n3KFDh3TTTTfpmGOOUaNGjfTHP/5RO3bscDXHK6+8orPOOkvx8fHyeDzav39/teNXJ8fevXt1880368QTT1SDBg3Url07/e1vf1N+fr6rr+Ovf/2rjjvuODVo0EDNmzfXRRddpO+++87VHD8zxuj888939PdPdeKfddZZh10X119/veuvYdmyZTrnnHMUFxen+Ph49e/fX8XFxa7k2LJlyxGv8X/961+uvY68vDxdddVVatWqleLi4nTaaafpnXfeqVb86ub4/vvvNWzYMDVv3lzx8fG69NJLHV1/+O056grGt99+W2lpaZowYYJWrVqlbt26adCgQdq5c6cr8QsLC9WtWze9+OKLrsT7tf/85z+66aab9MUXX2j+/PkqLS3VwIEDVVhY6FqOtm3b6tFHH9XKlSuVmZmpc845RxdddJG+/fZb13L80pdffqmXX35Zp5xyiuuxTz75ZOXm5la0JUuWuBZ737596tu3r6Kjo/XRRx9p3bp1euqpp9S0aVPXcnz55ZcB/Z8/f74k6ZJLLnEtx2OPPabJkydr0qRJWr9+vR577DE9/vjjeuGFF1zLIUl/+ctfNH/+fP3jH//Q119/rYEDB2rAgAHatm1bjeJVda09/vjjev755zVlyhQtX75ccXFxGjRokA4dOuRajsLCQp155pl67LHHXH8NRUVFWrVqle69916tWrVKs2fPVlZWloYMGeJaDkk64YQTNGnSJH399ddasmSJOnTooIEDB2rXrl2u5fjZu+++qy+++EKtW7d29Bqqm+O8884LuF5mzpzpao7vv/9eZ555pjp37qzFixdr7dq1uvfeexUbG+tK/F/2PTc3V1OnTpXH49Ef//hH115DWlqa5s2bpzfeeEPr16/XrbfeqjFjxmjOnDmu5DDGaOjQodq0aZP+/e9/a/Xq1Wrfvr0GDBhQ7c+p6nzOjR07VnPnztW//vUv/ec//9H27dt18cUXV/s1VCdHUVGRzjvvPN11113Vjuskx/bt27V9+3Y9+eST+uabbzRt2jTNmzdP1157rauvo0ePHnr99de1fv16ffzxxzLGaODAgSovL3ctx8+effZZeTyeavffSfzRo0cHXB+PP/64qzmWLVum8847TwMHDtSKFSv05ZdfasyYMYqIqN6fulXlOPbYYw+7xidOnKhGjRrp/PPPd+11jBgxQllZWZozZ46+/vprXXzxxbr00ku1evVqV3IUFhZq4MCB8ng8+vTTT/X555+rpKREgwcPlt/vr1YO/AaZo0yvXr3MTTfdVPF1eXm5ad26tcnIyHA9lyTz7rvvuh73l3bu3Gkkmf/85z9W8zRt2tT8/e9/dz3ugQMHzPHHH2/mz59vUlNTzS233OJa7AkTJphu3bq5Fu/Xxo8fb84880xr8YO55ZZbzHHHHWf8fr9rMS+88EJzzTXXBBy7+OKLzZVXXulajqKiIhMZGWnef//9gOOnnXaaufvuu2sd/9fXmt/vN61atTJPPPFExbH9+/cbr9drZs6c6UqOX9q8ebORZFavXl2j2FXF/9mKFSuMJLN161ZrOfLz840ks2DBAldz/Pjjj6ZNmzbmm2++Me3btzfPPPNMjeIfKcfIkSPNRRddVOOY1clx2WWXmT//+c/W4v/aRRddZM455xxXc5x88snmgQceCDhWm+vw1zmysrKMJPPNN99UHCsvLzfNmzc3r776ao1y/Ppzbv/+/SY6Otr861//qnjM+vXrjSSzbNkyV3L80qJFi4wks2/fvhrFrk6On/3zn/80MTExprS01FqOr776ykgyGzdudDXH6tWrTZs2bUxubm6t/v4JFt/tvw+C5ejdu7e55557rOb4te7dux/2+VvbHHFxcWbGjBkBj2vWrJlr19/HH39sIiIiTH5+fsVj9u/fbzwej5k/f36NciD8HVUjjCUlJVq5cqUGDBhQcSwiIkIDBgzQsmXLQtizmvt56kqzZs2sxC8vL9esWbNUWFioPn36uB7/pptu0oUXXhjwPXHThg0b1Lp1a3Xq1ElXXnlltaeOVcecOXPUs2dPXXLJJWrRooVOPfVUvfrqq67F/7WSkhK98cYbuuaaaxz/B7cyZ5xxhhYuXKjs7GxJ0ldffaUlS5ZU+z+e1VFWVqby8vLDRmIaNGjg6qjvzzZv3qy8vLyAn6uEhAT17t37qL3WpZ+ud4/HoyZNmliJX1JSoldeeUUJCQnq1q2ba3H9fr+uuuoqjRs3TieffLJrcX9t8eLFatGihU488UTdcMMN2rNnj2ux/X6/PvjgA51wwgkaNGiQWrRood69e7t+28HPduzYoQ8++MDRaFN1nHHGGZozZ462bdsmY4wWLVqk7OxsDRw40JX4Pp9PkgKu9YiICHm93hpf67/+nFu5cqVKS0sDru/OnTurXbt2Nb6+bX+WVjdHfn6+4uPjFRUVZSVHYWGhXn/9dXXs2FHHHnusazmKiop0xRVX6MUXX1SrVq1qFLey+JL05ptvKjExUV26dFF6erqKiopcy7Fz504tX75cLVq00BlnnKGWLVsqNTW1Vp9PVX0vVq5cqTVr1tTqGg+W44wzztDbb7+tvXv3yu/3a9asWTp06JDOOussV3L4fD55PB55vd6Kx8TGxioiIsLK5znCRKgrVie2bdtmJJmlS5cGHB83bpzp1auX6/lkeYSxvLzcXHjhhaZv376ux167dq2Ji4szkZGRJiEhwXzwwQeu55g5c6bp0qWLKS4uNsa4/x/EDz/80Pzzn/80X331lZk3b57p06ePadeunSkoKHAlvtfrNV6v16Snp5tVq1aZl19+2cTGxppp06a5Ev/X3n77bRMZGWm2bdvmatzy8nIzfvx44/F4TFRUlPF4POaRRx5xNYcxxvTp08ekpqaabdu2mbKyMvOPf/zDREREmBNOOKHWsX99rX3++edGktm+fXvA4y655BJz6aWXupLjl+pihLG4uNicdtpp5oorrnA9x9y5c01cXJzxeDymdevWZsWKFa7meOSRR8zvf//7ipFxGyOMM2fONP/+97/N2rVrzbvvvmtSUlLM6aefbsrKylzJ8fOoScOGDc3TTz9tVq9ebTIyMozH4zGLFy925TX80mOPPWaaNm1a8fuxJoLlOHTokBkxYoSRZKKiokxMTIyZPn26azlKSkpMu3btzCWXXGL27t1rfD6fefTRR40kM3DgQMfxg33OvfnmmyYmJuawx55++unmjjvucCXHL7kxwlidz+tdu3aZdu3ambvuusv1HC+++KKJi4szksyJJ55Y49HFI+W47rrrzLXXXlvxdU3//jlS/JdfftnMmzfPrF271rzxxhumTZs2ZtiwYa69hmXLlhlJplmzZmbq1Klm1apV5tZbbzUxMTEmOzvbtdfxSzfccINJSUmp0WuoLMe+ffvMwIEDK67x+Ph48/HHH7uWY+fOnSY+Pt7ccsstprCw0Bw8eNCMGTPGSDLXXXddjV8PwhsFYyVsF4zXX3+9ad++vfnhhx9cj+3z+cyGDRtMZmamufPOO01iYqL59ttvXYufk5NjWrRoYb766quKY24XjL+2b98+Ex8f79rU2ujoaNOnT5+AYzfffLP53e9+50r8Xxs4cKD5wx/+4HrcmTNnmrZt25qZM2eatWvXmhkzZphmzZq5Xvhu3LjR9O/f30gykZGR5vTTTzdXXnml6dy5c61jh3vBWFJSYgYPHmxOPfXUgGlAbuU4ePCg2bBhg1m2bJm55pprTIcOHcyOHTtcyZGZmWlatmwZ8I8OGwXjr33//feuTq39+fNj+PDhAY8bPHiwufzyy2sd/9dOPPFEM2bMGMdxq8rxxBNPmBNOOMHMmTPHfPXVV+aFF14wjRo1qvFUsmA5MjMzTbdu3Squ9UGDBpnzzz/fnHfeeY7jB/ucc7tgrOqz1I2Csaoc+fn5plevXua8884zJSUlrufYv3+/yc7ONv/5z3/M4MGDzWmnnVajf0YEy/Hvf//bJCcnmwMHDlQcq+nfP9X9u2bhwoU1nlYbLMfPnxnp6ekBj+3atau58847XcnxS0VFRSYhIcE8+eSTjmNXlWPMmDGmV69eZsGCBWbNmjXm/vvvNwkJCWbt2rWu5fj4449Np06djMfjMZGRkebPf/6zOe2008z1119f49eD8HZUFYw+n89ERkYe9ktsxIgRZsiQIa7ns1kw3nTTTaZt27Zm06ZNVuL/2rnnnuvqf47efffdij8mfm6SKn751HRUoCo9e/as0S//YNq1axfwH1VjjHnppZdM69atXYn/S1u2bDERERHmvffecz1227ZtzaRJkwKOPfjgg+bEE090PZcxPxUnPxdyl156qbngggtqHfPX19rPxcKvC7j+/fubv/3tb67k+CWbBWNJSYkZOnSoOeWUU8zu3btrHL+yHL+WnJxc41HmX+d45plnKq7rX17rERERpn379q7kOJLExEQzZcoUV3L4fD4TFRVlHnzwwYDH3XHHHeaMM86odfxf+uyzz4wks2bNGsdxK8tRVFRkoqOjD7uX+NprrzWDBg1yJccv7d+/3+zcudMY89P6ATfeeKOj2Ef6nPu5WPh1AdeuXTvz9NNPu5Ljl2pbMFaVo6CgwPTp08ece+65NR5RdvI3gc/nMw0bNjRvvfWWKzluueWWI17jqampVl7DwYMHjSQzb948V17Dpk2bjCTzj3/8I+D4pZde6nhWR3Vex4wZM0x0dHTF9eHUkXJs3LjxsHuIjfnpb7i//vWvruT4pV27dlVcFy1btjSPP/64oxz47Tiq7mGMiYlRjx49tHDhwopjfr9fCxcutHJ/ng3GGI0ZM0bvvvuuPv30U3Xs2LFO8vr9/op7U9xw7rnn6uuvv9aaNWsqWs+ePXXllVdqzZo1ioyMdC3Xzw4ePKjvv/9eSUlJrsTr27fvYUtNZ2dnq3379q7E/6XXX39dLVq00IUXXuh67KKiosNWgYuMjLS22llcXJySkpK0b98+ffzxx7roootcz9GxY0e1atUq4FovKCjQ8uXLj5prXfppa41LL71UGzZs0IIFC3TMMcfUSV43r/errrpKa9euDbjWW7durXHjxunjjz92JUcwP/74o/bs2ePa9R4TE6PTTz+9Tq751157TT169HD1PlLpp5+n0tLSOrveExIS1Lx5c23YsEGZmZnVvtar+pzr0aOHoqOjA67vrKws5eTkVPv6rovP0urkKCgo0MCBAxUTE6M5c+ZUe8VdJzmCPccYU+1rvKocd95552HXuCQ988wzev311628hp9zVPf6ripHhw4d1Lp161pd305ex2uvvaYhQ4aoefPm1Ypd3Rw/39dZm2vcyetITExUkyZN9Omnn2rnzp2OV/HGb0hIytRamDVrlvF6vWbatGlm3bp15rrrrjNNmjQxeXl5rsQ/cOCAWb16tVm9erWRVHGvS01XNfy1G264wSQkJJjFixeb3NzcilZUVORKfGOMufPOO81//vMfs3nzZrN27Vpz5513Go/HYz755BPXcgTj9pTU2267zSxevNhs3rzZfP7552bAgAEmMTGxxv/R+7UVK1aYqKgo8/DDD5sNGzaYN9980zRs2NC88cYbrsT/WXl5uWnXrp0ZP368q3F/NnLkSNOmTRvz/vvvm82bN5vZs2ebxMTEGk3tqsy8efPMRx99ZDZt2mQ++eQT061bN9O7d+8aT7+q6lp79NFHTZMmTSrua7voootMx44dHf0Hv6oce/bsMatXrzYffPCBkWRmzZplVq9ebXJzc2sdv6SkxAwZMsS0bdvWrFmzJuB69/l8rryGgwcPmvT0dLNs2TKzZcsWk5mZaUaNGmW8Xu9h/6Guzfv0azWZklpZjgMHDpjbb7/dLFu2zGzevNksWLDAnHbaaeb44483hw4dcu11zJ4920RHR5tXXnnFbNiwwbzwwgsmMjLS/Pe//3UlvjE/TU1s2LChmTx5sqP3p7o5UlNTzcknn2wWLVpkNm3aZF5//XUTGxtrXnrpJddy/POf/zSLFi0y33//vXnvvfdM+/btzcUXX1zt+NX5nLv++utNu3btzKeffmoyMzNNnz59DrtFoLY5cnNzzerVq82rr75qJJnPPvvMrF692uzZs8eVHPn5+aZ3796ma9euZuPGjQGPqe4sm6pyfP/99+aRRx4xmZmZZuvWrebzzz83gwcPNs2aNav2tPOa/N0hBzOsqoq/ceNG88ADD5jMzEyzefNm8+9//9t06tTJ9O/fv1rxq/sannnmGRMfH2/+9a9/mQ0bNph77rnHxMbGVnvaa3Xfpw0bNhiPx2M++uijave/ujlKSkpMcnKy6devn1m+fLnZuHGjefLJJ43H46n2WhTVeR1Tp041y5YtMxs3bjT/+Mc/TLNmzUxaWprj14PfjqOuYDTGmBdeeMG0a9fOxMTEmF69epkvvvjCtdg/T135dRs5cqQr8YPFlmRef/11V+IbY8w111xj2rdvb2JiYkzz5s3Nueeea71YNMb9gvGyyy4zSUlJJiYmxrRp08ZcdtllNb7R/0jmzp1runTpYrxer+ncubN55ZVXXI1vzE/3CkgyWVlZrsc25qfpULfccotp166diY2NNZ06dTJ33323o6KkOt5++23TqVMnExMTY1q1amVuuukms3///hrHq+pa8/v95t577zUtW7Y0Xq/XnHvuuY7fw6pyvP7660HPT5gwodbxf57mGqwtWrTIlddQXFxshg0bZlq3bm1iYmJMUlKSGTJkiONFb5z+3qtJwVhZjqKiIjNw4EDTvHlzEx0dbdq3b29Gjx7t+B+B1Xkdr732mklOTjaxsbGmW7dujqaJVyf+yy+/bBo0aFDja6OqHLm5uebqq682rVu3NrGxsebEE080Tz31lKOteqrK8dxzz5m2bdua6Oho065dO3PPPfc4+n1Snc+54uJic+ONN5qmTZuahg0bmmHDhlX7HzXVzTFhwoRafd5WleNI76Mks3nzZldybNu2zZx//vmmRYsWJjo62rRt29ZcccUV5rvvvnP1vQr2nOoWjFXFz8nJMf379zfNmjUzXq/XJCcnm3Hjxjm6n7u6ryEjI8O0bdvWNGzY0PTp06fa/wxykiM9Pd0ce+yxpry8vNqxneTIzs42F198sWnRooVp2LChOeWUUw7bZqO2OcaPH29atmxpoqOjzfHHH+/4dwh+ezzGGCMAAAAAAH7lqLqHEQAAAABQdygYAQAAAABBUTACAAAAAIKiYAQAAAAABEXBCAAAAAAIioIRAAAAABAUBSMAAAAAICgKRgAAAABAUBSMAAAAAICgKBgBAAAAAEFRMAIAAAAAgqJgBAAAAAAE9f8Age9PcewxOqUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.9\n",
        "highly_correlated = np.where(np.abs(correlation_matrix) > threshold)\n",
        "correlated_features = set()\n",
        "\n",
        "# Iterate over the indices of highly correlated features\n",
        "for x, y in zip(*highly_correlated):\n",
        "    if x != y and x < y:  # Ensure not to include self-correlation and only include one pair of each feature\n",
        "        feature1 = correlation_matrix.index[x]\n",
        "        feature2 = correlation_matrix.columns[y]\n",
        "        correlation = correlation_matrix.iloc[x, y]\n",
        "        correlated_features.add((feature1, feature2, correlation))\n",
        "print(\"Highly Correlated Features:\")\n",
        "for feature1, feature2, correlation in correlated_features:\n",
        "    print(f\"{feature1} - {feature2}: {correlation:.2f}\")\n",
        "\n",
        "features_to_remove = set()\n",
        "for feature1, feature2, _ in correlated_features:\n",
        "    features_to_remove.add(feature2)\n",
        "\n",
        "# Remove highly correlated features from the dataset\n",
        "data_filtered = df_describe.drop(columns=features_to_remove)\n",
        "\n",
        "print(\"\\nRemoved Features:\")\n",
        "print(features_to_remove)\n",
        "print(\"Shape of the filtered dataset:\", data_filtered.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omU7SL1AB25g",
        "outputId": "79ac51dc-affc-4ae0-cfe3-a957c21f3c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highly Correlated Features:\n",
            "0 - 3: 0.99\n",
            "0 - 23: 0.94\n",
            "0 - 22: 0.97\n",
            "0 - 2: 1.00\n",
            "10 - 13: 0.95\n",
            "10 - 12: 0.97\n",
            "2 - 23: 0.94\n",
            "22 - 23: 0.98\n",
            "2 - 20: 0.97\n",
            "7 - 27: 0.91\n",
            "12 - 13: 0.94\n",
            "2 - 22: 0.97\n",
            "20 - 23: 0.98\n",
            "2 - 3: 0.99\n",
            "3 - 20: 0.96\n",
            "0 - 20: 0.97\n",
            "1 - 21: 0.91\n",
            "20 - 22: 0.99\n",
            "3 - 23: 0.96\n",
            "6 - 7: 0.92\n",
            "3 - 22: 0.96\n",
            "\n",
            "Removed Features:\n",
            "{2, 3, 7, 12, 13, 20, 21, 22, 23, 27}\n",
            "Shape of the filtered dataset: (569, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_breast = data_filtered\n",
        "Y_breast = data.target\n",
        "print(type(X_breast), type(Y_breast))\n",
        "X_breast, Y_breast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N25CdMXBKXwd",
        "outputId": "1338ae50-ab2b-4dc2-8fe5-6c823f9a2299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        0      1        4        5        6       8        9       10      11  \\\n",
              " 0    17.99  10.38  0.11840  0.27760  0.30010  0.2419  0.07871  1.0950  0.9053   \n",
              " 1    20.57  17.77  0.08474  0.07864  0.08690  0.1812  0.05667  0.5435  0.7339   \n",
              " 2    19.69  21.25  0.10960  0.15990  0.19740  0.2069  0.05999  0.7456  0.7869   \n",
              " 3    11.42  20.38  0.14250  0.28390  0.24140  0.2597  0.09744  0.4956  1.1560   \n",
              " 4    20.29  14.34  0.10030  0.13280  0.19800  0.1809  0.05883  0.7572  0.7813   \n",
              " ..     ...    ...      ...      ...      ...     ...      ...     ...     ...   \n",
              " 564  21.56  22.39  0.11100  0.11590  0.24390  0.1726  0.05623  1.1760  1.2560   \n",
              " 565  20.13  28.25  0.09780  0.10340  0.14400  0.1752  0.05533  0.7655  2.4630   \n",
              " 566  16.60  28.08  0.08455  0.10230  0.09251  0.1590  0.05648  0.4564  1.0750   \n",
              " 567  20.60  29.33  0.11780  0.27700  0.35140  0.2397  0.07016  0.7260  1.5950   \n",
              " 568   7.76  24.54  0.05263  0.04362  0.00000  0.1587  0.05884  0.3857  1.4280   \n",
              " \n",
              "            14       15       16       17       18        19       24       25  \\\n",
              " 0    0.006399  0.04904  0.05373  0.01587  0.03003  0.006193  0.16220  0.66560   \n",
              " 1    0.005225  0.01308  0.01860  0.01340  0.01389  0.003532  0.12380  0.18660   \n",
              " 2    0.006150  0.04006  0.03832  0.02058  0.02250  0.004571  0.14440  0.42450   \n",
              " 3    0.009110  0.07458  0.05661  0.01867  0.05963  0.009208  0.20980  0.86630   \n",
              " 4    0.011490  0.02461  0.05688  0.01885  0.01756  0.005115  0.13740  0.20500   \n",
              " ..        ...      ...      ...      ...      ...       ...      ...      ...   \n",
              " 564  0.010300  0.02891  0.05198  0.02454  0.01114  0.004239  0.14100  0.21130   \n",
              " 565  0.005769  0.02423  0.03950  0.01678  0.01898  0.002498  0.11660  0.19220   \n",
              " 566  0.005903  0.03731  0.04730  0.01557  0.01318  0.003892  0.11390  0.30940   \n",
              " 567  0.006522  0.06158  0.07117  0.01664  0.02324  0.006185  0.16500  0.86810   \n",
              " 568  0.007189  0.00466  0.00000  0.00000  0.02676  0.002783  0.08996  0.06444   \n",
              " \n",
              "          26      28       29  \n",
              " 0    0.7119  0.4601  0.11890  \n",
              " 1    0.2416  0.2750  0.08902  \n",
              " 2    0.4504  0.3613  0.08758  \n",
              " 3    0.6869  0.6638  0.17300  \n",
              " 4    0.4000  0.2364  0.07678  \n",
              " ..      ...     ...      ...  \n",
              " 564  0.4107  0.2060  0.07115  \n",
              " 565  0.3215  0.2572  0.06637  \n",
              " 566  0.3403  0.2218  0.07820  \n",
              " 567  0.9387  0.4087  0.12400  \n",
              " 568  0.0000  0.2871  0.07039  \n",
              " \n",
              " [569 rows x 20 columns],\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAhKax1Kk_lA",
        "outputId": "ed6257ad-6522-4b3f-febf-06d531badc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ionosphere\n",
        "\n",
        "\n",
        "*   This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.\n",
        "*   The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere.  \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
        "\n"
      ],
      "metadata": {
        "id": "MVj3fT7BHImk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_ionsphere():\n",
        "  # fetch dataset\n",
        "  ionosphere = fetch_ucirepo(id=52)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = ionosphere.data.features\n",
        "  y = ionosphere.data.targets\n",
        "\n",
        "  missing_values_features = X.isnull().sum().sum()  # Checking is null with every feature, then sum\n",
        "  missing_values_targets = y.isnull().sum().sum()\n",
        "\n",
        "  if missing_values_features == 0 and missing_values_targets == 0:\n",
        "      print(\"No missing data in features and targets.\")\n",
        "  else:\n",
        "      print(f\"Missing data detected! Features missing values: {missing_values_features}, Targets missing values: {missing_values_targets}\")\n",
        "\n",
        "  #Mapping target classes b - bad to 0, g - good to 1\n",
        "  y['Class'] = y['Class'].replace({'b': 0, 'g': 1})\n",
        "\n",
        "  print(\"Tail features ionsphere data\", X.tail)\n",
        "  print(\"Tail targets ionsphere data\", y.tail)\n",
        "\n",
        "  return X, y\n"
      ],
      "metadata": {
        "id": "jjLOTXySHUss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ionsphere_X, ionsphere_y = fetch_ionsphere()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYETmQKiI7lz",
        "outputId": "ed6aa047-09ce-47b4-ad51-4ce8e0cdf4ba"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing data in features and targets.\n",
            "Tail features ionsphere data <bound method NDFrame.tail of      Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
            "0             1           0     0.99539    -0.05889     0.85243     0.02306   \n",
            "1             1           0     1.00000    -0.18829     0.93035    -0.36156   \n",
            "2             1           0     1.00000    -0.03365     1.00000     0.00485   \n",
            "3             1           0     1.00000    -0.45161     1.00000     1.00000   \n",
            "4             1           0     1.00000    -0.02401     0.94140     0.06531   \n",
            "..          ...         ...         ...         ...         ...         ...   \n",
            "346           1           0     0.83508     0.08298     0.73739    -0.14706   \n",
            "347           1           0     0.95113     0.00419     0.95183    -0.02723   \n",
            "348           1           0     0.94701    -0.00034     0.93207    -0.03227   \n",
            "349           1           0     0.90608    -0.01657     0.98122    -0.01989   \n",
            "350           1           0     0.84710     0.13533     0.73638    -0.06151   \n",
            "\n",
            "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute25  \\\n",
            "0       0.83398    -0.37708     1.00000      0.03760  ...      0.56811   \n",
            "1      -0.10868    -0.93597     1.00000     -0.04549  ...     -0.20332   \n",
            "2       1.00000    -0.12062     0.88965      0.01198  ...      0.57528   \n",
            "3       0.71216    -1.00000     0.00000      0.00000  ...      1.00000   \n",
            "4       0.92106    -0.23255     0.77152     -0.16399  ...      0.03286   \n",
            "..          ...         ...         ...          ...  ...          ...   \n",
            "346     0.84349    -0.05567     0.90441     -0.04622  ...      0.95378   \n",
            "347     0.93438    -0.01920     0.94590      0.01606  ...      0.94520   \n",
            "348     0.95177    -0.03431     0.95584      0.02446  ...      0.93988   \n",
            "349     0.95691    -0.03646     0.85746      0.00110  ...      0.91050   \n",
            "350     0.87873     0.08260     0.88928     -0.09139  ...      0.86467   \n",
            "\n",
            "     Attribute26  Attribute27  Attribute28  Attribute29  Attribute30  \\\n",
            "0       -0.51171      0.41078     -0.46168      0.21266     -0.34090   \n",
            "1       -0.26569     -0.20468     -0.18401     -0.19040     -0.11593   \n",
            "2       -0.40220      0.58984     -0.22145      0.43100     -0.17365   \n",
            "3        0.90695      0.51613      1.00000      1.00000     -0.20099   \n",
            "4       -0.65158      0.13290     -0.53206      0.02431     -0.62197   \n",
            "..           ...          ...          ...          ...          ...   \n",
            "346     -0.04202      0.83479      0.00123      1.00000      0.12815   \n",
            "347      0.01361      0.93522      0.04925      0.93159      0.08168   \n",
            "348      0.03193      0.92489      0.02542      0.92120      0.02242   \n",
            "349     -0.02099      0.89147     -0.07760      0.82983     -0.17238   \n",
            "350     -0.15114      0.81147     -0.04822      0.78207     -0.00703   \n",
            "\n",
            "     Attribute31  Attribute32  Attribute33  Attribute34  \n",
            "0        0.42267     -0.54487      0.18641     -0.45300  \n",
            "1       -0.16626     -0.06288     -0.13738     -0.02447  \n",
            "2        0.60436     -0.24180      0.56045     -0.38238  \n",
            "3        0.25682      1.00000     -0.32382      1.00000  \n",
            "4       -0.05707     -0.59573     -0.04608     -0.65697  \n",
            "..           ...          ...          ...          ...  \n",
            "346      0.86660     -0.10714      0.90546     -0.04307  \n",
            "347      0.94066     -0.00035      0.91483      0.04712  \n",
            "348      0.92459      0.00442      0.92697     -0.00577  \n",
            "349      0.96022     -0.03757      0.87403     -0.16243  \n",
            "350      0.75747     -0.06678      0.85764     -0.06151  \n",
            "\n",
            "[351 rows x 34 columns]>\n",
            "Tail targets ionsphere data <bound method NDFrame.tail of      Class\n",
            "0        1\n",
            "1        0\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "..     ...\n",
            "346      1\n",
            "347      1\n",
            "348      1\n",
            "349      1\n",
            "350      1\n",
            "\n",
            "[351 rows x 1 columns]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-fa38c4d6c518>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y['Class'] = y['Class'].replace({'b': 0, 'g': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(ionsphere_X), type(ionsphere_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOEio-VYKuDa",
        "outputId": "4bb49310-4977-46c7-946d-235c7f4d5db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 another datasets"
      ],
      "metadata": {
        "id": "fTvOJDFaQRUl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz6k-V1LpDjN",
        "outputId": "074d7518-a6d0-479b-b178-73d3479c1d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HhAH-0XfqHJL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Erasing colinearities**"
      ],
      "metadata": {
        "id": "B1bVz2-jm20T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq"
      ],
      "metadata": {
        "id": "Y8W7nSqSukP1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_collinearity(columns, indices, threshold = 1e-10):\n",
        "  \"\"\"\n",
        "  Helper function, testing whether a certain subset of columns is collinear.\n",
        "  :param columns: the whole set of columns.\n",
        "  :param indices: indices belonging to the subset.\n",
        "  :param threshold: the value of determinant, going below which will be\n",
        "    considered being numerically collinear.\n",
        "  :return: True if collinear, False otherwise.\n",
        "  \"\"\"\n",
        "  used_columns = []\n",
        "  for index in indices:\n",
        "    used_columns.append(columns[index])\n",
        "\n",
        "  X = np.column_stack(used_columns)\n",
        "  XX = X.transpose() @ X\n",
        "  if np.linalg.det(XX) < threshold:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def remove_collinear(X):\n",
        "  \"\"\"\n",
        "  Removes the minimum number of columns to ensure the result matrix will be\n",
        "  full rank.\n",
        "  :param X: a numpy matrix one needs a non-collinear version of.\n",
        "  :return: a numpy matrix with collinearities removed and a set containing\n",
        "    indices of removed columns.\n",
        "  \"\"\"\n",
        "  columns = []\n",
        "  p = len(X[0])\n",
        "  for i in range(p):\n",
        "    columns.append(X[:,i])\n",
        "\n",
        "  columns_used = []\n",
        "  columns_stashed = set()\n",
        "  columns_removed = set()\n",
        "  for i in range(p):\n",
        "    columns_used.append(i)\n",
        "\n",
        "  heapq.heapify(columns_used)\n",
        "\n",
        "  last_removed = -1\n",
        "  while(True):\n",
        "    if len(columns_used) == 0:\n",
        "      break\n",
        "\n",
        "    if test_collinearity(columns, columns_used):\n",
        "      last_removed = heapq.heappop(columns_used)\n",
        "      columns_stashed.add(last_removed)\n",
        "    else:\n",
        "      if last_removed == -1:\n",
        "        # If the whole remaining subset is non-collinear, it's time to stop.\n",
        "\n",
        "        break\n",
        "      else:\n",
        "        # If removing a certain column made the subset non-collinear, it means\n",
        "        # that this column is a good candidate for removal.\n",
        "\n",
        "        columns_stashed.remove(last_removed)\n",
        "        columns_removed.add(last_removed)\n",
        "\n",
        "        # Returning stashed away columns back to the subset.\n",
        "        for index in columns_stashed:\n",
        "          columns_used.append(index)\n",
        "        heapq.heapify(columns_used)\n",
        "        columns_stashed.clear()\n",
        "        last_removed = -1\n",
        "\n",
        "  # Recreating the matrix\n",
        "  is_used = [False for i in range(p)]\n",
        "  for index in columns_used:\n",
        "    is_used[index] = True\n",
        "\n",
        "  columns_used = []\n",
        "  for i in range(p):\n",
        "    if is_used[i]:\n",
        "      columns_used.append(columns[i])\n",
        "\n",
        "  X_clean = np.column_stack(columns_used)\n",
        "  return X_clean, columns_removed\n"
      ],
      "metadata": {
        "id": "VsETljLgnCaL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Heart Disease dataset** (https://archive.ics.uci.edu/dataset/45/heart+disease)"
      ],
      "metadata": {
        "id": "lWnUmg6Nt37V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's perform some EDA:\n",
        "\n",
        "# fetch dataset\n",
        "data_heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = data_heart_disease.data.features\n",
        "y = data_heart_disease.data.targets\n",
        "\n",
        "print(X.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJhgz3kTskyx",
        "outputId": "2940c45a-bdb0-4bfa-f419-2865f0de9901"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age           int64\n",
            "sex           int64\n",
            "cp            int64\n",
            "trestbps      int64\n",
            "chol          int64\n",
            "fbs           int64\n",
            "restecg       int64\n",
            "thalach       int64\n",
            "exang         int64\n",
            "oldpeak     float64\n",
            "slope         int64\n",
            "ca          float64\n",
            "thal        float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the amount of missing values.\n",
        "print('missing values\\n')\n",
        "for name in X.columns:\n",
        "  print(name+': '+str(X[name].isnull().sum()))\n",
        "\n",
        "print('\\nAmount of data points:',len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td1grVCvqcqy",
        "outputId": "893c1bb1-0afa-4302-fc34-7e301ea6b529"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values\n",
            "\n",
            "age: 0\n",
            "sex: 0\n",
            "cp: 0\n",
            "trestbps: 0\n",
            "chol: 0\n",
            "fbs: 0\n",
            "restecg: 0\n",
            "thalach: 0\n",
            "exang: 0\n",
            "oldpeak: 0\n",
            "slope: 0\n",
            "ca: 4\n",
            "thal: 2\n",
            "\n",
            "Amount of data points: 303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one can see, the number of missing values is miniscule compared to the amount of data points we have, so not to complicate stuff too much, we can just remove the incomplete observations if need be."
      ],
      "metadata": {
        "id": "djdbBjcJvDWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the number of categories for each variable.\n",
        "print('different values present\\n')\n",
        "for name in X.columns:\n",
        "  print(name+': '+str(X[name].nunique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd-x2e44u_ST",
        "outputId": "52b1fccf-1958-46f8-907f-a394c4824a6b"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "different values present\n",
            "\n",
            "age: 41\n",
            "sex: 2\n",
            "cp: 4\n",
            "trestbps: 50\n",
            "chol: 152\n",
            "fbs: 2\n",
            "restecg: 3\n",
            "thalach: 91\n",
            "exang: 2\n",
            "oldpeak: 40\n",
            "slope: 3\n",
            "ca: 4\n",
            "thal: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the https://archive.ics.uci.edu/dataset/45/heart+disease page, 'cp', 'restecg', 'slope' and 'thal' are categorical variables that have more than 2 possible values, so they should be one-hot-encoded before building the model."
      ],
      "metadata": {
        "id": "u6cwF2uMwmGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, looking at the target variable:"
      ],
      "metadata": {
        "id": "B9tceEjixZHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YxIwWcZqoDo",
        "outputId": "60d9f047-61bd-4dd5-932e-9449110d682d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are 5 possible values for that. In accordance to the experiments mentioned on the dataset's page, we will transform the answers column to have two classes:\n",
        "\n",
        "0 <- no presence of heart disease (original values: 0)\n",
        "\n",
        "1 <- presence of heart disease (original values: 1, 2, 3 ,4)\n",
        "\n",
        "\n",
        "So finally, for a function that returns this dataset in a form palatable for model training:"
      ],
      "metadata": {
        "id": "hdNABKXpxflx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_heart_disease():\n",
        "  # fetch dataset\n",
        "  data_heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = data_heart_disease.data.features\n",
        "  y = data_heart_disease.data.targets\n",
        "\n",
        "  # removing missing variables\n",
        "  X = X.dropna()\n",
        "  y = y.loc[X.index]\n",
        "\n",
        "  # one-hot-encoding the detected multi-valued categorical variables\n",
        "  X = pd.get_dummies(X, columns=['cp', 'restecg', 'slope', 'thal'],\n",
        "                     drop_first=True, dtype=int)\n",
        "\n",
        "  # changing the format to numpy arrays\n",
        "  # (flattening is necessary for y as .values isn't smart enough to notice that\n",
        "  # y had only one column)\n",
        "  X = X.values\n",
        "  y = y.values.flatten()\n",
        "\n",
        "  # mapping the answers to {0,1}\n",
        "  y = (y==0)\n",
        "  y = y.astype(int)\n",
        "\n",
        "  # removing collinearities\n",
        "  X, _ = remove_collinear(X)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "NmPpUnPYyI3o"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_heart, y_heart = fetch_heart_disease()"
      ],
      "metadata": {
        "id": "c0LSUsh85Cmj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parkinsons dataset** (https://archive.ics.uci.edu/dataset/174/parkinsons)"
      ],
      "metadata": {
        "id": "JgWvEfsJ-Igc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of the EDA, this time everything is noted on the page.\n",
        "There are no missing values, every feature is continous and the target variable is indeed a {0,1} binary value, so the only thing we need to do is to fetch the dataset and turn it into an appropriate numpy arrays."
      ],
      "metadata": {
        "id": "lZKBVDRO-UR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_parkinsons():\n",
        "  # fetch dataset\n",
        "  data_parkinsons = fetch_ucirepo(id=174)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = data_parkinsons.data.features\n",
        "  y = data_parkinsons.data.targets\n",
        "\n",
        "  # changing the format to numpy arrays\n",
        "  # (flattening is necessary for y as .values isn't smart enough to notice that\n",
        "  # y had only one column)\n",
        "  X = X.values\n",
        "  y = y.values.flatten()\n",
        "\n",
        "  # removing collinearities\n",
        "  X, _ = remove_collinear(X)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "hVGbZYAP-SfJ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_parkinsons()"
      ],
      "metadata": {
        "id": "APVfU8Ao_you"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some columns have been removed\n",
        "print(len(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ljA_Kh5pXK",
        "outputId": "305d2f07-8b6c-4f62-d1bb-abb1d965a49d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HCV dataset** (https://archive.ics.uci.edu/dataset/571/hcv+data)"
      ],
      "metadata": {
        "id": "3V7RjCPJAFGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's perform some EDA:\n",
        "\n",
        "# fetch dataset\n",
        "data_hcv = fetch_ucirepo(id=571)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = data_hcv.data.features\n",
        "y = data_hcv.data.targets\n",
        "\n",
        "print(X.dtypes)\n",
        "print(y.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsVeTRcYCY6k",
        "outputId": "4835610c-3ff3-484d-c2e0-b15447f5dfa1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Age       int64\n",
            "Sex      object\n",
            "ALB     float64\n",
            "ALP     float64\n",
            "AST     float64\n",
            "BIL     float64\n",
            "CHE     float64\n",
            "CHOL    float64\n",
            "CREA    float64\n",
            "CGT     float64\n",
            "PROT    float64\n",
            "ALT     float64\n",
            "dtype: object\n",
            "Category    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(X['Sex']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFA1nAW3pynj",
        "outputId": "70982472-02a6-40d8-ef8b-3fd764e8347b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['f' 'm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the types, it's obvious that we'll need to map the 'Sex' column to {0,1}."
      ],
      "metadata": {
        "id": "jTXkEP8AkQca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the amount of missing values.\n",
        "print('missing values\\n')\n",
        "for name in X.columns:\n",
        "  print(name+': '+str(X[name].isnull().sum()))\n",
        "\n",
        "print('\\nAmount of data points:',len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao7Gb2o4j_-T",
        "outputId": "bb044a84-524c-4b24-9bec-959cde0472e2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values\n",
            "\n",
            "Age: 0\n",
            "Sex: 0\n",
            "ALB: 1\n",
            "ALP: 18\n",
            "AST: 0\n",
            "BIL: 0\n",
            "CHE: 0\n",
            "CHOL: 10\n",
            "CREA: 0\n",
            "CGT: 0\n",
            "PROT: 1\n",
            "ALT: 1\n",
            "\n",
            "Amount of data points: 615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that apart from the 'ALP' and 'CHOL' columns, there aren't that many missing values, so the plan seems to be removing the observations, where 'ALB', 'PROT' or 'ALT' is missing and then using some regressor to predict the values of 'ALP' and 'CHOL' when necessary."
      ],
      "metadata": {
        "id": "YE92H8I4k5wL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the https://archive.ics.uci.edu/dataset/571/hcv+data page, there are no categorical features, only the target variable is categorical, so there is no need for one-hot-encoding.\n",
        "\n",
        "Speaking of the target variable, it has 5 different values:"
      ],
      "metadata": {
        "id": "LUR9U4k-lyBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YleIV_0ml-cO",
        "outputId": "2ccae1c1-5a81-40fb-9fc3-24d5892d064e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0=Blood Donor', '0s=suspect Blood Donor', '1=Hepatitis',\n",
              "       '2=Fibrosis', '3=Cirrhosis'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus we'll group those categories into:\n",
        "\n",
        "0 <- all blood donors (original values: 0 and 0s)\n",
        "\n",
        "1 <- all the nasty stuff (orignal values: 1, 2 and 3)\n",
        "\n",
        "Now for the fetching function:"
      ],
      "metadata": {
        "id": "laqI4D69mlXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "4AvWYePZqEQe"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_hcv():\n",
        "  # fetch dataset\n",
        "  data_hcv = fetch_ucirepo(id=571)\n",
        "\n",
        "  # data (as pandas dataframes)\n",
        "  X = data_hcv.data.features\n",
        "  y = data_hcv.data.targets\n",
        "\n",
        "  # mapping the 'Sex' column to numeric values\n",
        "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
        "  # mapping the target variable to {0,1}\n",
        "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n",
        "                                           '0s=suspect Blood Donor': 0,\n",
        "                                           '1=Hepatitis': 1, '2=Fibrosis': 1,\n",
        "                                           '3=Cirrhosis': 1})\n",
        "\n",
        "  # removing rare missing values\n",
        "  X = X.dropna(subset=['ALB','PROT','ALT'])\n",
        "  y = y.loc[X.index]\n",
        "\n",
        "  # Regressing for the remaining missing values\n",
        "  X_for_lr = X.dropna()\n",
        "  y_for_lr1 = X_for_lr['ALP'].values\n",
        "  y_for_lr2 = X_for_lr['CHOL'].values\n",
        "  X_for_lr = X_for_lr.drop(columns=['ALP','CHOL']).values\n",
        "\n",
        "  lr = LinearRegression()\n",
        "\n",
        "  lr.fit(X_for_lr, y_for_lr1)\n",
        "  ALP_missing = X[X['ALP'].isna()]\n",
        "  data_for_ALP_predicting = ALP_missing.drop(columns=['ALP', 'CHOL']).values\n",
        "  ALP_predictions = lr.predict(data_for_ALP_predicting)\n",
        "  X.loc[X['ALP'].isna(), 'ALP'] = ALP_predictions\n",
        "\n",
        "  lr.fit(X_for_lr, y_for_lr2)\n",
        "  CHOL_missing = X[X['CHOL'].isna()]\n",
        "  data_for_CHOL_predicting = CHOL_missing.drop(columns=['ALP', 'CHOL']).values\n",
        "  CHOL_predictions = lr.predict(data_for_CHOL_predicting)\n",
        "  X.loc[X['CHOL'].isna(), 'CHOL'] = CHOL_predictions\n",
        "\n",
        "  # changing the format to numpy arrays\n",
        "  # (flattening is necessary for y as .values isn't smart enough to notice that\n",
        "  # y had only one column)\n",
        "  X = X.values\n",
        "  y = y.values.flatten()\n",
        "\n",
        "  # removing collinearities\n",
        "  X, _ = remove_collinear(X)\n",
        "\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "BXYYTvpxnHWK"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = fetch_hcv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwXga6Le59__",
        "outputId": "e5a8230f-d008-46bf-e455-94dc983be8fd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-aee083fc4a77>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
            "<ipython-input-82-aee083fc4a77>:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
            "<ipython-input-82-aee083fc4a77>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n",
            "<ipython-input-82-aee083fc4a77>:12: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pai3dyAQ656N",
        "outputId": "f398a6fd-77b5-4419-f72a-bce5770e7a98"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load small datasets"
      ],
      "metadata": {
        "id": "k70trbB21DSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adam"
      ],
      "metadata": {
        "id": "iLX8_E_-074J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "cL7q8sJOsUiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lrii3Mwrxcq"
      },
      "outputs": [],
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Logistic regression cost-function (Cross-entropy loss)\n",
        "def logistic_loss(X, y, weights):\n",
        "    z = np.dot(X, weights)\n",
        "    predictions = sigmoid(z)\n",
        "    loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
        "    return loss\n",
        "\n",
        "# Gradient of the logistic regression cost-function\n",
        "def logistic_gradient(X, y, weights):\n",
        "    predictions = sigmoid(np.dot(X, weights))\n",
        "    gradient = np.dot(X.T, (predictions - y)) / y.size\n",
        "    return gradient\n",
        "\n",
        "# Function to add custom interactions between the variables\n",
        "def add_custom_interactions(X, interaction_indices):\n",
        "    interactions = np.array([X[:, i] * X[:, j] for i, j in interaction_indices]).T\n",
        "    return np.hstack((X, interactions))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "# Generate predictions from the custom logistic regression model\n",
        "def balanced_accuracy(X, y, custom_weights):\n",
        "  if custom_weights.size == X.shape[1] + 1:\n",
        "        # Add a column of ones to X to account for the bias term in the weights\n",
        "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "  y_pred_probs_custom = sigmoid(np.dot(X, custom_weights))\n",
        "\n",
        "  y_pred_custom = (y_pred_probs_custom >= 0.5).astype(int)\n",
        "\n",
        "  bal_acc_custom = balanced_accuracy_score(y, y_pred_custom)\n",
        "  return bal_acc_custom"
      ],
      "metadata": {
        "id": "HuQ4u1Eu-zvc"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_log_likelihood(X, y, weights):\n",
        "    logits = np.dot(X, weights)\n",
        "    log_likelihood = np.sum(y * logits - np.log1p(np.exp(logits)))\n",
        "    return log_likelihood"
      ],
      "metadata": {
        "id": "m2GfS90_v25_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adam_logistic_regression(X, y, alpha, beta1, beta2, epsilon=1e-8, max_iterations=1000, interaction_indices=None, threshold=1e-6):\n",
        "    # If interaction_indices is provided, augment the feature set with specified interaction terms\n",
        "    if interaction_indices:\n",
        "        X = add_custom_interactions(X, interaction_indices)\n",
        "\n",
        "    # Initialize weights\n",
        "    weights = np.zeros(X.shape[1])\n",
        "\n",
        "    # Initialize first moment and second moment\n",
        "    m = np.zeros(X.shape[1])\n",
        "    v = np.zeros(X.shape[1])\n",
        "    log_likelihood_history = []\n",
        "    for t in range(1, max_iterations+1):\n",
        "        # Compute the gradient\n",
        "        g = logistic_gradient(X, y, weights)\n",
        "\n",
        "        # Update moments\n",
        "        m = beta1 * m + (1 - beta1) * g\n",
        "        v = beta2 * v + (1 - beta2) * np.square(g)\n",
        "\n",
        "        # Compute bias-corrected moments\n",
        "        m_corrected = m / (1 - beta1 ** t)\n",
        "        v_corrected = v / (1 - beta2 ** t)\n",
        "\n",
        "        beta_old = np.copy(weights)\n",
        "        # Update weights\n",
        "        weights -= alpha * m_corrected / (np.sqrt(v_corrected) + epsilon)\n",
        "\n",
        "        # Print the loss value occasionally to monitor progress\n",
        "        if t % 100 == 0 or t == 1:\n",
        "            loss = logistic_loss(X, y, weights)\n",
        "            print(f'Iteration {t}/{max_iterations} - Loss: {loss}')\n",
        "\n",
        "        # Calculate log-likelihood and append to history after the update\n",
        "        current_log_likelihood = compute_log_likelihood(X, y, weights)\n",
        "        log_likelihood_history.append(current_log_likelihood)\n",
        "\n",
        "        # Convergence check based on weights change\n",
        "        diff = beta_old - weights\n",
        "        diff_norm = np.linalg.norm(diff)\n",
        "        if diff_norm < threshold:\n",
        "            print(f\"Algorithm stopped due to convergence at iteration {t}. Norm of weight difference: {diff_norm:.6f}\")\n",
        "            break\n",
        "\n",
        "        # If the algorithm did not converge within the max iterations, print that information\n",
        "        if t == max_iterations:\n",
        "          print(f\"Algorithm reached the maximum number of iterations: {max_iterations}\")\n",
        "\n",
        "    return weights, log_likelihood_history"
      ],
      "metadata": {
        "id": "0nAKQr0Fvj8S"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on fake data"
      ],
      "metadata": {
        "id": "ARjb2OGb4gWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_data(n: int):\n",
        "  X = np.random.normal(loc=0,scale=1,size=(n,3))\n",
        "  Y = X[:,0] + (X[:,1] * X[:,2])\n",
        "  Y = (Y > 1).astype(int)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "7jWxbcPrsPAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = generate_fake_data(10)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_by32F0sPbs",
        "outputId": "f256d574-c1dd-443f-a7ad-3d0c7d60eddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.89565096 -0.55759158 -0.22398289]\n",
            " [-0.4551438   0.15373351 -0.74359082]\n",
            " [ 0.35047165  0.37919655  0.77276871]\n",
            " [ 0.89025591  0.81883407  0.68484671]\n",
            " [-0.11605876 -1.00659674  0.31362304]\n",
            " [ 0.61285097 -0.1101846  -1.37660063]\n",
            " [ 0.89226472  0.33934765  0.89822575]\n",
            " [ 0.2564311  -0.49601225 -0.39096263]\n",
            " [ 0.48355458 -1.69924241 -0.38001659]\n",
            " [ 0.08587151  0.00351885  0.7366613 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.001 #learning rate\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "interaction_indices = [(0, 1), (0, 2), (1, 2)]  # Interactions between X1*X2, X1*X3, and X2*X3\n",
        "\n",
        "# Train the logistic regression model using ADAM with specified interactions\n",
        "custom_weights, log_history = adam_logistic_regression(X, y, alpha, beta1, beta2, max_iterations=1000, interaction_indices=interaction_indices)\n",
        "weights_without_interactions, log_history = adam_logistic_regression(X, y, alpha, beta1, beta2, max_iterations=1000)\n",
        "print(weights_without_interactions)\n",
        "print(custom_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "45w5ucTDsCBj",
        "outputId": "4db0e26a-dcb0-4b4a-f650-4140889478b3"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "(slice(None, None, None), 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-323-062ed873f4b6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train the logistic regression model using ADAM with specified interactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcustom_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minteraction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mweights_without_interactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madam_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_without_interactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-da571ce59f92>\u001b[0m in \u001b[0;36madam_logistic_regression\u001b[0;34m(X, y, alpha, beta1, beta2, epsilon, max_iterations, interaction_indices, threshold)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# If interaction_indices is provided, augment the feature set with specified interaction terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_custom_interactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Initialize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9801421dd320>\u001b[0m in \u001b[0;36madd_custom_interactions\u001b[0;34m(X, interaction_indices)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Function to add custom interactions between the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_custom_interactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0minteractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-9801421dd320>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Function to add custom interactions between the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_custom_interactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0minteractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minteraction_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0;31m#  the TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5923\u001b[0m             \u001b[0;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5924\u001b[0m             \u001b[0;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5925\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5927\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on big datasets"
      ],
      "metadata": {
        "id": "UTv0x2eJ8nAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "# Function to perform your experiment, e.g., training a model with the ADAM optimizer\n",
        "def run_experiment(X_train, y_train, X_test, y_test, experiment_name, if_interactions=False):\n",
        "    alpha = 0.001 #learning rate\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    print(experiment_name)\n",
        "    interaction_indices = [(0, 1)]\n",
        "    # Run your optimizer to train the model\n",
        "    if if_interactions:\n",
        "      weights, log_likelihood_history = adam_logistic_regression(X_train, y_train, alpha, beta1, beta2, max_iterations=500, interaction_indices=interaction_indices)\n",
        "    else:\n",
        "      weights, log_likelihood_history = adam_logistic_regression(X_train, y_train, alpha, beta1, beta2, max_iterations=500)\n",
        "    # Calculate the balanced accuracy on the test set\n",
        "    test_balanced_accuracy = balanced_accuracy(X_test, y_test, weights)\n",
        "    print(test_balanced_accuracy)\n",
        "    # Create a dictionary to store the results\n",
        "    experiment_results = {\n",
        "        'experiment_name': experiment_name,\n",
        "        'log_likelihood_history': log_likelihood_history,\n",
        "        'number_of_iterations': len(log_likelihood_history),\n",
        "        'balanced_accuracy': test_balanced_accuracy\n",
        "    }\n",
        "\n",
        "    return experiment_results"
      ],
      "metadata": {
        "id": "5u3gIb8jp90T"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking if every dataset is in the right format"
      ],
      "metadata": {
        "id": "idUBQf3fScsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sonar_X = sonar_X.values\n",
        "sonar_y = np.asarray(sonar_y)\n",
        "sonar_y = sonar_y.flatten()"
      ],
      "metadata": {
        "id": "UwUihq0N80td"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sonar_X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbqmEi9FZBMV",
        "outputId": "699b7396-0b80-42d2-e0de-0d609d41ccff"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
              "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
              "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
              "       ...,\n",
              "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
              "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
              "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sonar_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe1tp4PMZNI1",
        "outputId": "6ac985b0-7210-4923-acc1-671e0eb60269"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_breast = np.asarray(X_breast)"
      ],
      "metadata": {
        "id": "X2bSRH669xcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ionsphere_X = np.asarray(ionsphere_X)\n",
        "ionsphere_y = np.asarray(ionsphere_y)\n",
        "ionsphere_y = ionsphere_y.flatten()"
      ],
      "metadata": {
        "id": "ssii8v3p97l3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_heart, y_heart = fetch_heart_disease()"
      ],
      "metadata": {
        "id": "--4_HG5j-iEI"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_heart.shape, y_heart.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ZZjHvYSMn1",
        "outputId": "a755db59-5f12-417f-ae5c-d803340a663b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(297, 18) (297,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_parkinson, y_parkinson = fetch_parkinsons()"
      ],
      "metadata": {
        "id": "5PFnNQ1BReFw"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_hcv, y_hcv = fetch_hcv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nGetEI6RieQ",
        "outputId": "86cb9b59-a3e9-41d1-b717-c6e7045038d3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-aee083fc4a77>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
            "<ipython-input-82-aee083fc4a77>:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  X.loc[:,'Sex'] = X['Sex'].map({'m': 0, 'f': 1})\n",
            "<ipython-input-82-aee083fc4a77>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n",
            "<ipython-input-82-aee083fc4a77>:12: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  y.loc[:,'Category'] = y['Category'].map({'0=Blood Donor': 0,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_heart = np.asarray(y_heart)\n",
        "y_heart = y_heart.flatten()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrFKbrnhSj7a",
        "outputId": "160e32b2-c794-4127-844d-6d8fbf381c0b"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load small dataset"
      ],
      "metadata": {
        "id": "FmluHo5DZD9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes  = pd.read_csv(r'/content/diabetes.csv') # small dataset"
      ],
      "metadata": {
        "id": "Rct1CLAnyk59"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_diabetes = diabetes.iloc[:, :-1]\n",
        "Y_diabetes = diabetes[\"Outcome\"]"
      ],
      "metadata": {
        "id": "lwXFEvzXyTKy"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_diabetes = np.asarray(Y_diabetes)\n",
        "Y_diabetes = Y_diabetes.flatten()"
      ],
      "metadata": {
        "id": "DcWaDD-WzbtK"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_diabetes=np.asarray(X_diabetes)"
      ],
      "metadata": {
        "id": "VWcAw2xM0Pba"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['Variance', 'Skewness', 'Class']\n",
        "banknote = pd.read_csv(r'/content/data_banknote_authentication_pca.txt', header=None, names=columns)\n",
        "banknote = banknote.iloc[1:]"
      ],
      "metadata": {
        "id": "pBeiiy8exQSb"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_bank = banknote.iloc[:, :-1]\n",
        "Y_bank = banknote[\"Class\"]"
      ],
      "metadata": {
        "id": "IAQ_R0XbMaSO"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_bank = np.asarray(X_bank)\n",
        "X_bank = [[float(number) for number in inner_list] for inner_list in X_bank]\n",
        "X_bank = np.asarray(X_bank)\n",
        "Y_bank = [[int(number) for number in inner_list] for inner_list in Y_bank]\n",
        "Y_bank = np.asarray(Y_bank)\n",
        "Y_bank = Y_bank.flatten()"
      ],
      "metadata": {
        "id": "CqlfTcgiNfCY"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fraud = pd.read_csv(r'/content/fraud_detection_dataset_cleaned.txt')\n",
        "X_fraud = fraud.iloc[:, :-1]\n",
        "Y_fraud = fraud[\"is_fraud\"]"
      ],
      "metadata": {
        "id": "zlGpcGsJOpDK"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_fraud = np.asarray(X_fraud)\n",
        "Y_fraud = np.asarray(Y_fraud)"
      ],
      "metadata": {
        "id": "ocZLdeMXRiWr"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Adam on big datasets"
      ],
      "metadata": {
        "id": "BKFv696USlpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sonar_X, sonar_y, X_breast, Y_breast, _X, ionspherionspheree_y, X_heart, y_heart, X_parkinson, y_parkinson, X_hcv, y_hcv"
      ],
      "metadata": {
        "id": "Cy0kmSHgTC_X"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_experiment_results = []"
      ],
      "metadata": {
        "id": "8u6QiF6dqsxA"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sonar\n",
        "title=\"Sonar\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(sonar_X, sonar_y, test_size=0.3, random_state=i)\n",
        "  results_1 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_1[\"balanced_accuracy\"])\n",
        "\n",
        "results_1[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_1[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "all_experiment_results.append(results_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5LVci8Nqlue",
        "outputId": "35cf0910-519a-488d-aff7-dbd20281a13d"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sonar\n",
            "Iteration 1/500 - Loss: 0.6921673562122808\n",
            "Iteration 100/500 - Loss: 0.6418428863890534\n",
            "Iteration 200/500 - Loss: 0.6034088338225829\n",
            "Iteration 300/500 - Loss: 0.5721763604376524\n",
            "Iteration 400/500 - Loss: 0.5464452773334616\n",
            "Iteration 500/500 - Loss: 0.5249860493056951\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7342799188640974\n",
            "Sonar\n",
            "Iteration 1/500 - Loss: 0.6920510683465634\n",
            "Iteration 100/500 - Loss: 0.6424209963503728\n",
            "Iteration 200/500 - Loss: 0.6045149884855325\n",
            "Iteration 300/500 - Loss: 0.5733987589982101\n",
            "Iteration 400/500 - Loss: 0.5478255767946999\n",
            "Iteration 500/500 - Loss: 0.5265845052217505\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7111895161290323\n",
            "Sonar\n",
            "Iteration 1/500 - Loss: 0.69227976642076\n",
            "Iteration 100/500 - Loss: 0.6483006057551798\n",
            "Iteration 200/500 - Loss: 0.6125125972573058\n",
            "Iteration 300/500 - Loss: 0.5832159510659757\n",
            "Iteration 400/500 - Loss: 0.5589900422800709\n",
            "Iteration 500/500 - Loss: 0.5387254303434104\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7439148073022313\n",
            "Sonar\n",
            "Iteration 1/500 - Loss: 0.6921609582233753\n",
            "Iteration 100/500 - Loss: 0.6408827327700016\n",
            "Iteration 200/500 - Loss: 0.6019521602517537\n",
            "Iteration 300/500 - Loss: 0.5705725018446377\n",
            "Iteration 400/500 - Loss: 0.5448993741237707\n",
            "Iteration 500/500 - Loss: 0.523644929431667\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.696969696969697\n",
            "Sonar\n",
            "Iteration 1/500 - Loss: 0.6921942336665631\n",
            "Iteration 100/500 - Loss: 0.63741132354096\n",
            "Iteration 200/500 - Loss: 0.5959988685847923\n",
            "Iteration 300/500 - Loss: 0.5626336651786734\n",
            "Iteration 400/500 - Loss: 0.5353884280775054\n",
            "Iteration 500/500 - Loss: 0.5128899369395997\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.675\n",
            "0.7122707878530117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Breast\n",
        "title=\"Breast\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_breast, Y_breast, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "all_experiment_results.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHf-Pf4UrS6Z",
        "outputId": "68af73cb-a71c-4481-c30d-ac89b93ecffe"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breast\n",
            "Iteration 1/500 - Loss: 0.6908078313615811\n",
            "Iteration 100/500 - Loss: 0.6234120427520091\n",
            "Iteration 200/500 - Loss: 0.5916708582997776\n",
            "Iteration 300/500 - Loss: 0.573667539924419\n",
            "Iteration 400/500 - Loss: 0.5594700658975111\n",
            "Iteration 500/500 - Loss: 0.5464180963160324\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.673941798941799\n",
            "Breast\n",
            "Iteration 1/500 - Loss: 0.6910454008469531\n",
            "Iteration 100/500 - Loss: 0.6259570704477202\n",
            "Iteration 200/500 - Loss: 0.5953732953683674\n",
            "Iteration 300/500 - Loss: 0.5771534936691314\n",
            "Iteration 400/500 - Loss: 0.5621165730085417\n",
            "Iteration 500/500 - Loss: 0.5481521598272462\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6871693121693122\n",
            "Breast\n",
            "Iteration 1/500 - Loss: 0.6905058782980582\n",
            "Iteration 100/500 - Loss: 0.6320333840225207\n",
            "Iteration 200/500 - Loss: 0.6022277769393694\n",
            "Iteration 300/500 - Loss: 0.5845707684205375\n",
            "Iteration 400/500 - Loss: 0.5705679176882351\n",
            "Iteration 500/500 - Loss: 0.5577503699624408\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.716776693455798\n",
            "Breast\n",
            "Iteration 1/500 - Loss: 0.690885824291662\n",
            "Iteration 100/500 - Loss: 0.6230321785477594\n",
            "Iteration 200/500 - Loss: 0.5906479201048852\n",
            "Iteration 300/500 - Loss: 0.572867787740009\n",
            "Iteration 400/500 - Loss: 0.5595110680072594\n",
            "Iteration 500/500 - Loss: 0.5475223512907618\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6789730689553122\n",
            "Breast\n",
            "Iteration 1/500 - Loss: 0.6917606832086024\n",
            "Iteration 100/500 - Loss: 0.629062495281742\n",
            "Iteration 200/500 - Loss: 0.6011459616048934\n",
            "Iteration 300/500 - Loss: 0.5837409134811092\n",
            "Iteration 400/500 - Loss: 0.5688438440899707\n",
            "Iteration 500/500 - Loss: 0.5549259470562558\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6965811965811965\n",
            "0.6906884140206836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ionsphere\n",
        "title=\"Ionsphere\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(ionsphere_X, ionsphere_y, test_size=0.3, random_state=i)\n",
        "  results_1 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_1[\"balanced_accuracy\"])\n",
        "\n",
        "results_1[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_1[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "all_experiment_results.append(results_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eh-vfXSsGXy",
        "outputId": "7c214b28-e643-4cdf-cc14-e5214189c965"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ionsphere\n",
            "Iteration 1/500 - Loss: 0.6903722266517557\n",
            "Iteration 100/500 - Loss: 0.5479145220934577\n",
            "Iteration 200/500 - Loss: 0.4999806869337956\n",
            "Iteration 300/500 - Loss: 0.46920150933440014\n",
            "Iteration 400/500 - Loss: 0.4466603266494115\n",
            "Iteration 500/500 - Loss: 0.4289628555103742\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7159090909090909\n",
            "Ionsphere\n",
            "Iteration 1/500 - Loss: 0.6906694245343246\n",
            "Iteration 100/500 - Loss: 0.5599890858220912\n",
            "Iteration 200/500 - Loss: 0.5108895488631626\n",
            "Iteration 300/500 - Loss: 0.48100866057710806\n",
            "Iteration 400/500 - Loss: 0.4590874955327786\n",
            "Iteration 500/500 - Loss: 0.44141737335539716\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6944444444444444\n",
            "Ionsphere\n",
            "Iteration 1/500 - Loss: 0.6902262896950365\n",
            "Iteration 100/500 - Loss: 0.5315989660245559\n",
            "Iteration 200/500 - Loss: 0.47707183252702984\n",
            "Iteration 300/500 - Loss: 0.445107900535805\n",
            "Iteration 400/500 - Loss: 0.4225618806838793\n",
            "Iteration 500/500 - Loss: 0.4049809724112759\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6521739130434783\n",
            "Ionsphere\n",
            "Iteration 1/500 - Loss: 0.6904636690065462\n",
            "Iteration 100/500 - Loss: 0.5499865711797208\n",
            "Iteration 200/500 - Loss: 0.5044942365396078\n",
            "Iteration 300/500 - Loss: 0.47724466336029653\n",
            "Iteration 400/500 - Loss: 0.45688281405328485\n",
            "Iteration 500/500 - Loss: 0.4402323782751523\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7307692307692308\n",
            "Ionsphere\n",
            "Iteration 1/500 - Loss: 0.6905661472471869\n",
            "Iteration 100/500 - Loss: 0.5567182842685154\n",
            "Iteration 200/500 - Loss: 0.5087449793933941\n",
            "Iteration 300/500 - Loss: 0.47926911175985093\n",
            "Iteration 400/500 - Loss: 0.4578259385715666\n",
            "Iteration 500/500 - Loss: 0.4407433410868211\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6388888888888888\n",
            "0.6864371136110268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Heart\n",
        "title=\"Heart\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_heart, y_heart, test_size=0.3, random_state=i)\n",
        "  results_1 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_1[\"balanced_accuracy\"])\n",
        "\n",
        "results_1[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_1[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "all_experiment_results.append(results_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oCm_LTAsQYB",
        "outputId": "8a6cd1b3-c7a9-4485-912f-4c80e691e19a"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heart\n",
            "Iteration 1/500 - Loss: 0.7108406836925574\n",
            "Iteration 100/500 - Loss: 0.5042640041444746\n",
            "Iteration 200/500 - Loss: 0.45922022004678137\n",
            "Iteration 300/500 - Loss: 0.4262704840814968\n",
            "Iteration 400/500 - Loss: 0.40188794609668127\n",
            "Iteration 500/500 - Loss: 0.38372158797146505\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7708333333333333\n",
            "Heart\n",
            "Iteration 1/500 - Loss: 0.7175513739377687\n",
            "Iteration 100/500 - Loss: 0.5100010237919831\n",
            "Iteration 200/500 - Loss: 0.46240425437667043\n",
            "Iteration 300/500 - Loss: 0.42625414713608095\n",
            "Iteration 400/500 - Loss: 0.3988167901074035\n",
            "Iteration 500/500 - Loss: 0.37794894307718685\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7767722473604827\n",
            "Heart\n",
            "Iteration 1/500 - Loss: 0.7069070210133366\n",
            "Iteration 100/500 - Loss: 0.5182270083377529\n",
            "Iteration 200/500 - Loss: 0.4753992820065156\n",
            "Iteration 300/500 - Loss: 0.4437753488505174\n",
            "Iteration 400/500 - Loss: 0.42017949964532747\n",
            "Iteration 500/500 - Loss: 0.40222464874232583\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.8295398317664522\n",
            "Heart\n",
            "Iteration 1/500 - Loss: 0.7165768831435569\n",
            "Iteration 100/500 - Loss: 0.5245848918338184\n",
            "Iteration 200/500 - Loss: 0.4814528309719203\n",
            "Iteration 300/500 - Loss: 0.4499538629837417\n",
            "Iteration 400/500 - Loss: 0.42703118225806214\n",
            "Iteration 500/500 - Loss: 0.41028112834234187\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.8275\n",
            "Heart\n",
            "Iteration 1/500 - Loss: 0.692506981470784\n",
            "Iteration 100/500 - Loss: 0.5156271680840592\n",
            "Iteration 200/500 - Loss: 0.47278635112180384\n",
            "Iteration 300/500 - Loss: 0.4407788946512036\n",
            "Iteration 400/500 - Loss: 0.41671024497219666\n",
            "Iteration 500/500 - Loss: 0.398393171440582\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7976190476190477\n",
            "0.8004528920158632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parkinson\n",
        "title=\"Parkinson\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_parkinson, y_parkinson, test_size=0.3, random_state=i)\n",
        "  results_1 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_1[\"balanced_accuracy\"])\n",
        "\n",
        "results_1[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_1[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "all_experiment_results.append(results_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jgTHeqHskH3",
        "outputId": "53c5ab23-44a9-42b5-9c8c-62cbd7d783e3"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parkinson\n",
            "Iteration 1/500 - Loss: 0.6234271897153595\n",
            "Iteration 100/500 - Loss: 0.57498422204276\n",
            "Iteration 200/500 - Loss: 0.5478999509798717\n",
            "Iteration 300/500 - Loss: 0.5240967810282808\n",
            "Iteration 400/500 - Loss: 0.5027769948090204\n",
            "Iteration 500/500 - Loss: 0.4839409667190151\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6153846153846154\n",
            "Parkinson\n",
            "Iteration 1/500 - Loss: 0.6039088871149334\n",
            "Iteration 100/500 - Loss: 0.5295397798128593\n",
            "Iteration 200/500 - Loss: 0.5028613168694159\n",
            "Iteration 300/500 - Loss: 0.48049626253239724\n",
            "Iteration 400/500 - Loss: 0.4602116642466236\n",
            "Iteration 500/500 - Loss: 0.4420133088262716\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5526315789473684\n",
            "Parkinson\n",
            "Iteration 1/500 - Loss: 0.6287599275751632\n",
            "Iteration 100/500 - Loss: 0.5750888683088891\n",
            "Iteration 200/500 - Loss: 0.5436145787326415\n",
            "Iteration 300/500 - Loss: 0.5159434297560198\n",
            "Iteration 400/500 - Loss: 0.49120095942591996\n",
            "Iteration 500/500 - Loss: 0.46931315147052455\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.625\n",
            "Parkinson\n",
            "Iteration 1/500 - Loss: 0.6273564753491806\n",
            "Iteration 100/500 - Loss: 0.5709804944821577\n",
            "Iteration 200/500 - Loss: 0.5437452585790069\n",
            "Iteration 300/500 - Loss: 0.5201467881181506\n",
            "Iteration 400/500 - Loss: 0.49873251740244234\n",
            "Iteration 500/500 - Loss: 0.4795589216674597\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6538461538461539\n",
            "Parkinson\n",
            "Iteration 1/500 - Loss: 0.6159992831505936\n",
            "Iteration 100/500 - Loss: 0.5359755698789831\n",
            "Iteration 200/500 - Loss: 0.5097299454301314\n",
            "Iteration 300/500 - Loss: 0.4891479690719972\n",
            "Iteration 400/500 - Loss: 0.47012864526660303\n",
            "Iteration 500/500 - Loss: 0.45269711308844757\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5625\n",
            "0.6018724696356276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hcv\n",
        "title=\"Hcv\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_hcv, y_hcv, test_size=0.3, random_state=i)\n",
        "  results_1 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_1[\"balanced_accuracy\"])\n",
        "\n",
        "results_1[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_1[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "all_experiment_results.append(results_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2jPQCaPwtwv",
        "outputId": "a577356c-72ba-41a7-8c03-396be4d6b0f8"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hcv\n",
            "Iteration 1/500 - Loss: 0.5681231757580323\n",
            "Iteration 100/500 - Loss: 0.1660336762799733\n",
            "Iteration 200/500 - Loss: 0.15267186921871012\n",
            "Iteration 300/500 - Loss: 0.14800580801243135\n",
            "Iteration 400/500 - Loss: 0.14565852826442055\n",
            "Iteration 500/500 - Loss: 0.144041443119013\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7732919254658385\n",
            "Hcv\n",
            "Iteration 1/500 - Loss: 0.5678026257390376\n",
            "Iteration 100/500 - Loss: 0.1715488776724476\n",
            "Iteration 200/500 - Loss: 0.15877417186859533\n",
            "Iteration 300/500 - Loss: 0.15321755952866098\n",
            "Iteration 400/500 - Loss: 0.1495086810292698\n",
            "Iteration 500/500 - Loss: 0.14648478012069602\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7765118317265556\n",
            "Hcv\n",
            "Iteration 1/500 - Loss: 0.5700644517016705\n",
            "Iteration 100/500 - Loss: 0.133829767589309\n",
            "Iteration 200/500 - Loss: 0.12023957608346415\n",
            "Iteration 300/500 - Loss: 0.11532727692828698\n",
            "Iteration 400/500 - Loss: 0.11272485862910865\n",
            "Iteration 500/500 - Loss: 0.11104880974622724\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6921997755331089\n",
            "Hcv\n",
            "Iteration 1/500 - Loss: 0.5723280870856859\n",
            "Iteration 100/500 - Loss: 0.17326099406066506\n",
            "Iteration 200/500 - Loss: 0.14864577796061895\n",
            "Iteration 300/500 - Loss: 0.13555246156512876\n",
            "Iteration 400/500 - Loss: 0.12871892819133002\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.9089314194577351\n",
            "Hcv\n",
            "Iteration 1/500 - Loss: 0.5649405578689143\n",
            "Iteration 100/500 - Loss: 0.13858439240585013\n",
            "Iteration 200/500 - Loss: 0.1262425952622576\n",
            "Iteration 300/500 - Loss: 0.12273784359350146\n",
            "Iteration 400/500 - Loss: 0.12117386026098205\n",
            "Iteration 500/500 - Loss: 0.12019283005649081\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7005189903279075\n",
            "0.7702907885022291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(all_experiment_results)\n",
        "results_df.to_csv('experiment_results.csv', index=False)"
      ],
      "metadata": {
        "id": "FukUmi3bqhfA"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing on small datasets"
      ],
      "metadata": {
        "id": "X9uWa3sTSpAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With interactions"
      ],
      "metadata": {
        "id": "ZzGK-ddCPa18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_data_experiments_with_interactions=[]"
      ],
      "metadata": {
        "id": "zBbqQ9WjPalK"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Diabetes\"\n",
        "mean_balanced_acc\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_diabetes, Y_diabetes, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title, if_interactions=True)\n",
        "\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "small_data_experiments_with_interactions.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEifWlw4V1i6",
        "outputId": "524a2be7-5da3-4edf-9108-467499c03706"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.7716298786439287\n",
            "Iteration 100/500 - Loss: 0.6073915480073103\n",
            "Iteration 200/500 - Loss: 0.6028125883183937\n",
            "Iteration 300/500 - Loss: 0.5987395312821494\n",
            "Iteration 400/500 - Loss: 0.5951345049345864\n",
            "Iteration 500/500 - Loss: 0.5921243595818931\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.49285591323807887\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.7475813249352027\n",
            "Iteration 100/500 - Loss: 0.5866807911569724\n",
            "Iteration 200/500 - Loss: 0.5822699100553447\n",
            "Iteration 300/500 - Loss: 0.5783264260969444\n",
            "Iteration 400/500 - Loss: 0.5748722853935283\n",
            "Iteration 500/500 - Loss: 0.5720074610129792\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.4827961321514907\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.6756708037263477\n",
            "Iteration 100/500 - Loss: 0.5647327226998129\n",
            "Iteration 200/500 - Loss: 0.5597239482061727\n",
            "Iteration 300/500 - Loss: 0.5559713874390783\n",
            "Iteration 400/500 - Loss: 0.5528843535186685\n",
            "Iteration 500/500 - Loss: 0.5504660807703378\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5129032258064516\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.732325727145993\n",
            "Iteration 100/500 - Loss: 0.5747427053657993\n",
            "Iteration 200/500 - Loss: 0.5701150940212474\n",
            "Iteration 300/500 - Loss: 0.5658378224981522\n",
            "Iteration 400/500 - Loss: 0.5621025250236329\n",
            "Iteration 500/500 - Loss: 0.55902042658607\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5112781954887218\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.7624766683835688\n",
            "Iteration 100/500 - Loss: 0.6001526676024939\n",
            "Iteration 200/500 - Loss: 0.595018017647318\n",
            "Iteration 300/500 - Loss: 0.5909060167803203\n",
            "Iteration 400/500 - Loss: 0.5872946824625149\n",
            "Iteration 500/500 - Loss: 0.584264818021696\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5\n",
            "0.58768999426552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Bank\"\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_bank, Y_bank, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title, if_interactions=True)\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "small_data_experiments_with_interactions.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_I5cjq-WjTZ",
        "outputId": "4c1dfef9-16d4-489c-86a1-d309b0cb551d"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6924924142090076\n",
            "Iteration 100/500 - Loss: 0.6390501155848657\n",
            "Iteration 200/500 - Loss: 0.6015628238146633\n",
            "Iteration 300/500 - Loss: 0.5725756330858758\n",
            "Iteration 400/500 - Loss: 0.5491915492351045\n",
            "Iteration 500/500 - Loss: 0.5300570524716905\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6925319246913657\n",
            "Iteration 100/500 - Loss: 0.6412597700357897\n",
            "Iteration 200/500 - Loss: 0.6032609114774651\n",
            "Iteration 300/500 - Loss: 0.5732007115468265\n",
            "Iteration 400/500 - Loss: 0.5490569616937845\n",
            "Iteration 500/500 - Loss: 0.5294634168239754\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6654405577593461\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6924554451018916\n",
            "Iteration 100/500 - Loss: 0.6359685235208021\n",
            "Iteration 200/500 - Loss: 0.5958928353727031\n",
            "Iteration 300/500 - Loss: 0.5645754958194067\n",
            "Iteration 400/500 - Loss: 0.5392576765113802\n",
            "Iteration 500/500 - Loss: 0.5185572412992406\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.654826893536571\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6924697253942581\n",
            "Iteration 100/500 - Loss: 0.6373375947413584\n",
            "Iteration 200/500 - Loss: 0.5988488186408902\n",
            "Iteration 300/500 - Loss: 0.5692204671965122\n",
            "Iteration 400/500 - Loss: 0.5454862534054302\n",
            "Iteration 500/500 - Loss: 0.5262247012936856\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6751453488372092\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6924694161324273\n",
            "Iteration 100/500 - Loss: 0.6373041414540026\n",
            "Iteration 200/500 - Loss: 0.5981590605620408\n",
            "Iteration 300/500 - Loss: 0.5675479330659047\n",
            "Iteration 400/500 - Loss: 0.5429310149961033\n",
            "Iteration 500/500 - Loss: 0.5229276819687453\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6383221042031313\n",
            "0.6667469808672515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Fraud\"\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_fraud, Y_fraud, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title, if_interactions=True)\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "small_data_experiments_with_interactions.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPGELS1AWmeY",
        "outputId": "cfb2f421-d486-47d7-de29-1e1938f20b2e"
      },
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c193c5551b37>:3: RuntimeWarning: overflow encountered in exp\n",
            "  log_likelihood = np.sum(y * logits - np.log1p(np.exp(logits)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.49999333883989233\n",
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c193c5551b37>:3: RuntimeWarning: overflow encountered in exp\n",
            "  log_likelihood = np.sum(y * logits - np.log1p(np.exp(logits)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.49986517033481037\n",
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c193c5551b37>:3: RuntimeWarning: overflow encountered in exp\n",
            "  log_likelihood = np.sum(y * logits - np.log1p(np.exp(logits)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5\n",
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c193c5551b37>:3: RuntimeWarning: overflow encountered in exp\n",
            "  log_likelihood = np.sum(y * logits - np.log1p(np.exp(logits)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5\n",
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-c193c5551b37>:3: RuntimeWarning: overflow encountered in exp\n",
            "  log_likelihood = np.sum(y * logits - np.log1p(np.exp(logits)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5\n",
            "0.4999717018349406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_small = pd.DataFrame(small_data_experiments_with_interactions)\n",
        "results_df_small.to_csv('small_data_set_experiment_results_with_interactions.csv', index=False)"
      ],
      "metadata": {
        "id": "sCjMAM23WpSI"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without interactions"
      ],
      "metadata": {
        "id": "a133DsNEPdZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_data_experiments =[]"
      ],
      "metadata": {
        "id": "6niyljdAR_bW"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Diabetes\"\n",
        "mean_balanced_acc\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_diabetes, Y_diabetes, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "small_data_experiments.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4MmSn9eSQfz",
        "outputId": "1d8d6c9e-19ee-4dba-c62a-fb26ac4c25fe"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.6806073932985435\n",
            "Iteration 100/500 - Loss: 0.6239308852871734\n",
            "Iteration 200/500 - Loss: 0.623102056219557\n",
            "Iteration 300/500 - Loss: 0.622954599638847\n",
            "Iteration 400/500 - Loss: 0.6228919391145639\n",
            "Iteration 500/500 - Loss: 0.6228680342240533\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6521346186951282\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.6720291042524539\n",
            "Iteration 100/500 - Loss: 0.6036472399544808\n",
            "Iteration 200/500 - Loss: 0.6026579118463246\n",
            "Iteration 300/500 - Loss: 0.6025891091969237\n",
            "Iteration 400/500 - Loss: 0.6025733793135104\n",
            "Iteration 500/500 - Loss: 0.6025678450815168\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.58883964544722\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.6788736557343917\n",
            "Iteration 100/500 - Loss: 0.6004419606557373\n",
            "Iteration 200/500 - Loss: 0.5918216700606456\n",
            "Iteration 300/500 - Loss: 0.5890698077697651\n",
            "Iteration 400/500 - Loss: 0.5882112455213031\n",
            "Iteration 500/500 - Loss: 0.5878787636388798\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5775042444821732\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.664927400906752\n",
            "Iteration 100/500 - Loss: 0.597922889069163\n",
            "Iteration 200/500 - Loss: 0.5953991780723098\n",
            "Iteration 300/500 - Loss: 0.5948661696730873\n",
            "Iteration 400/500 - Loss: 0.5946671296313484\n",
            "Iteration 500/500 - Loss: 0.5945605177318595\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5735767991407089\n",
            "Diabetes\n",
            "Iteration 1/500 - Loss: 0.6739630931782687\n",
            "Iteration 100/500 - Loss: 0.6217973303849103\n",
            "Iteration 200/500 - Loss: 0.6185150323263915\n",
            "Iteration 300/500 - Loss: 0.6179076638020484\n",
            "Iteration 400/500 - Loss: 0.6177207867713186\n",
            "Iteration 500/500 - Loss: 0.6176336459329189\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.6060959360426382\n",
            "0.5996302487615737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Bank\"\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_bank, Y_bank, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "small_data_experiments.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a77SqjBWR-XI",
        "outputId": "d043818c-5366-4553-b20e-c36ec8c19a58"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6926142332222456\n",
            "Iteration 100/500 - Loss: 0.6451518930830245\n",
            "Iteration 200/500 - Loss: 0.6075610337728179\n",
            "Iteration 300/500 - Loss: 0.5781994662410033\n",
            "Iteration 400/500 - Loss: 0.5550936390131969\n",
            "Iteration 500/500 - Loss: 0.5367211950546398\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7777298850574713\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.692611213696167\n",
            "Iteration 100/500 - Loss: 0.6447002911196112\n",
            "Iteration 200/500 - Loss: 0.6064442773613574\n",
            "Iteration 300/500 - Loss: 0.5763793029122157\n",
            "Iteration 400/500 - Loss: 0.5526405479562615\n",
            "Iteration 500/500 - Loss: 0.533745992014186\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7714148335136435\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6925774939408085\n",
            "Iteration 100/500 - Loss: 0.6417536651712319\n",
            "Iteration 200/500 - Loss: 0.6013420857087769\n",
            "Iteration 300/500 - Loss: 0.5696617044420468\n",
            "Iteration 400/500 - Loss: 0.5446527683281384\n",
            "Iteration 500/500 - Loss: 0.5247173388287739\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7332860687699397\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.6925919037414772\n",
            "Iteration 100/500 - Loss: 0.6432517312243867\n",
            "Iteration 200/500 - Loss: 0.604398110747493\n",
            "Iteration 300/500 - Loss: 0.5742446715368834\n",
            "Iteration 400/500 - Loss: 0.5506693421200541\n",
            "Iteration 500/500 - Loss: 0.5320393060410337\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7724806201550387\n",
            "Bank\n",
            "Iteration 1/500 - Loss: 0.692585065561662\n",
            "Iteration 100/500 - Loss: 0.6425231186737571\n",
            "Iteration 200/500 - Loss: 0.602891378620988\n",
            "Iteration 300/500 - Loss: 0.5719810211726506\n",
            "Iteration 400/500 - Loss: 0.5477197751939867\n",
            "Iteration 500/500 - Loss: 0.5285021758538181\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.7607715731172224\n",
            "0.7631365961226632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title=\"Fraud\"\n",
        "mean_balanced_acc = []\n",
        "for i in range(0, 5):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_fraud, Y_fraud, test_size=0.3, random_state=i)\n",
        "  results_2 =run_experiment(X_train, y_train, X_test, y_test, title)\n",
        "  mean_balanced_acc.append(results_2[\"balanced_accuracy\"])\n",
        "\n",
        "results_2[\"balanced_accuracy\"] = np.mean(mean_balanced_acc)\n",
        "print(results_2[\"balanced_accuracy\"])\n",
        "#It takes the log-like function from last expermient\n",
        "small_data_experiments.append(results_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-F2a3KPggf",
        "outputId": "ad0d31a1-99c9-425a-939c-0ce890f9562a"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n",
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.9598297566818816\n",
            "Fraud\n",
            "Iteration 1/500 - Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.9597981816707846\n",
            "Fraud\n",
            "Iteration 1/500 - Loss: 29.133824821457313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.5259698071214145\n",
            "Fraud\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/500 - Loss: nan\n",
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.9597584798292516\n",
            "Fraud\n",
            "Iteration 1/500 - Loss: 53.791327020655594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: divide by zero encountered in log\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
            "<ipython-input-3-9801421dd320>:9: RuntimeWarning: invalid value encountered in multiply\n",
            "  loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 100/500 - Loss: nan\n",
            "Iteration 200/500 - Loss: nan\n",
            "Iteration 300/500 - Loss: nan\n",
            "Iteration 400/500 - Loss: nan\n",
            "Iteration 500/500 - Loss: nan\n",
            "Algorithm reached the maximum number of iterations: 500\n",
            "0.9593277820896915\n",
            "0.8729368014786049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_small = pd.DataFrame(small_data_experiments)\n",
        "results_df_small.to_csv('small_data_set_experiment_results_without_interactions.csv', index=False)"
      ],
      "metadata": {
        "id": "sfVslCiDTc8h"
      },
      "execution_count": 315,
      "outputs": []
    }
  ]
}