{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "cL7q8sJOsUiR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3lrii3Mwrxcq"
      },
      "outputs": [],
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Logistic regression cost-function (Cross-entropy loss)\n",
        "def logistic_loss(X, y, weights):\n",
        "    z = np.dot(X, weights)\n",
        "    predictions = sigmoid(z)\n",
        "    loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
        "    return loss\n",
        "\n",
        "# Gradient of the logistic regression cost-function\n",
        "def logistic_gradient(X, y, weights):\n",
        "    predictions = sigmoid(np.dot(X, weights))\n",
        "    gradient = np.dot(X.T, (predictions - y)) / y.size\n",
        "    return gradient\n",
        "\n",
        "# Function to add custom interactions between the variables\n",
        "def add_custom_interactions(X, interaction_indices):\n",
        "    interactions = np.array([X[:, i] * X[:, j] for i, j in interaction_indices]).T\n",
        "    return np.hstack((X, interactions))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adam_logistic_regression(X, y, alpha, beta1, beta2, epsilon=1e-8, max_iterations=1000, interaction_indices=None):\n",
        "    # If interaction_indices is provided, augment the feature set with specified interaction terms\n",
        "    if interaction_indices:\n",
        "        X = add_custom_interactions(X, interaction_indices)\n",
        "\n",
        "    # Initialize weights\n",
        "    weights = np.zeros(X.shape[1])\n",
        "\n",
        "    # Initialize first moment and second moment\n",
        "    m = np.zeros(X.shape[1])\n",
        "    v = np.zeros(X.shape[1])\n",
        "\n",
        "    for t in range(1, max_iterations+1):\n",
        "        # Compute the gradient\n",
        "        g = logistic_gradient(X, y, weights)\n",
        "\n",
        "        # Update moments\n",
        "        m = beta1 * m + (1 - beta1) * g\n",
        "        v = beta2 * v + (1 - beta2) * np.square(g)\n",
        "\n",
        "        # Compute bias-corrected moments\n",
        "        m_corrected = m / (1 - beta1 ** t)\n",
        "        v_corrected = v / (1 - beta2 ** t)\n",
        "\n",
        "        # Update weights\n",
        "        weights -= alpha * m_corrected / (np.sqrt(v_corrected) + epsilon)\n",
        "\n",
        "        # Print the loss value occasionally to monitor progress\n",
        "        if t % 100 == 0 or t == 1:\n",
        "            loss = logistic_loss(X, y, weights)\n",
        "            print(f'Iteration {t}/{max_iterations} - Loss: {loss}')\n",
        "\n",
        "    return weights"
      ],
      "metadata": {
        "id": "cPJOIlc3r7Qa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_data(n: int):\n",
        "  X = np.random.normal(loc=0,scale=1,size=(n,3))\n",
        "  Y = X[:,0] + (X[:,1] * X[:,2])\n",
        "  Y = (Y > 1).astype(int)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "7jWxbcPrsPAk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = generate_fake_data(10)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_by32F0sPbs",
        "outputId": "17730450-d5a8-4759-a6e9-c8adbcbf30a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.71671533  0.21360876  0.24112544]\n",
            " [ 0.52678433  2.48753786 -0.03087967]\n",
            " [ 0.66183741 -1.63411601 -0.75063294]\n",
            " [-0.42253157 -0.49435484 -0.79454838]\n",
            " [-1.40786671 -1.16401044  0.91079288]\n",
            " [-1.21231104 -0.56454689  1.69508072]\n",
            " [-3.37682423  0.02853939 -1.33770856]\n",
            " [ 0.6538612  -0.01890399 -0.65351566]\n",
            " [-2.34758436  0.57518585  0.71882664]\n",
            " [ 0.46121278  0.1281024   0.85440883]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.001 #learning rate\n",
        "beta1 = 0.9\n",
        "beta2 = 0.999\n",
        "interaction_indices = [(0, 1), (0, 2), (1, 2)]  # Interactions between X1*X2, X1*X3, and X2*X3\n",
        "\n",
        "# Train the logistic regression model using ADAM with specified interactions\n",
        "custom_weights = adam_logistic_regression(X, y, alpha, beta1, beta2, max_iterations=1000, interaction_indices=interaction_indices)\n",
        "weights_without_interactions = adam_logistic_regression(X, y, alpha, beta1, beta2, max_iterations=1000)\n",
        "print(weights_without_interactions)\n",
        "print(custom_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45w5ucTDsCBj",
        "outputId": "306dbc7e-b256-490e-b187-ac2f5c36f7dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/1000 - Loss: 0.6922107392977853\n",
            "Iteration 100/1000 - Loss: 0.6137356196056912\n",
            "Iteration 200/1000 - Loss: 0.5585182759102753\n",
            "Iteration 300/1000 - Loss: 0.520353318491456\n",
            "Iteration 400/1000 - Loss: 0.49368645019302343\n",
            "Iteration 500/1000 - Loss: 0.47466948121998015\n",
            "Iteration 600/1000 - Loss: 0.4607526273654015\n",
            "Iteration 700/1000 - Loss: 0.45026411667934296\n",
            "Iteration 800/1000 - Loss: 0.442104281749302\n",
            "Iteration 900/1000 - Loss: 0.4355446275138811\n",
            "Iteration 1000/1000 - Loss: 0.4300991709822012\n",
            "Iteration 1/1000 - Loss: 0.6925351897244209\n",
            "Iteration 100/1000 - Loss: 0.6383995859226491\n",
            "Iteration 200/1000 - Loss: 0.5964357537728319\n",
            "Iteration 300/1000 - Loss: 0.5647682407833423\n",
            "Iteration 400/1000 - Loss: 0.5410201098983268\n",
            "Iteration 500/1000 - Loss: 0.5232444325698975\n",
            "Iteration 600/1000 - Loss: 0.509931305525479\n",
            "Iteration 700/1000 - Loss: 0.49994338600592475\n",
            "Iteration 800/1000 - Loss: 0.4924354983095129\n",
            "Iteration 900/1000 - Loss: 0.4867823381977229\n",
            "Iteration 1000/1000 - Loss: 0.4825209575720411\n",
            "[ 0.67214217 -0.63083871 -0.56693461]\n",
            "[ 0.64813684 -0.59805511 -0.41502615 -0.64833967 -0.03731548  0.32573482]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "# Generate predictions from the custom logistic regression model\n",
        "y_pred_probs_custom = sigmoid(np.dot(X_with_interactions, custom_weights))\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n",
        "y_pred_custom = (y_pred_probs_custom >= 0.5).astype(int)\n",
        "\n",
        "# Calculate balanced accuracy for the custom model\n",
        "bal_acc_custom = balanced_accuracy_score(y, y_pred_custom)\n",
        "print(f\"Balanced Accuracy (Custom Model): {bal_acc_custom}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuQ4u1Eu-zvc",
        "outputId": "b65d975c-dff5-45bb-a69c-22c78fe9b89f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Accuracy (Custom Model): 0.8333333333333333\n"
          ]
        }
      ]
    }
  ]
}