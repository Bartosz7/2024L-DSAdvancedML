{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openml\n",
    "from scipy.io import arff\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated_columns(X, index=0.8):\n",
    "\n",
    "    correlation_matrix = X.corr()\n",
    "    correlation_matrix = correlation_matrix.abs()\n",
    "\n",
    "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > index)]\n",
    "\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### League of Legends Diamond Games (First 15 Minutes) - large\n",
    "https://www.kaggle.com/datasets/benfattori/league-of-legends-diamond-games-first-15-minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_data = pd.read_csv('data_raw/MatchTimelinesFirst15.csv', index_col=0)\n",
    "lol_data = lol_data.drop(columns=['matchId','blueDragonKills','redDragonKills'])\n",
    "lol_data = lol_data.drop_duplicates()\n",
    "y = lol_data['blue_win']\n",
    "X = lol_data.drop(columns=['blue_win'])\n",
    "X = X.drop(correlated_columns(X), axis=1)\n",
    "lol_data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_data.to_csv('data_clean/lol_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heart Attack Analysis & Prediction Dataset - large\n",
    "https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data = pd.read_csv('data_raw/heart.csv')\n",
    "y = heart_data['output']\n",
    "X = heart_data.drop(columns=['output'])\n",
    "X = X.drop(correlated_columns(X), axis=1)\n",
    "heart_data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_data.to_csv('data_clean/heart_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pollen - small\n",
    "https://www.openml.org/search?type=data&sort=version&status=any&order=asc&exact_name=pollen&id=871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patryk\\AppData\\Local\\Temp/ipykernel_8600/620631877.py:1: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  pollen = openml.datasets.get_dataset(871)\n"
     ]
    }
   ],
   "source": [
    "pollen = openml.datasets.get_dataset(871)\n",
    "X, y, _, _ = pollen.get_data(target=pollen.default_target_attribute)\n",
    "y = np.where(y == 'P', 1, 0)\n",
    "pollen_data = pd.DataFrame(X)\n",
    "pollen_data = pollen_data.drop(correlated_columns(pollen_data), axis=1)\n",
    "pollen_data['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollen_data.to_csv('data_clean/pollen_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phishing websites - large\n",
    "[link to data](https://www.openml.org/search?type=data&sort=runs&status=active&qualities.NumberOfClasses=%3D_2&qualities.NumberOfFeatures=between_10_100&id=4534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing_arff = arff.loadarff('data_raw/phishing_websites.arff')\n",
    "phishing = pd.DataFrame(phishing_arff[0])\n",
    "for col in phishing:\n",
    "    phishing[col] = phishing[col].apply(lambda x: int(x.decode()))\n",
    "phishing['Result'] = phishing['Result'].apply(lambda x: 0 if x==-1 else 1)\n",
    "phishing = phishing.drop(correlated_columns(phishing), axis=1)\n",
    "phishing.to_csv('data_clean/phishing_websites.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate model simulation - large\n",
    "[link to data](https://www.openml.org/search?type=data&sort=runs&status=active&qualities.NumberOfClasses=%3D_2&qualities.NumberOfFeatures=between_10_100&id=40994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_model_arff = arff.loadarff('data_raw/climate_model_simulation.arff')\n",
    "climate_model = pd.DataFrame(climate_model_arff[0])\n",
    "climate_model['outcome'] = climate_model['outcome'].apply(lambda x: int(x.decode()))\n",
    "climate_model = climate_model.drop(correlated_columns(climate_model), axis=1)\n",
    "climate_model.to_csv('data_clean/climate_model_simulation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banknote authentication - small\n",
    "[link to data](https://www.openml.org/search?type=data&sort=runs&status=active&qualities.NumberOfClasses=%3D_2&qualities.NumberOfFeatures=lte_10&qualities.NumberOfInstances=between_1000_10000&id=1462)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "banknote_file_path = 'data_raw/banknote_authentication.arff'\n",
    "with open(banknote_file_path, 'r', encoding='utf-8') as f:\n",
    "    arff_data = f.read()\n",
    "banknote_arff = arff.loadarff(StringIO(arff_data))\n",
    "banknote = pd.DataFrame(banknote_arff[0])\n",
    "banknote['Class'] = banknote['Class'].apply(lambda x: int(x.decode())-1)\n",
    "print(len(list(banknote.columns)))\n",
    "banknote = banknote.drop(correlated_columns(banknote), axis=1)\n",
    "print(len(list(banknote.columns)))\n",
    "banknote.to_csv('data_clean/banknote_authentication.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spambase - large\n",
    "https://archive.ics.uci.edu/dataset/94/spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_data = pd.read_csv('data_raw/spambase.data', header=None)\n",
    "X = spambase_data.iloc[:, :-1]\n",
    "y = spambase_data.iloc[:, -1]\n",
    "X = X.drop(correlated_columns(X), axis=1)\n",
    "spambase_data = pd.concat([X, y], axis=1)\n",
    "spambase_data.columns = list(range(len(spambase_data.columns) - 1)) + ['target']\n",
    "spambase_data.to_csv('data_clean/spambase.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ionosphere - large\n",
    "https://archive.ics.uci.edu/dataset/52/ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ion_data = pd.read_csv('data_raw/ionosphere.data', header=None)\n",
    "X = ion_data.iloc[:, :-1]\n",
    "X = X.iloc[:, 2:]\n",
    "X = X.drop(correlated_columns(X), axis=1)\n",
    "y = (ion_data.iloc[:, -1] == 'g').astype('int')\n",
    "ion_data = pd.concat([X, y], axis=1)\n",
    "ion_data.columns = list(range(len(ion_data.columns) - 1)) + ['target']\n",
    "ion_data.to_csv('data_clean/ionosphere.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phoneme - small\n",
    "https://www.openml.org/search?type=data&sort=nr_of_downloads&status=active&qualities.NumberOfClasses=%3D_2&format=any&id=1489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = arff.loadarff('data_raw/phoneme.arff')\n",
    "df = pd.DataFrame(raw_data[0])\n",
    "df['Class'] = df['Class'].astype('int') - 1\n",
    "df.to_csv('data_clean/phoneme.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "396",
   "language": "python",
   "name": "396"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
